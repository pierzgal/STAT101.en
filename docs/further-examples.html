<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.3 Further examples | STAT 101 IPS (WSMiP UŁ)</title>
  <meta name="description" content="4.3 Further examples | STAT 101 IPS (WSMiP UŁ)" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4.3 Further examples | STAT 101 IPS (WSMiP UŁ)" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.3 Further examples | STAT 101 IPS (WSMiP UŁ)" />
  
  
  

<meta name="author" content="Michał Pierzgalski" />


<meta name="date" content="2021-01-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="elementary-probability.html"/>
<link rel="next" href="random-variables-and-probability-distributions-lecture-5-draft-copy-ver-0-3.html"/>
<script src="assets/header-attrs-2.6/header-attrs.js"></script>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<script src="assets/viz-1.8.2/viz.js"></script>
<link href="assets/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="assets/grViz-binding-1.0.6.1/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Course description</a>
<ul>
<li class="chapter" data-level="" data-path="contact.html"><a href="contact.html"><i class="fa fa-check"></i>Contact</a>
<ul>
<li class="chapter" data-level="" data-path="contact.html"><a href="contact.html#office-hours-20202021"><i class="fa fa-check"></i>Office hours (2020/2021)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-lecture-1.html"><a href="introduction-lecture-1.html"><i class="fa fa-check"></i><b>1</b> Introduction [Lecture 1]</a>
<ul>
<li class="chapter" data-level="1.1" data-path="motivation-two-reasons-why-you-should-learn-statistics-and-data-analysis-methods.html"><a href="motivation-two-reasons-why-you-should-learn-statistics-and-data-analysis-methods.html"><i class="fa fa-check"></i><b>1.1</b> Motivation - two reasons why you should learn statistics and data analysis methods?</a></li>
<li class="chapter" data-level="1.2" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><i class="fa fa-check"></i><b>1.2</b> Review of some mathematical concepts used in statistics and data science</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#algebra-review---some-basic-rules"><i class="fa fa-check"></i><b>1.2.1</b> Algebra review - some basic rules</a></li>
<li class="chapter" data-level="1.2.2" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#functions"><i class="fa fa-check"></i><b>1.2.2</b> Functions</a></li>
<li class="chapter" data-level="1.2.3" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#three-basic-concepts-of-calculus"><i class="fa fa-check"></i><b>1.2.3</b> Three basic concepts of calculus</a></li>
<li class="chapter" data-level="1.2.4" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#limits"><i class="fa fa-check"></i><b>1.2.4</b> Limits</a></li>
<li class="chapter" data-level="1.2.5" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#derivative"><i class="fa fa-check"></i><b>1.2.5</b> Derivative</a></li>
<li class="chapter" data-level="1.2.6" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#integral"><i class="fa fa-check"></i><b>1.2.6</b> Integral</a></li>
<li class="chapter" data-level="1.2.7" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#integral-as-an-area---intuitive-explanation"><i class="fa fa-check"></i><b>1.2.7</b> Integral as an area - intuitive explanation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistics-an-introduction-lecture-2.html"><a href="statistics-an-introduction-lecture-2.html"><i class="fa fa-check"></i><b>2</b> Statistics - an introduction [Lecture 2]</a>
<ul>
<li class="chapter" data-level="2.1" data-path="essential-concepts.html"><a href="essential-concepts.html"><i class="fa fa-check"></i><b>2.1</b> Essential concepts</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="essential-concepts.html"><a href="essential-concepts.html#a-parameter-and-a-statistic"><i class="fa fa-check"></i><b>2.1.1</b> A parameter and a statistic</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="constructs-and-operational-definitionslecture-1.html"><a href="constructs-and-operational-definitionslecture-1.html"><i class="fa fa-check"></i><b>2.2</b> Constructs and operational definitions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="constructs-and-operational-definitionslecture-1.html"><a href="constructs-and-operational-definitionslecture-1.html#conceptualisation-and-operationalisation"><i class="fa fa-check"></i><b>2.2.1</b> Conceptualisation and operationalisation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-collection.html"><a href="data-collection.html"><i class="fa fa-check"></i><b>2.3</b> Data collection</a></li>
<li class="chapter" data-level="2.4" data-path="sampling-techniqueslecture-2.html"><a href="sampling-techniqueslecture-2.html"><i class="fa fa-check"></i><b>2.4</b> Sampling techniques</a></li>
<li class="chapter" data-level="2.5" data-path="data-distribution.html"><a href="data-distribution.html"><i class="fa fa-check"></i><b>2.5</b> Data distribution</a></li>
<li class="chapter" data-level="2.6" data-path="basic-stages-of-social-researchlecture-3.html"><a href="basic-stages-of-social-researchlecture-3.html"><i class="fa fa-check"></i><b>2.6</b> Basic stages of social research</a></li>
<li class="chapter" data-level="2.7" data-path="statistical-study-essential-steps.html"><a href="statistical-study-essential-steps.html"><i class="fa fa-check"></i><b>2.7</b> Statistical study - essential steps</a></li>
<li class="chapter" data-level="2.8" data-path="experimental-and-observational-studieslecture-4.html"><a href="experimental-and-observational-studieslecture-4.html"><i class="fa fa-check"></i><b>2.8</b> Experimental and observational studies</a></li>
<li class="chapter" data-level="2.9" data-path="statistical-research-design-an-example-of-a-simple-experimentlecture-5.html"><a href="statistical-research-design-an-example-of-a-simple-experimentlecture-5.html"><i class="fa fa-check"></i><b>2.9</b> Statistical research design - an example of a simple experiment</a></li>
<li class="chapter" data-level="2.10" data-path="descriptive-and-inferential-statistics.html"><a href="descriptive-and-inferential-statistics.html"><i class="fa fa-check"></i><b>2.10</b> Descriptive and inferential statistics</a></li>
<li class="chapter" data-level="2.11" data-path="random-samplinglecture-6.html"><a href="random-samplinglecture-6.html"><i class="fa fa-check"></i><b>2.11</b> Random sampling</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="random-samplinglecture-6.html"><a href="random-samplinglecture-6.html#sampling-errors-and-systematic-bias"><i class="fa fa-check"></i><b>2.11.1</b> Sampling errors and systematic bias</a></li>
<li class="chapter" data-level="2.11.2" data-path="random-samplinglecture-6.html"><a href="random-samplinglecture-6.html#various-types-of-bias-in-statistical-analysis"><i class="fa fa-check"></i><b>2.11.2</b> Various types of bias in statistical analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="experimental-designlecture-7.html"><a href="experimental-designlecture-7.html"><i class="fa fa-check"></i><b>2.12</b> Experimental design</a></li>
<li class="chapter" data-level="2.13" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><i class="fa fa-check"></i><b>2.13</b> Relevant modern application of statistical theory: Machine learning - the conceptual introduction</a>
<ul>
<li class="chapter" data-level="2.13.1" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#machine-learning-approaches"><i class="fa fa-check"></i><b>2.13.1</b> Machine learning approaches</a></li>
<li class="chapter" data-level="2.13.2" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#make-predictions-or-decisions-using-ml"><i class="fa fa-check"></i><b>2.13.2</b> Make predictions or decisions using ML</a></li>
<li class="chapter" data-level="2.13.3" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#machine-learning-approaches---visual-guide"><i class="fa fa-check"></i><b>2.13.3</b> Machine learning approaches - visual guide</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploratory-data-analysis-lecture-3.html"><a href="exploratory-data-analysis-lecture-3.html"><i class="fa fa-check"></i><b>3</b> Exploratory data analysis [Lecture 3]</a>
<ul>
<li class="chapter" data-level="3.1" data-path="types-of-data-and-the-scales-of-measurement.html"><a href="types-of-data-and-the-scales-of-measurement.html"><i class="fa fa-check"></i><b>3.1</b> Types of data and the scales of measurement</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="types-of-data-and-the-scales-of-measurement.html"><a href="types-of-data-and-the-scales-of-measurement.html#what-is-measurement"><i class="fa fa-check"></i><b>3.1.1</b> What is measurement?</a></li>
<li class="chapter" data-level="3.1.2" data-path="types-of-data-and-the-scales-of-measurement.html"><a href="types-of-data-and-the-scales-of-measurement.html#levels-of-measurement-scales-of-measurement"><i class="fa fa-check"></i><b>3.1.2</b> Levels of measurement (scales of measurement)</a></li>
<li class="chapter" data-level="3.1.3" data-path="types-of-data-and-the-scales-of-measurement.html"><a href="types-of-data-and-the-scales-of-measurement.html#discrete-or-continuous-variables"><i class="fa fa-check"></i><b>3.1.3</b> Discrete or continuous variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="levels-of-measurement-a-summary.html"><a href="levels-of-measurement-a-summary.html"><i class="fa fa-check"></i><b>3.2</b> Levels of measurement - a summary</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="levels-of-measurement-a-summary.html"><a href="levels-of-measurement-a-summary.html#types-of-data-and-levels-of-measurement---intuitions"><i class="fa fa-check"></i><b>3.2.1</b> Types of data and levels of measurement - intuitions</a></li>
<li class="chapter" data-level="3.2.2" data-path="levels-of-measurement-a-summary.html"><a href="levels-of-measurement-a-summary.html#frequency-distribution"><i class="fa fa-check"></i><b>3.2.2</b> Frequency distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html"><i class="fa fa-check"></i><b>3.3</b> Reliability and Validity</a></li>
<li class="chapter" data-level="3.4" data-path="tabular-presentation-of-data-distributions.html"><a href="tabular-presentation-of-data-distributions.html"><i class="fa fa-check"></i><b>3.4</b> Tabular presentation of data distributions</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="tabular-presentation-of-data-distributions.html"><a href="tabular-presentation-of-data-distributions.html#unordered-data"><i class="fa fa-check"></i><b>3.4.1</b> Unordered data</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="frequency-distribution-1.html"><a href="frequency-distribution-1.html"><i class="fa fa-check"></i><b>3.5</b> Frequency distribution</a></li>
<li class="chapter" data-level="3.6" data-path="frequency-distribution-with-intervals-for-grouped-data.html"><a href="frequency-distribution-with-intervals-for-grouped-data.html"><i class="fa fa-check"></i><b>3.6</b> Frequency distribution with intervals (for grouped data)</a></li>
<li class="chapter" data-level="3.7" data-path="basic-descriptive-statistics.html"><a href="basic-descriptive-statistics.html"><i class="fa fa-check"></i><b>3.7</b> Basic descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="basic-descriptive-statistics.html"><a href="basic-descriptive-statistics.html#basic-measures-of-central-tendency"><i class="fa fa-check"></i><b>3.7.1</b> Basic measures of central tendency</a></li>
<li class="chapter" data-level="3.7.2" data-path="basic-descriptive-statistics.html"><a href="basic-descriptive-statistics.html#which-measures-of-central-tendency-are-appropriate-for-numerical-and-categorical-data"><i class="fa fa-check"></i><b>3.7.2</b> Which measures of central tendency are appropriate for numerical and categorical data</a></li>
<li class="chapter" data-level="3.7.3" data-path="basic-descriptive-statistics.html"><a href="basic-descriptive-statistics.html#basic-measures-of-spreaddispersion"><i class="fa fa-check"></i><b>3.7.3</b> Basic measures of spread/dispersion</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="mean-and-standard-deviation.html"><a href="mean-and-standard-deviation.html"><i class="fa fa-check"></i><b>3.8</b> Mean and standard deviation</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="mean-and-standard-deviation.html"><a href="mean-and-standard-deviation.html#mean"><i class="fa fa-check"></i><b>3.8.1</b> Mean</a></li>
<li class="chapter" data-level="3.8.2" data-path="mean-and-standard-deviation.html"><a href="mean-and-standard-deviation.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>3.8.2</b> Variance and standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="useful-formulas-descriptive-statistics.html"><a href="useful-formulas-descriptive-statistics.html"><i class="fa fa-check"></i><b>3.9</b> Useful formulas (descriptive statistics)</a></li>
<li class="chapter" data-level="3.10" data-path="parameter-and-statistic-summary-of-symbols.html"><a href="parameter-and-statistic-summary-of-symbols.html"><i class="fa fa-check"></i><b>3.10</b> Parameter and statistic - summary of symbols</a></li>
<li class="chapter" data-level="3.11" data-path="finding-mean-and-standard-deviation.html"><a href="finding-mean-and-standard-deviation.html"><i class="fa fa-check"></i><b>3.11</b> Finding mean and standard deviation</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="finding-mean-and-standard-deviation.html"><a href="finding-mean-and-standard-deviation.html#example-3.1"><i class="fa fa-check"></i><b>3.11.1</b> Example 3.1</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="mode.html"><a href="mode.html"><i class="fa fa-check"></i><b>3.12</b> Mode</a></li>
<li class="chapter" data-level="3.13" data-path="quartiles-and-median.html"><a href="quartiles-and-median.html"><i class="fa fa-check"></i><b>3.13</b> Quartiles and median</a>
<ul>
<li class="chapter" data-level="3.13.1" data-path="quartiles-and-median.html"><a href="quartiles-and-median.html#example"><i class="fa fa-check"></i><b>3.13.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="measures-of-relative-standing.html"><a href="measures-of-relative-standing.html"><i class="fa fa-check"></i><b>3.14</b> Measures of relative standing</a>
<ul>
<li class="chapter" data-level="3.14.1" data-path="measures-of-relative-standing.html"><a href="measures-of-relative-standing.html#percentile-and-percentile-rank"><i class="fa fa-check"></i><b>3.14.1</b> Percentile and percentile rank</a></li>
<li class="chapter" data-level="3.14.2" data-path="measures-of-relative-standing.html"><a href="measures-of-relative-standing.html#standard-score-z-score"><i class="fa fa-check"></i><b>3.14.2</b> Standard score (Z-score)</a></li>
</ul></li>
<li class="chapter" data-level="3.15" data-path="basic-methods-of-data-visualization.html"><a href="basic-methods-of-data-visualization.html"><i class="fa fa-check"></i><b>3.15</b> Basic methods of data visualization</a></li>
<li class="chapter" data-level="3.16" data-path="bar-plot.html"><a href="bar-plot.html"><i class="fa fa-check"></i><b>3.16</b> Bar plot</a></li>
<li class="chapter" data-level="3.17" data-path="frequency-distribution-table-and-histogram.html"><a href="frequency-distribution-table-and-histogram.html"><i class="fa fa-check"></i><b>3.17</b> Frequency distribution table and histogram</a></li>
<li class="chapter" data-level="3.18" data-path="three-types-of-histograms-are-used.html"><a href="three-types-of-histograms-are-used.html"><i class="fa fa-check"></i><b>3.18</b> Three types of histograms are used:</a></li>
<li class="chapter" data-level="3.19" data-path="density-histogram-and-frequency-histogram.html"><a href="density-histogram-and-frequency-histogram.html"><i class="fa fa-check"></i><b>3.19</b> Density histogram and frequency histogram</a>
<ul>
<li class="chapter" data-level="3.19.1" data-path="density-histogram-and-frequency-histogram.html"><a href="density-histogram-and-frequency-histogram.html#construction-of-the-density-histogram-1"><i class="fa fa-check"></i><b>3.19.1</b> Construction of the density histogram (1)</a></li>
<li class="chapter" data-level="3.19.2" data-path="density-histogram-and-frequency-histogram.html"><a href="density-histogram-and-frequency-histogram.html#absolute-histogram"><i class="fa fa-check"></i><b>3.19.2</b> Absolute histogram</a></li>
<li class="chapter" data-level="3.19.3" data-path="density-histogram-and-frequency-histogram.html"><a href="density-histogram-and-frequency-histogram.html#relative-frequency-histogram"><i class="fa fa-check"></i><b>3.19.3</b> Relative frequency histogram</a></li>
</ul></li>
<li class="chapter" data-level="3.20" data-path="histogram-for-the-binomial-distribution-1.html"><a href="histogram-for-the-binomial-distribution-1.html"><i class="fa fa-check"></i><b>3.20</b> Histogram for the binomial distribution (1)</a></li>
<li class="chapter" data-level="3.21" data-path="box-plot.html"><a href="box-plot.html"><i class="fa fa-check"></i><b>3.21</b> Box plot</a></li>
<li class="chapter" data-level="3.22" data-path="box-plot-example-1.html"><a href="box-plot-example-1.html"><i class="fa fa-check"></i><b>3.22</b> Box plot - example (1)</a>
<ul>
<li class="chapter" data-level="3.22.1" data-path="box-plot-example-1.html"><a href="box-plot-example-1.html#box-plot---example-2"><i class="fa fa-check"></i><b>3.22.1</b> Box plot - example (2)</a></li>
<li class="chapter" data-level="3.22.2" data-path="box-plot-example-1.html"><a href="box-plot-example-1.html#box-plot---example-compare-the-box-plots"><i class="fa fa-check"></i><b>3.22.2</b> Box plot - example (compare the box plots)</a></li>
<li class="chapter" data-level="3.22.3" data-path="box-plot-example-1.html"><a href="box-plot-example-1.html#plot-the-data-from-the-above-example-using-histograms-and-smooth-density-curves"><i class="fa fa-check"></i><b>3.22.3</b> Plot the data from the above example using histograms and smooth density curves</a></li>
</ul></li>
<li class="chapter" data-level="3.23" data-path="box-plots-additional-example.html"><a href="box-plots-additional-example.html"><i class="fa fa-check"></i><b>3.23</b> Box plots - additional example</a></li>
<li class="chapter" data-level="3.24" data-path="histogram-and-box-plot.html"><a href="histogram-and-box-plot.html"><i class="fa fa-check"></i><b>3.24</b> Histogram and box-plot</a></li>
<li class="chapter" data-level="3.25" data-path="skewness-of-data-distribution.html"><a href="skewness-of-data-distribution.html"><i class="fa fa-check"></i><b>3.25</b> Skewness of data distribution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-statistical-inference-lecture-4-draft-copy-ver-0-3.html"><a href="introduction-to-statistical-inference-lecture-4-draft-copy-ver-0-3.html"><i class="fa fa-check"></i><b>4</b> Introduction to statistical inference [Lecture 4 - draft copy, ver. 0.3]</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>4.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="introduction.html"><a href="introduction.html#logic"><i class="fa fa-check"></i><b>4.1.1</b> Logic</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction.html"><a href="introduction.html#sets"><i class="fa fa-check"></i><b>4.1.2</b> Sets</a></li>
<li class="chapter" data-level="4.1.3" data-path="introduction.html"><a href="introduction.html#cardinality-retrieved-from-wikipedia.org"><i class="fa fa-check"></i><b>4.1.3</b> Cardinality (Retrieved from Wikipedia.org)</a></li>
<li class="chapter" data-level="4.1.4" data-path="introduction.html"><a href="introduction.html#sets---summary"><i class="fa fa-check"></i><b>4.1.4</b> Sets - summary</a></li>
<li class="chapter" data-level="4.1.5" data-path="introduction.html"><a href="introduction.html#venn-diagrams"><i class="fa fa-check"></i><b>4.1.5</b> Venn diagrams</a></li>
<li class="chapter" data-level="4.1.6" data-path="introduction.html"><a href="introduction.html#basic-counting-principles"><i class="fa fa-check"></i><b>4.1.6</b> Basic counting principles</a></li>
<li class="chapter" data-level="4.1.7" data-path="introduction.html"><a href="introduction.html#permutations-and-combinations"><i class="fa fa-check"></i><b>4.1.7</b> Permutations and Combinations</a></li>
<li class="chapter" data-level="4.1.8" data-path="introduction.html"><a href="introduction.html#permutations-without-repetitions"><i class="fa fa-check"></i><b>4.1.8</b> Permutations without repetitions</a></li>
<li class="chapter" data-level="4.1.9" data-path="introduction.html"><a href="introduction.html#combinations-without-repetitions"><i class="fa fa-check"></i><b>4.1.9</b> Combinations without repetitions</a></li>
<li class="chapter" data-level="4.1.10" data-path="introduction.html"><a href="introduction.html#permutations-with-repetitions"><i class="fa fa-check"></i><b>4.1.10</b> Permutations with repetitions</a></li>
<li class="chapter" data-level="4.1.11" data-path="introduction.html"><a href="introduction.html#combinations-with-repetitions"><i class="fa fa-check"></i><b>4.1.11</b> Combinations with repetitions</a></li>
<li class="chapter" data-level="4.1.12" data-path="introduction.html"><a href="introduction.html#permutations-and-combinations-with-bounded-repetition"><i class="fa fa-check"></i><b>4.1.12</b> Permutations and Combinations with Bounded Repetition</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="elementary-probability.html"><a href="elementary-probability.html"><i class="fa fa-check"></i><b>4.2</b> Elementary probability</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="elementary-probability.html"><a href="elementary-probability.html#introduction-1"><i class="fa fa-check"></i><b>4.2.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2.2" data-path="elementary-probability.html"><a href="elementary-probability.html#essential-definitions-and-concepts"><i class="fa fa-check"></i><b>4.2.2</b> Essential definitions and concepts</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="further-examples.html"><a href="further-examples.html"><i class="fa fa-check"></i><b>4.3</b> Further examples</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="further-examples.html"><a href="further-examples.html#example-1"><i class="fa fa-check"></i><b>4.3.1</b> Example 1</a></li>
<li class="chapter" data-level="4.3.2" data-path="further-examples.html"><a href="further-examples.html#example-2"><i class="fa fa-check"></i><b>4.3.2</b> Example 2</a></li>
<li class="chapter" data-level="4.3.3" data-path="further-examples.html"><a href="further-examples.html#example-3"><i class="fa fa-check"></i><b>4.3.3</b> Example 3</a></li>
<li class="chapter" data-level="4.3.4" data-path="further-examples.html"><a href="further-examples.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>4.3.4</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="4.3.5" data-path="further-examples.html"><a href="further-examples.html#law-of-total-probability"><i class="fa fa-check"></i><b>4.3.5</b> Law of total probability</a></li>
<li class="chapter" data-level="4.3.6" data-path="further-examples.html"><a href="further-examples.html#bayes-theorem"><i class="fa fa-check"></i><b>4.3.6</b> Bayes’ theorem</a></li>
<li class="chapter" data-level="4.3.7" data-path="further-examples.html"><a href="further-examples.html#various-examples"><i class="fa fa-check"></i><b>4.3.7</b> Various examples (*)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="random-variables-and-probability-distributions-lecture-5-draft-copy-ver-0-3.html"><a href="random-variables-and-probability-distributions-lecture-5-draft-copy-ver-0-3.html"><i class="fa fa-check"></i><b>5</b> Random variables and probability distributions [Lecture 5 - draft copy, ver. 0.3]</a>
<ul>
<li class="chapter" data-level="5.1" data-path="random-variable-and-probability-distribution-definitions.html"><a href="random-variable-and-probability-distribution-definitions.html"><i class="fa fa-check"></i><b>5.1</b> Random variable and probability distribution - definitions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="random-variable-and-probability-distribution-definitions.html"><a href="random-variable-and-probability-distribution-definitions.html#random-variable"><i class="fa fa-check"></i><b>5.1.1</b> Random variable</a></li>
<li class="chapter" data-level="5.1.2" data-path="random-variable-and-probability-distribution-definitions.html"><a href="random-variable-and-probability-distribution-definitions.html#probability-distribution-function"><i class="fa fa-check"></i><b>5.1.2</b> Probability distribution (function)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="how-to-define-random-variable-and-probability-distribution-an-example.html"><a href="how-to-define-random-variable-and-probability-distribution-an-example.html"><i class="fa fa-check"></i><b>5.2</b> How to define random variable and probability distribution - an example</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-probability-distributions-bernoulli-and-binomial-distributions.html"><a href="discrete-probability-distributions-bernoulli-and-binomial-distributions.html"><i class="fa fa-check"></i><b>5.3</b> Discrete probability distributions - Bernoulli and binomial distributions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="discrete-probability-distributions-bernoulli-and-binomial-distributions.html"><a href="discrete-probability-distributions-bernoulli-and-binomial-distributions.html#binary-random-variables-and-binomial-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Binary random variables and Binomial distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="discrete-probability-distributions-bernoulli-and-binomial-distributions.html"><a href="discrete-probability-distributions-bernoulli-and-binomial-distributions.html#some-characteristics-of-the-binomial-distribution"><i class="fa fa-check"></i><b>5.3.2</b> Some characteristics of the binomial distribution</a></li>
<li class="chapter" data-level="5.3.3" data-path="discrete-probability-distributions-bernoulli-and-binomial-distributions.html"><a href="discrete-probability-distributions-bernoulli-and-binomial-distributions.html#examples"><i class="fa fa-check"></i><b>5.3.3</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuous-probability-distributions-uniform-and-normal-distributions.html"><a href="continuous-probability-distributions-uniform-and-normal-distributions.html"><i class="fa fa-check"></i><b>5.4</b> Continuous probability distributions - uniform and normal distributions</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="continuous-probability-distributions-uniform-and-normal-distributions.html"><a href="continuous-probability-distributions-uniform-and-normal-distributions.html#uniform-probability-distribution"><i class="fa fa-check"></i><b>5.4.1</b> Uniform probability distribution</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuous-probability-distributions-uniform-and-normal-distributions.html"><a href="continuous-probability-distributions-uniform-and-normal-distributions.html#normal-probability-distribution"><i class="fa fa-check"></i><b>5.4.2</b> Normal probability distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="the-basics-of-statistical-inference-lecture-6-draft-copy-ver-0-1.html"><a href="the-basics-of-statistical-inference-lecture-6-draft-copy-ver-0-1.html"><i class="fa fa-check"></i><b>6</b> The basics of statistical inference [Lecture 6 - draft copy, ver. 0.1]</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistics-and-sampling-variability.html"><a href="statistics-and-sampling-variability.html"><i class="fa fa-check"></i><b>6.1</b> Statistics and sampling variability</a></li>
<li class="chapter" data-level="6.2" data-path="sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html"><a href="sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html"><i class="fa fa-check"></i><b>6.2</b> Sampling distribution for a statistic (a sample mean, a sample proportion etc.)</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html"><a href="sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html#sampling-distribution-of-a-sample-mean"><i class="fa fa-check"></i><b>6.2.1</b> Sampling distribution of a sample mean</a></li>
<li class="chapter" data-level="6.2.2" data-path="sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html"><a href="sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html#sampling-distribution-for-a-sample-sum-s"><i class="fa fa-check"></i><b>6.2.2</b> Sampling distribution for a sample sum (<span class="math inline">\(S\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="central-limit-theorem-clt.html"><a href="central-limit-theorem-clt.html"><i class="fa fa-check"></i><b>6.3</b> Central Limit Theorem (CLT)</a></li>
<li class="chapter" data-level="6.4" data-path="point-and-interval-estimation.html"><a href="point-and-interval-estimation.html"><i class="fa fa-check"></i><b>6.4</b> Point and interval estimation</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="point-and-interval-estimation.html"><a href="point-and-interval-estimation.html#point-estimation"><i class="fa fa-check"></i><b>6.4.1</b> Point estimation</a></li>
<li class="chapter" data-level="6.4.2" data-path="point-and-interval-estimation.html"><a href="point-and-interval-estimation.html#interval-estimation"><i class="fa fa-check"></i><b>6.4.2</b> Interval estimation</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 101 IPS (WSMiP UŁ)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="further-examples" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Further examples</h2>
<div id="example-1" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Example 1</h3>
<p>You arrive randomly between 1:30 and 1:45. What is the probability that you will arrive before 1:35? Obviously, the favourable length is 5 minutes, while the total length is 15 minutes. Hence,</p>
<p>Pr(you arrive before 1:35)=favourably length/total length=5/15=1/3.</p>
</div>
<div id="example-2" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Example 2</h3>
<p>You arrive randomly between 2:00 and 2:30. What is the probability that you arrive between 2:15 and 2:20? The favorable length is 5 minutes and the total length is 30 minutes. Hence,</p>
<p>Pr(you arrive between 2:15 and 2:20) = 1/6.</p>
<p>What is the probability you arrive at 2:15? It is zero, because 2:15 has length zero. In this model only intervals of time (lengths) have probability greater than zero.</p>
</div>
<div id="example-3" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Example 3</h3>
<p>A movie starts at 5:00, 5:15, and 5:30, and that you get to the movie theater at random between 5:00 and 5:30. What is the probability that you’ll have to wait 5 minutes or less before the movie starts? We can model the situation with a length of 30 and note that if you get there between 5:10 and 5:15 you will wait 5 minutes or less, and similarly if you get there between 5:25 and 5:30. So, the favourable length is 10 minutes, while the total length is 30 minutes. Hence,</p>
<p>Pr(you wait less then 5 minutes)=10/30, that is, 1/3.</p>
<blockquote>
<p><strong>Remark</strong>. Note that if what is picked is one-dimensional (a number, the time of arrival of one person, for example) then the model is one-dimensional, that is, a line. So, if the probability is uniformly distributed within an interval [a,b], then one models what is picked by a variable x such that a≤x≤b and determines the probability by dividing the favorable length by the total length. However, if what is picked is two-dimensional (two numbers, the time of meeting of two persons, for example), then the model is two-dimensional, that is a rectangle, for example. So, if the probability is uniformly distributed within two (possibly identical) intervals [a,b] and [c,d], then one models the event by two numbers x and y such that a≤x≤b and c≤y≤d, and the probability space by the rectangle abcd. The relevant probability is obtained by dividing the favorable area (typically obtained by determining the graph of an inequality) by the total area. More generally, an n-dimensional problem is modeled in an n-dimensional probability space.</p>
</blockquote>
<div id="sample-space" class="section level4" number="4.3.3.1">
<h4><span class="header-section-number">4.3.3.1</span> Sample space</h4>
<p>The set of all possible outcomes of a random experiment is called a <em>sample space</em>, we denote it by <span class="math inline">\(\Omega\)</span>. Its elements, or points, are called outcomes, they are denoted by <span class="math inline">\(\omega\)</span>. The result of the random experiment is always one point <span class="math inline">\(\omega\)</span> of <span class="math inline">\(\Omega\)</span>.</p>
<p>An event is a part of <span class="math inline">\(\Omega\)</span> (called a subset of <span class="math inline">\(\Omega\)</span>). It is often characterized by a certain condition (such as “two Heads are observed in three tosses” or “the bull’s-eye is hit”). Events are denoted by <span class="math inline">\(A,B,C,\)</span> etc. We say that an event <span class="math inline">\(A\)</span> occurs if the random experiment results in an outcome <span class="math inline">\(\omega\)</span> that belongs in <span class="math inline">\(A\)</span>. If <span class="math inline">\(\omega\)</span> happens to be outside of <span class="math inline">\(A\)</span>, the event <span class="math inline">\(A\)</span> does not occur. Each event has a probability, which is a number between 0 and 1. The probability of an event <span class="math inline">\(A\)</span> is denoted by <span class="math inline">\(P(A)\)</span>.<br />
</p>
<ol style="list-style-type: lower-alpha">
<li>The entire <span class="math inline">\(\Omega\)</span> is called a <em>certain</em> event. It always occurs because it contains every possible outcome <span class="math inline">\(\omega\)</span>. So, its probability is one: <span class="math inline">\(P(\Omega)=1\)</span>.<br />
</li>
<li>There is a special notation <span class="math inline">\(\emptyset\)</span> for the event that never occurs. It contains no outcomes. Its probability is zero, <span class="math inline">\(P(\emptyset)=0\)</span>. The event <span class="math inline">\(\emptyset\)</span> is said to be <em>impossible</em>. It is also called an empty set.<br />
</li>
<li>If <span class="math inline">\(A\)</span> is an event, then the rest of <span class="math inline">\(\Omega\)</span> is called the <em>complement</em> of <span class="math inline">\(A\)</span> and denoted by <span class="math inline">\(A^c\)</span>. If <span class="math inline">\(A\)</span> occurs, <span class="math inline">\(A^c\)</span> doesn’t, and vice versa. The probability of <span class="math inline">\(A^c\)</span> is given by <span class="math inline">\(P(A^c)=1-P(A)\)</span>.<br />
</li>
<li>If <span class="math inline">\(A\)</span> is a part of <span class="math inline">\(B\)</span>, we write <span class="math inline">\(A\subseteq B\)</span> (inclusion). This means that <span class="math inline">\(A\)</span> implies <span class="math inline">\(B\)</span> (i.e., if <span class="math inline">\(A\)</span> occurs, then <span class="math inline">\(B\)</span> also occurs). Then we have <span class="math inline">\(P(A)\leq P(B)\)</span>.<br />
</li>
<li>The common part of two events, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, is called their intersection, denoted by <span class="math inline">\(A\cap B\)</span>, or just <span class="math inline">\(AB\)</span>. It occurs whenever both <span class="math inline">\(A\)</span> <strong>and</strong> <span class="math inline">\(B\)</span> occur.<br />
</li>
<li>The event consisting of all the outcomes that are either in <span class="math inline">\(A\)</span> or in <span class="math inline">\(B\)</span> is called the union of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, denoted by <span class="math inline">\(A\cup B\)</span>. It occurs whenever <span class="math inline">\(A\)</span> <strong>or</strong> <span class="math inline">\(B\)</span> occurs.<br />
</li>
<li>If two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have no common part (no common outcomes; note that in this case <span class="math inline">\(A\cap B=\emptyset\)</span>), then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be disjoint, or mutually exclusive. They cannot occur simultaneously. In this case we have <span class="math inline">\(P(A\cup B)=P(A)+P(B)\)</span>.</li>
</ol>
</div>
</div>
<div id="conditional-probability-and-independence" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Conditional Probability and Independence</h3>
<p>A friend tosses a coin three times. You accidentally notice that the first time the coin shows Head. What is the chance that the friend observes 2 Heads?</p>
<p><em>Solution</em>. In a previous example, we found all eight possible outcomes. Now, with the additional information at our disposal, we can exclude the outcomes starting with a T. Only four possible outcomes remain: HHH, HHT, HTH, HTT. Two of them contain exactly two Heads. So, the chance is 2/4=1/2.</p>
<p>Note that here we have two events: <span class="math inline">\(A=\{\text{2 Heads are observed}\}\)</span> and <span class="math inline">\(B=\{\text{First toss is Heads}\}\)</span>. We know that <span class="math inline">\(P(A)=3/8\)</span>. Now, the event <span class="math inline">\(A\)</span> is considered under the condition that the event <span class="math inline">\(B\)</span> has occurred. Then the conditional probability of <span class="math inline">\(A\)</span>, given <span class="math inline">\(B\)</span>, is found by calculating the fraction of <span class="math inline">\(A\)</span> within <span class="math inline">\(B\)</span>, i.e. the fraction of <span class="math inline">\(A\cap B\)</span> within <span class="math inline">\(B\)</span>.<br />
</p>
<p><strong>Conditional probability</strong>. The conditional probability of an event <span class="math inline">\(A\)</span>, given an event <span class="math inline">\(B\)</span>, is <span class="math display">\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</span></p>
<div id="multiplication-rule" class="section level4" number="4.3.4.1">
<h4><span class="header-section-number">4.3.4.1</span> Multiplication rule</h4>
<p>The formula for conditional probability can be rewritten as <span class="math display">\[P(A\cap B)=P(B)\cdot P(A|B)\]</span> Due to the symmetry, one can rewrite this as <span class="math display">\[P(A\cap B)=P(A)\cdot P(B|A)\]</span></p>
<p>Example. A deck of 52 cards has 13 spades. If two cards are drawn from the deck at random, what is the chance that both are spades?</p>
<p><em>Solution</em>. Let <span class="math inline">\(A=\{\)</span>First card is a spade<span class="math inline">\(\}\)</span> and <span class="math inline">\(B=\{\)</span>Second card is a spade<span class="math inline">\(\}\)</span>. Clearly, <span class="math inline">\(P(A)=13/52=1/4\)</span>. If the first card is a spade, then the chance to draw another spade is 12/51 (the remaining deck of 51 cards has 12 spades left). This means that <span class="math inline">\(P(B|A)=12/51\)</span>. Hence, <span class="math display">\[P(A\cap B)=P(A)\cdot
P(B|A)=\frac 14\cdot\frac{12}{51}=\frac{12}{204}\]</span></p>
<p><strong>Extended multiplication rule</strong>. If <span class="math inline">\(A_1,A_2,\ldots,A_n\)</span> are events, then</p>
<p><span class="math display">\[P(A_1\cap A_2\cap\cdots\cap A_n)=P(A_1)\cdot P(A_2|A_1)\cdot
      P(A_3|A_1\cap A_2)\cdots P(A_n|A_1\cap\cdots\cap A_{n-1})\]</span></p>
<p><strong>Partition</strong>. Let <span class="math inline">\(B_1,\ldots,B_n\)</span> be disjoint (i.e., mutually exclusive) events; i.e. <span class="math inline">\(B_i\cap B_j=\emptyset\)</span>. Let <span class="math inline">\(\cup B_i=\Omega\)</span>, i.e. these events cover (exhaust) the entire probability space. We call <span class="math inline">\(\{B_1,\ldots, B_n\}\)</span> a <em>partition</em> of <span class="math inline">\(\Omega\)</span>.<br />
</p>
</div>
<div id="two-stage-experiments" class="section level4" number="4.3.4.2">
<h4><span class="header-section-number">4.3.4.2</span> Two-stage experiments</h4>
<p>Amanda rolls a die and then flips a coin the number of times shown on the die. What is the chance she observes two Heads?</p>
<p><em>Solution</em>: In the first stage, the die shows one of the six numbers <span class="math inline">\(1,\ldots,6\)</span>. These are six events, which we denote by <span class="math inline">\(B_1,\ldots,B_6\)</span>. They are disjoint and exhaust all the possibilities, so they make a partition. In the second stage, the event <span class="math inline">\(A=\{\)</span>Two Heads are observed<span class="math inline">\(\}\)</span> may (or may not) occur. Applying the law of total probability gives</p>
<p><span class="math display">\[\begin{aligned}
  P(A)&amp;=&amp;P(B_1)\cdot P(A|B_1)+\cdots +P(B_6)\cdot P(A|B_6)\\
      &amp;=&amp;\frac 16 \cdot 0 +\frac 16 \cdot \frac 14
        +\frac 16 \cdot \frac 38 +\frac 16 \cdot \frac {C_{4,2}}{2^4}
        +\frac 16 \cdot \frac{C_{5,2}}{2^5}+\frac 16 \cdot\frac{C_{6,2}}{2^6}
       =\frac{33}{128}\end{aligned}\]</span></p>
<p>Roll a die twice. If the first roll is a six, what is the chance the second roll will be a six?</p>
<p><em>Solution</em>. Let <span class="math inline">\(A=\{\)</span>The second roll is a six<span class="math inline">\(\}\)</span> and <span class="math inline">\(B=\{\)</span>The first roll is a six<span class="math inline">\(\}\)</span>. Then <span class="math display">\[P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{1/36}{1/6}=\frac 16\]</span></p>
<p>Note that <span class="math inline">\(P(A)=1/6\)</span>, so that</p>
<p><span class="math display">\[P(A|B)=P(A)\]</span></p>
<p>In other words, the probability of <span class="math inline">\(A\)</span> does not change when the event <span class="math inline">\(B\)</span> occurs, the event <span class="math inline">\(B\)</span> does not affect the chance of <span class="math inline">\(A\)</span> to occur.<br />
</p>
</div>
<div id="independent-events" class="section level4" number="4.3.4.3">
<h4><span class="header-section-number">4.3.4.3</span> Independent events</h4>
<p>Two events, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, are said to be <em>independent</em> if</p>
<p><span class="math display">\[P(A|B)=P(A)\]</span></p>
<p>By using 3.2, we can rewrite this equation as</p>
<p><span class="math display">\[P(A\cap B)=P(A)\, P(B)\]</span></p>
<p>and also as <span class="math display">\[P(B|A)=P(B)\]</span></p>
<p>All these three equations mean the same: the independence of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.<br />
</p>
<p>Note: The equation <span class="math inline">\(P(A\cap B)=P(A)P(B)\)</span> is better the other two: it is symmetric. It also works when <span class="math inline">\(P(A)=0\)</span> or <span class="math inline">\(P(B)=0\)</span>. So, it is preferred for practical purposes.<br />
</p>
<p>Example. Flip two coins. Let <span class="math inline">\(A=\{\)</span>First coin shows Head<span class="math inline">\(\}\)</span> and <span class="math inline">\(B=\{\)</span>Both coins show the same face<span class="math inline">\(\}\)</span>. Are <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> independent?</p>
<p><em>Solution</em>. One easily finds that <span class="math inline">\(P(A)=1/2\)</span>, <span class="math inline">\(P(B)=1/2\)</span> and <span class="math inline">\(P(A\cap B)=1/4\)</span>. Then we check that <span class="math inline">\(1/2\times 1/2=1/4\)</span>. Yes, they are independent.<br />
</p>
<p>Note: Sometimes the independence is obvious, like in 3.11 (because there is no way the result of the first roll can affect the second). Sometimes the independence is harder to recognize, as it is in 3.13 above. One can explain the independence in 3.13 noting that the second coin may or may not show the same face as the first with probability 1/2, no matter what face the first coin shows.<br />
</p>
<p><strong>Independence of three events</strong>. Three events <span class="math inline">\(A,B,C\)</span> are said to be mutually (or jointly) independent if<br />
</p>
<ol style="list-style-type: lower-alpha">
<li>any two of them are independent in the sense of 3.12, and<br />
</li>
<li>the following holds:</li>
</ol>
<p><span class="math display">\[P(A\cap B\cap C)=P(A)\, P(B)\, P(C)\]</span></p>
<p>Neither one of the conditions (a) and (b) alone is enough for joint independence. One needs to check both (a) and (b) to verify the joint independence of <span class="math inline">\(A,B,C\)</span>.<br />
</p>
</div>
</div>
<div id="law-of-total-probability" class="section level3" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Law of total probability</h3>
<p>Let <span class="math inline">\(\{B_1,\ldots, B_n\}\)</span> be a partition of <span class="math inline">\(\Omega\)</span>, and <span class="math inline">\(A\)</span> an event. Then</p>
<p><span class="math display">\[P(A)=P(B_1)\cdot P(A|B_1)+\cdots +P(B_n)\cdot P(A|B_n)\]</span></p>
<p>One can think of <span class="math inline">\(B_1,\ldots,B_n\)</span> as conditions under which the event <span class="math inline">\(A\)</span> may occur. The events <span class="math inline">\(B_1,\ldots,B_n\)</span> are also called <em>hypotheses</em>.<br />
</p>
<p>Example. Alex goes to school by bus or train, whichever comes first. He notice that the bus comes first with probability 30% and the train with probability 70%. When Alex takes train, he arrives late to school with probability 5%. When he takes bus, he is late to school with probability 20%. What is the probability that he is late to school?</p>
<p><em>Solution</em>. The event in question here is <span class="math inline">\(A=\{\)</span>Alex is late to school<span class="math inline">\(\}\)</span>. This may happen under two conditions (hypotheses): <span class="math inline">\(B_1=\{\)</span>Alex takes bus<span class="math inline">\(\}\)</span> and <span class="math inline">\(B_2=\{\)</span>Alex takes train<span class="math inline">\(\}\)</span>. Hence,</p>
<p><span class="math display">\[P(A)=P(B_1)\cdot P(A|B_1)+P(B_2)\cdot P(A|B_2)=0.3\times 0.2+0.7\times 0.05=0.095\]</span></p>
</div>
<div id="bayes-theorem" class="section level3" number="4.3.6">
<h3><span class="header-section-number">4.3.6</span> Bayes’ theorem</h3>
<p>Example. A rocket has a built-in redundant system. It has three components, <span class="math inline">\(K_1,K_2,K_3\)</span>. If component <span class="math inline">\(K_1\)</span> fails, it is bypassed and component <span class="math inline">\(K_2\)</span> is used, etc. So, as long as one component works the system is functioning. Suppose that the probabilities of failure of the components are 10%, 20% and 5%, respectively. Find the probability that the entire system works.</p>
<p><em>Solution</em>. First, note: <span class="math inline">\(P(\)</span>system works<span class="math inline">\()=1-P(\)</span>system fails<span class="math inline">\()\)</span>. The system fails if all the three components fail. The failures are mutually independent events, so</p>
<p><span class="math display">\[P({\rm system}\ {\rm fails})=0.1\cdot 0.2\cdot 0.05=0.001\]</span></p>
<p>So, the entire system will function with probability 99.9%. Note a very high reliability!<br />
</p>
<p>An additional note: it is more difficult to find the probability that two components fail. Because they can fail in various combinations: <span class="math inline">\(\{1,2\}\)</span>, <span class="math inline">\(\{1,3\}\)</span>, and <span class="math inline">\(\{2,3\}\)</span>. In each case the remaining component is assumed to work.</p>
<p>Therefore, the probability that two components fail is</p>
<p><span class="math display">\[\begin{aligned}
    P({\rm two}\ {\rm fail})&amp;=&amp;P(1,2\ {\rm fail})+P(1,3\ {\rm fail})+P(2,3\ {\rm fail})\\
    &amp;=&amp;0.1\cdot 0.2\cdot 0.95+0.1\cdot 0.8\cdot 0.05+0.9\cdot 0.2\cdot 0.05=0.032\end{aligned}\]</span></p>
<p>Remark. If <span class="math inline">\(A_1,\ldots,A_n\)</span> are independent, one can replace any number of these events by their complements (e.g., <span class="math inline">\(A_1\)</span> by <span class="math inline">\(A_1^c\)</span>, etc.) and the new collection of events will be also independent.<br />
</p>
<p><strong>Bayes formula</strong>. Recall the law of total probability in 3.8 and suppose we need to compute <span class="math inline">\(P(B_i|A)\)</span> for some <span class="math inline">\(i=1,\ldots,n\)</span>. By using the formulas in 3.2-3.3 we get</p>
<p><span class="math display">\[P(B_i|A)=\frac{P(B_i\cap A)}{P(A)}=\frac{P(B_i)\cdot P(A|B_i)}{P(A)}\]</span></p>
<p>Now we replace the denominator <span class="math inline">\(P(A)\)</span> by its expansion given by the law of total probability and obtain</p>
<p><span class="math display">\[P(B_i|A)=\frac{P(B_i)\cdot P(A|B_i)}{P(B_1)\cdot P(A|B_1)+\cdots +P(B_n)\cdot P(A|B_n)}\]</span></p>
<p>This is called <em>Bayes formula</em>. Note that the numerator here is one of the terms that appear in the denominator.</p>
</div>
<div id="various-examples" class="section level3" number="4.3.7">
<h3><span class="header-section-number">4.3.7</span> Various examples (*)</h3>
<div id="example-4" class="section level4" number="4.3.7.1">
<h4><span class="header-section-number">4.3.7.1</span> Example</h4>
<p>You roll a six-sided die. What is the probability of getting an even number?</p>
<p><strong>Solution.</strong> Since <span class="math inline">\(E = \{2, 4, 6\}\)</span>, <span class="math inline">\(S = \{1, 2, 3, 4, 5, 6\}\)</span>, then</p>
<p><span class="math display">\[P(E) = \frac{3}{6} = \frac{1}{2}\]</span></p>
</div>
<div id="example-5" class="section level4" number="4.3.7.2">
<h4><span class="header-section-number">4.3.7.2</span> Example</h4>
<p>You roll two fair dice numbered from 1 to 6. Find the probability of rolling 1 on the first die and 2 on the second one.</p>
<p><strong>Solution.</strong> Since <span class="math inline">\(E = \{(1, 2)\}\)</span> and <span class="math inline">\(S = \{(1, 1), (1, 2), (2, 1), ..., (6, 5), (6, 6)\}\)</span>, then <span class="math inline">\(P(X = (1, 2)) = \frac{1}{6} \times \frac{1}{6} = \frac{1}{36}\)</span></p>
<p>To find the total number of possible outcomes, you need to apply multiplication principle (the rule of product). <span class="math inline">\(n(S) = |S| = k_1 \times k_2 = 6 \times 6 = 36\)</span></p>
</div>
<div id="example-6" class="section level4" number="4.3.7.3">
<h4><span class="header-section-number">4.3.7.3</span> Example</h4>
<p>You roll a fair die. What is the probability of getting an even number? Solution. <span class="math inline">\(E = E_1 \cup E_2 \cup E_3\)</span>. You can see that events <span class="math inline">\(E_1, E_2, E_3\)</span> are disjoint, then <span class="math inline">\(P(E = E_1 \cup E_2 \cup E_3) = P(E_1) + P(E_2) + P(E_3) = \frac{3}{6}\)</span></p>
<p>You roll a fair die. What is the probability of getting an even number (<em>A</em>) <strong>and</strong> the number greater or equal to 4 (<em>B</em>)? Are events <em>A</em> and <em>B</em> independent?</p>
<p><strong>Solution</strong>. Let’s find the intersection of events <em>A</em> and <em>B</em>, <span class="math inline">\(A \cap B\)</span>. <span class="math inline">\(A = \{2, 4, 6\}, B = \{4, 5, 6\}\)</span>, then <span class="math inline">\(A \cap B = \{4, 6\}\)</span>. <span class="math display">\[P(A \cap B) = \frac{|A \cap B|}{|S|} = \frac{2}{6} = \frac{1}{3}\]</span></p>
<p>Also,</p>
<p><span class="math display">\[P(A) = \frac{|A|}{|S|} = \frac{3}{6} = \frac{1}{2}, P(B) = \frac{|B|}{|S|} = \frac{3}{6} = \frac{1}{2}\]</span></p>
<p>then,</p>
<p><span class="math display">\[P(A)P(B) = \frac{1}{2} \times \frac{1}{2} = \frac{1}{4}\]</span></p>
<p>We conclude that events <em>A</em> and <em>B</em> are <strong>dependent</strong>, on the basis of the test for independence: <span class="math display">\[P(A)P(B) \neq P(A \cap B)\]</span></p>
</div>
<div id="example-7" class="section level4" number="4.3.7.4">
<h4><span class="header-section-number">4.3.7.4</span> Example</h4>
<p>Roll two fair dice. What is the probability of getting the sum of the two dice equal 7 <strong>and</strong> an even number on the second die?</p>
<p>Let <span class="math inline">\(A = \{ (1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1) \}\)</span></p>
<p><span class="math display">\[P(A) = \frac{|A|}{|S|} = \frac{6}{36} = \frac{1}{6}\]</span> Let <span class="math inline">\(B = \{ (1, 6), (1, 4), (1, 2), (2, 6), (2, 4), ... \}\)</span></p>
<p>We can notice that, by product rule, we have <span class="math inline">\(|B| = 6 \times 3\)</span>, Thus,</p>
<p><span class="math display">\[P(B) = \frac{|B|}{|S|} = \frac{6 \times 3 = 18}{36} = \frac{1}{2}\]</span> Finally,</p>
<p><span class="math display">\[P(A \cap B) = \frac{|A \cap B|}{|S|} = \frac{3}{36} = \frac{1}{12}\]</span> Also,</p>
<p><span class="math display">\[P(A)P(B) = \frac{1}{6} \times \frac{1}{2} = \frac{1}{12}\]</span></p>
<p>Employing the test for independence of events:</p>
<p><span class="math display">\[P(A)P(B) = P(A \cap B)\]</span> - Events <em>A</em> and <em>B</em> are <strong>independent</strong>.</p>
</div>
<div id="example-8" class="section level4" number="4.3.7.5">
<h4><span class="header-section-number">4.3.7.5</span> Example</h4>
<p>You roll three fair dice. What is the probability of rolling a combination of the numbers 1, 3, 5?</p>
<p><strong>Solution.</strong> We need to answer two questions. “What are the odds of getting any particular combination, in order, on three dice?”. The second is “How many orderings are there of the numbers 1, 3, and 5?”.</p>
<p>The answer to the first question is that there is a 1 in 216 chance of getting a specific, particular ordering of results from three dice. For <span class="math inline">\((1,3,5)\)</span>, you have to get 1 on the first die (1 in 6 chance), 3 on the second (1 in 6 chance), and 5 on the third (1 in 6 chance). For <span class="math inline">\((3,1,5)\)</span>, the odds are the same. And so on.</p>
<p>The answer to the second question is that there are 6 possible orderings of three distinct digits: <span class="math inline">\((1,3,5), (1,5,3), (3,1,5), (3,5,1), (5,1,3), \text{and } (5,3,1)\)</span>. That’s because there are 3 possible choices for the first digit, 2 possible choices for the second digit, and 1 possible choice for the last digit.</p>
<p>Combining these two answers, we find that for each of the 6 possible orderings, there is a 1 in 216 chance of getting that specific result. Since each possibility is distinct, we can just add them together to get a 6 in 216 chance of getting the numbers <span class="math inline">\({1, 3, 5}\)</span> in some order on three dice.</p>
<p>Finally, the probability is <span class="math inline">\((1/6 \times 1/6 \times 1/6) \times (3 \times 2 \times 1)\)</span></p>
</div>
<div id="example-9" class="section level4" number="4.3.7.6">
<h4><span class="header-section-number">4.3.7.6</span> Example</h4>
<p>Three dice are thrown. What is the probability that the same number appears on exactly two of the three dice?</p>
<p><strong>Solution.</strong> Since you need exactly two to be the same, there are three possibilities: (1) First and second, not third, (2) First and third, not second, (3) Second and third, not first.</p>
<p>For the first possibility (1): The first die, you have probability of 6/6. The second die needs to be equal to the first, so you have probability of 1/6. Then the third die can’t be equal to the first and second die, so it’s 5/6. Finally you get <span class="math inline">\(1\times \frac{1}{6} \times \frac{5}{6}\)</span>. And <strong>since the next two possibilities (2) and (3) yield the same result</strong>, then the probability that the same number appears on exactly two of the three dice is</p>
<p><span class="math display">\[3 \times (1 \times \frac{1}{6} \times \frac{5}{6}) = \binom{3}{2}(1 \times \frac{1}{6} \times \frac{5}{6}) = \frac{5}{12}\]</span></p>

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="elementary-probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-variables-and-probability-distributions-lecture-5-draft-copy-ver-0-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
