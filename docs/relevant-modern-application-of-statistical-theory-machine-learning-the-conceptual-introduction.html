<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.13 Relevant modern application of statistical theory: Machine learning - the conceptual introduction | STAT 101 IPS</title>
  <meta name="description" content="2.13 Relevant modern application of statistical theory: Machine learning - the conceptual introduction | STAT 101 IPS" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="2.13 Relevant modern application of statistical theory: Machine learning - the conceptual introduction | STAT 101 IPS" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.13 Relevant modern application of statistical theory: Machine learning - the conceptual introduction | STAT 101 IPS" />
  
  
  

<meta name="author" content="Michał Pierzgalski" />


<meta name="date" content="2020-11-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="experimental-designlecture-7.html"/>

<script src="assets/header-attrs-2.5/header-attrs.js"></script>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="assets/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="assets/anchor-sections-1.0/anchor-sections.js"></script>
<script src="assets/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<script src="assets/viz-1.8.2/viz.js"></script>
<link href="assets/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="assets/grViz-binding-1.0.6.1/grViz.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Course description</a>
<ul>
<li class="chapter" data-level="" data-path="contact.html"><a href="contact.html"><i class="fa fa-check"></i>Contact</a>
<ul>
<li class="chapter" data-level="" data-path="contact.html"><a href="contact.html#office-hours-20202021"><i class="fa fa-check"></i>Office hours (2020/2021)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-lecture-1.html"><a href="introduction-lecture-1.html"><i class="fa fa-check"></i><b>1</b> Introduction [Lecture 1]</a>
<ul>
<li class="chapter" data-level="1.1" data-path="motivation-two-reasons-why-you-should-learn-statistics-and-data-analysis-methods.html"><a href="motivation-two-reasons-why-you-should-learn-statistics-and-data-analysis-methods.html"><i class="fa fa-check"></i><b>1.1</b> Motivation - two reasons why you should learn statistics and data analysis methods?</a></li>
<li class="chapter" data-level="1.2" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><i class="fa fa-check"></i><b>1.2</b> Review of some mathematical concepts used in statistics and data science</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#algebra-review---some-basic-rules"><i class="fa fa-check"></i><b>1.2.1</b> Algebra review - some basic rules</a></li>
<li class="chapter" data-level="1.2.2" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#functions"><i class="fa fa-check"></i><b>1.2.2</b> Functions</a></li>
<li class="chapter" data-level="1.2.3" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#sets"><i class="fa fa-check"></i><b>1.2.3</b> Sets</a></li>
<li class="chapter" data-level="1.2.4" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#three-basic-concepts-of-calculus"><i class="fa fa-check"></i><b>1.2.4</b> Three basic concepts of calculus</a></li>
<li class="chapter" data-level="1.2.5" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#limits"><i class="fa fa-check"></i><b>1.2.5</b> Limits</a></li>
<li class="chapter" data-level="1.2.6" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#derivative"><i class="fa fa-check"></i><b>1.2.6</b> Derivative</a></li>
<li class="chapter" data-level="1.2.7" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#integral"><i class="fa fa-check"></i><b>1.2.7</b> Integral</a></li>
<li class="chapter" data-level="1.2.8" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#integral-as-an-area---intuitive-explanation"><i class="fa fa-check"></i><b>1.2.8</b> Integral as an area - intuitive explanation</a></li>
<li class="chapter" data-level="1.2.9" data-path="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html"><a href="review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html#probability"><i class="fa fa-check"></i><b>1.2.9</b> Probability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistics-an-introduction-lecture-2.html"><a href="statistics-an-introduction-lecture-2.html"><i class="fa fa-check"></i><b>2</b> Statistics - an introduction [Lecture 2]</a>
<ul>
<li class="chapter" data-level="2.1" data-path="essential-concepts.html"><a href="essential-concepts.html"><i class="fa fa-check"></i><b>2.1</b> Essential concepts</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="essential-concepts.html"><a href="essential-concepts.html#a-parameter-and-a-statistic"><i class="fa fa-check"></i><b>2.1.1</b> A parameter and a statistic</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="constructs-and-operational-definitionslecture-1.html"><a href="constructs-and-operational-definitionslecture-1.html"><i class="fa fa-check"></i><b>2.2</b> Constructs and operational definitions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="constructs-and-operational-definitionslecture-1.html"><a href="constructs-and-operational-definitionslecture-1.html#conceptualisation-and-operationalisation"><i class="fa fa-check"></i><b>2.2.1</b> Conceptualisation and operationalisation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-collection.html"><a href="data-collection.html"><i class="fa fa-check"></i><b>2.3</b> Data collection</a></li>
<li class="chapter" data-level="2.4" data-path="sampling-techniqueslecture-2.html"><a href="sampling-techniqueslecture-2.html"><i class="fa fa-check"></i><b>2.4</b> Sampling techniques</a></li>
<li class="chapter" data-level="2.5" data-path="data-distribution.html"><a href="data-distribution.html"><i class="fa fa-check"></i><b>2.5</b> Data distribution</a></li>
<li class="chapter" data-level="2.6" data-path="basic-stages-of-social-researchlecture-3.html"><a href="basic-stages-of-social-researchlecture-3.html"><i class="fa fa-check"></i><b>2.6</b> Basic stages of social research</a></li>
<li class="chapter" data-level="2.7" data-path="statistical-study-essential-steps.html"><a href="statistical-study-essential-steps.html"><i class="fa fa-check"></i><b>2.7</b> Statistical study - essential steps</a></li>
<li class="chapter" data-level="2.8" data-path="experimental-and-observational-studieslecture-4.html"><a href="experimental-and-observational-studieslecture-4.html"><i class="fa fa-check"></i><b>2.8</b> Experimental and observational studies</a></li>
<li class="chapter" data-level="2.9" data-path="statistical-research-design-an-example-of-a-simple-experimentlecture-5.html"><a href="statistical-research-design-an-example-of-a-simple-experimentlecture-5.html"><i class="fa fa-check"></i><b>2.9</b> Statistical research design - an example of a simple experiment</a></li>
<li class="chapter" data-level="2.10" data-path="descriptive-and-inferential-statistics.html"><a href="descriptive-and-inferential-statistics.html"><i class="fa fa-check"></i><b>2.10</b> Descriptive and inferential statistics</a></li>
<li class="chapter" data-level="2.11" data-path="random-samplinglecture-6.html"><a href="random-samplinglecture-6.html"><i class="fa fa-check"></i><b>2.11</b> Random sampling</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="random-samplinglecture-6.html"><a href="random-samplinglecture-6.html#sampling-errors-and-systematic-bias"><i class="fa fa-check"></i><b>2.11.1</b> Sampling errors and systematic bias</a></li>
<li class="chapter" data-level="2.11.2" data-path="random-samplinglecture-6.html"><a href="random-samplinglecture-6.html#various-types-of-bias-in-statistical-analysis"><i class="fa fa-check"></i><b>2.11.2</b> Various types of bias in statistical analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="experimental-designlecture-7.html"><a href="experimental-designlecture-7.html"><i class="fa fa-check"></i><b>2.12</b> Experimental design</a></li>
<li class="chapter" data-level="2.13" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><i class="fa fa-check"></i><b>2.13</b> Relevant modern application of statistical theory: Machine learning - the conceptual introduction</a>
<ul>
<li class="chapter" data-level="2.13.1" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#machine-learning-approaches"><i class="fa fa-check"></i><b>2.13.1</b> Machine learning approaches</a></li>
<li class="chapter" data-level="2.13.2" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#make-predictions-or-decisions-using-ml"><i class="fa fa-check"></i><b>2.13.2</b> Make predictions or decisions using ML</a></li>
<li class="chapter" data-level="2.13.3" data-path="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html"><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#machine-learning-approaches---visual-guide"><i class="fa fa-check"></i><b>2.13.3</b> Machine learning approaches - visual guide</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 101 IPS</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="relevant-modern-application-of-statistical-theory-machine-learning---the-conceptual-introduction" class="section level2" number="2.13">
<h2><span class="header-section-number">2.13</span> Relevant modern application of statistical theory: Machine learning - the conceptual introduction</h2>
<p><strong>Definitions</strong></p>
<p>Machine learning (ML) is a sub-field of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.</p>
<p>Machine learning algorithms build a mathematical model based on sample data, known as “training data”, in order to <strong>make predictions or decisions</strong> without being explicitly programmed to do so.</p>
<p><strong>Basic concepts used in Machine Learning</strong>:</p>
<ul>
<li>Algorithm: A Machine Learning algorithm is a set of rules and statistical techniques used to learn patterns from data and draw significant information from it. It is the logic behind a Machine Learning model. An example of a Machine Learning algorithm is the Linear Regression algorithm.</li>
<li>Model: A model is the main component of Machine Learning. A model is trained by using a Machine Learning Algorithm. An algorithm maps all the decisions that a model is supposed to take based on the given input, in order to get the correct output.</li>
<li>Predictor Variable: It is a feature(s) of the data that can be used to predict the output.</li>
<li>Response Variable: It is the feature or the output variable that needs to be predicted by using the predictor variable(s).</li>
<li>Training Data: The Machine Learning model is built using the training data. The training data helps the model to identify key trends and patterns essential to predict the output.</li>
<li>Testing Data: After the model is trained, it must be tested to evaluate how accurately it can predict an outcome. This is done by the testing data set.</li>
</ul>
<div id="machine-learning-approaches" class="section level3" number="2.13.1">
<h3><span class="header-section-number">2.13.1</span> Machine learning approaches</h3>
<div id="htmlwidget-64d80f24e51836c4cbad" style="width:672px;height:200px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-64d80f24e51836c4cbad">{"x":{"diagram":"digraph {\n  graph [layout = dot, rankdir = TB]\n  \n  node [shape = rectangle]        \n  rec1 [label = \"Step 1. Machine learning\"]\n  rec2 [label = \"Step 2. Supervised learning\"]\n  rec3 [label = \"Step 3. Unsupervised learning\"]\n  rec4 [label = \"Step 4. Reinforced learning\"]\n  \n  # edge definitions with the node IDs\n  rec1 -> {rec2, rec3, rec4}\n  }","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p>[From <em>Wikipedia.org</em>:]</p>
<ul>
<li>Supervised learning: The computer is presented with example inputs and their desired outputs, given by a “teacher”, and the goal is to learn a general rule that maps inputs to outputs.</li>
<li>Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).</li>
<li>Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that’s analogous to rewards, which it tries to maximize.</li>
</ul>
<p>“For the process of learning (model fitting) we need to have available some observations or data (also known as samples or examples) in order to explore potential underlying patterns, hidden in our data. These learned patterns are nothing more that some functions or decision boundaries.”</p>
</div>
<div id="make-predictions-or-decisions-using-ml" class="section level3" number="2.13.2">
<h3><span class="header-section-number">2.13.2</span> Make predictions or decisions using ML</h3>
<p>In science and technology, predictions or decisions are made using formal models. A very simple mathematical deterministic model can be:</p>
<p><span class="math display">\[F = \frac{9}{5}(C) + 32\]</span></p>
<p>which you could use to convert degrees Celsius to degrees Fahrenheit. For example:</p>
<p><span class="math display">\[F = \frac{9}{5}(39) + 32 = 70.2 + 32 = 102.2\]</span></p>
<p>You might be familiar with the formula for a line using the slope and y-intercept (recall the equation of linear function - <span class="math inline">\(y = ax + b\)</span>):</p>
<p><span class="math inline">\(y\)</span> = predicted value (dependent variable); <span class="math inline">\(a\)</span> = slope, i.e. <span class="math inline">\(\frac{\text{change in }y}{\text{change in }x}\)</span>; <span class="math inline">\(b\)</span> = intercept with <span class="math inline">\(x-\)</span>axis.</p>
<p>However, in statistics, we rarely deal with deterministic models which will produce perfect prediction. We have stochastic models which will have unexplained (“random”) error.</p>
<p>If you have an equation that tries to predict what the adult height of a newborn baby boy based on the height of his father. You will certainly not get a perfect prediction for many reasons. A mathematical version of a simple <strong>linear regression model</strong>, which is stochastic, would be:</p>
<p><span class="math display">\[y = \beta_0 + x_1\beta_1 + ... + x_k\beta_k + \epsilon\]</span></p>
<p>This denotes that we believe that there is a linear relationship between predictor variables <span class="math inline">\(x_k\)</span> and response variable <span class="math inline">\(y\)</span> with some unexplained error <span class="math inline">\(\epsilon\)</span>.</p>
</div>
<div id="machine-learning-approaches---visual-guide" class="section level3" number="2.13.3">
<h3><span class="header-section-number">2.13.3</span> Machine learning approaches - visual guide</h3>
<p>The following figures give general idea on how machine learning works<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>:</p>
<div class="figure">
<img src="images/ml/1__YfYURermogYfTxYUEhXNA.jpeg" title="Supervised learning" alt="" />
<p class="caption">Supervised learning</p>
</div>
<div class="figure">
<img src="images/ml/1_f3xba3IZ-8vwsyzhoTlpzw.jpeg" title="Unsupervised learning" alt="" />
<p class="caption">Unsupervised learning</p>
</div>
<div class="figure">
<img src="images/ml/1_e2CL8Al7syAh-Mc5OaMHwQ.jpeg" title="Reinforcement learning" alt="" />
<p class="caption">Reinforcement learning</p>
</div>
<div id="supervised-learning---examplelecture-9" class="section level4" number="2.13.3.1">
<h4><span class="header-section-number">2.13.3.1</span> Supervised learning - example<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></h4>
<p>We seek to teach a computer to predict housing prices. We begin with giving our computer the prices of other houses in the area, as well as information about each house (e.g. the size, number of bedrooms, number of floors). This data are called the <strong>training set</strong>. Also, the data provided for any one of the given houses is called a training example - this is denoted by <span class="math inline">\(x^{(i)}\)</span>, meaning data pertaining to house (i), while <span class="math inline">\(x^{(2)}\)</span> = training example (2). Each distinct bit of information contained within a training example is called a <strong>feature</strong>. In data representing housing attributes, the size of the house is a feature, as would the number of stories and the number of bedrooms. Every training example contains the same features in the same order.</p>
<p>Features are denoted with <span class="math inline">\(j\)</span>. That is: <span class="math inline">\(x^{(i)}_j\)</span> is a feature <span class="math inline">\(j\)</span> for an example <span class="math inline">\(i\)</span>.</p>
<p>Linear regression is one of the most basic machine learning models. Symbolically, this is a common representation of the linear regression model:</p>
<p><span class="math display">\[h_{\theta}(x) = \theta_0 + \theta_1 x\]</span></p>
<p><span class="math inline">\(h_{\theta}(x)\)</span></p>
<p>represents the hypothesis function (hypothesis). It says that the outputted value varies based on the input <span class="math inline">\(x\)</span> That is to say, based on the value <span class="math inline">\(x\)</span> between parentheses, the prediction is made, meaning that <span class="math inline">\(h_{\theta}(x^{(i)})\)</span> symbolizes the prediction made by the hypothesis on example <span class="math inline">\(x^{(i)}\)</span>. The <span class="math inline">\(\theta\)</span> symbols are known as parameters - can be positive or negative numbers. Also, theta zero represents a <strong>bias unit</strong>.</p>
<p>“Let’s go back to our housing prices example. Let’s pretend we’re using training example 1. Our example will use only one feature for this explanation: the size of the house in square feet. This will be represented by <span class="math inline">\(x^{(1)}_1\)</span>, meaning feature 1 of training example 1, and will be equal to 2,500 (square feet).”</p>
<p>"Let’s say our hypothesis believes that each square foot adds $50 of value to the home and that housing prices start at $200,000 in the area. <span class="math inline">\(\theta_0\)</span> would then have a value of 200,000 and <span class="math inline">\(\theta_1\)</span> would then be 50. Let’s check out why that is.</p>
<p>We know that a prediction is formed by summing the bias unit with the product of features and their respective parameters. When we multiply our <span class="math inline">\(x^{(1)}_1\)</span> (2,500 square feet) by our <span class="math inline">\(\theta_1\)</span> (the associated parameter of $50/square feet), we get a value of $125,000. Through this multiplication, for every square foot (<span class="math inline">\(x^{(1)}_1\)</span>), $50 dollars of value (<span class="math inline">\(\theta_1\)</span>) is added. We add that product to our bias unit of $200,000 (<span class="math inline">\(\theta_0\)</span> representing the average local starting housing price) to get a final output value of $325,000!"</p>

</div>
</div>
</div>
<!-- </div> -->























<div class="footnotes">
<hr />
<ol start="17">
<li id="fn17"><p>Retrieved from: Loukas, S. What is Machine Learning: Supervised, Unsupervised, Semi-Supervised and Reinforcement learning methods. <a href="https://towardsdatascience.com/what-is-machine-learning-a-short-note-on-supervised-unsupervised-semi-supervised-and-aed1573ae9bb" class="uri">https://towardsdatascience.com/what-is-machine-learning-a-short-note-on-supervised-unsupervised-semi-supervised-and-aed1573ae9bb</a><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Based on: Nolan, F. A Comprehensive Introductory Guide to Supervised Learning for the Non-Mathematician. <a href="https://towardsdatascience.com/an-involved-introduction-to-supervised-learning-for-the-common-human-6338d9559748" class="uri">https://towardsdatascience.com/an-involved-introduction-to-supervised-learning-for-the-common-human-6338d9559748</a><a href="relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html#fnref18" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="experimental-designlecture-7.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
