[["index.html", "STAT 101 IPS (WSMiP UŁ) Lecture notes [DRAFT: Do not copy, cite, or distribute without permission.] Course description", " STAT 101 IPS (WSMiP UŁ) Lecture notes [DRAFT: Do not copy, cite, or distribute without permission.] Michał Pierzgalski 2021-01-27 Course description Before you start reading, please look into the detailed syllabus: STAT101 "],["contact.html", "Contact", " Contact Email: michal.pierzgalski@uni.lodz.pl Personal website: https://pierzgal.github.io/michalpierzgalski/ Office hours (2020/2021) By appointment (via MS Teams); please, arrange the day and time via an official email address. IMPORTANT! Students, please contact me only via e-mail in the domain @uni.lodz.pl and @edu.uni.lodz.pl. In the email subject, please reference the course name, major, minor, etc. Students in contact with employees of the University of Lodz are required to use addresses in the domains of the University of Lodz and correspondence on the line student - teacher can only be conducted via these e-mail addresses. I reply to emails from students only on Fridays and Mondays or during my office hours. "],["introduction-lecture-1.html", "1 Introduction [Lecture 1]", " 1 Introduction [Lecture 1] Statistics is the discipline that concerns the collection, organization, analysis, interpretation and presentation of data. "],["motivation-two-reasons-why-you-should-learn-statistics-and-data-analysis-methods.html", "1.1 Motivation - two reasons why you should learn statistics and data analysis methods?", " 1.1 Motivation - two reasons why you should learn statistics and data analysis methods? In social research (political science, sociology, psychology or economics), statistical methods are used to find answers to research questions or to test research hypotheses. Statistics is a basic research tool for social scientists. Statistics and related disciplines such as Data Science or Machine Learning allow us to better understand modern technologies (such as Computational photography, Google’s Spam Filter, Self-driving cars) that not only make our lives easier, but also have an impact on politics and current society (e.g. the so-called microtargeting 1 - it “is a form of targeting that uses recent technological developments to gather large amounts of online data. The data from people’s digital footprint’s analyzed to create and convey messages that reflect an individual’s preferences and personality” (Wikipedia). Microtargeting (via social media like Facebook) can be used e.g. in election campaigns. Zob. np. Mikrotargetowanie i datakracja: https://wszystkoconajwazniejsze.pl/jan-sliwa-mikrotargetowanie-i-datakracja/↩︎ "],["review-of-some-mathematical-concepts-used-in-statistics-and-data-science.html", "1.2 Review of some mathematical concepts used in statistics and data science", " 1.2 Review of some mathematical concepts used in statistics and data science 1.2.1 Algebra review - some basic rules 1.2.1.1 Identity There are equalities of two different types: equations and identities. An equality \\(=\\) is not the same as identity \\(\\equiv\\). The \\(\\equiv\\) symbol originally meant “is identically equal to”. An identity is a type of equality which is true for all values, e.g.: \\((a+b)^2 \\equiv a^2+2ab+b^2.\\) 1.2.1.2 Differences - Delta notation The Greek letter \\(\\Delta\\) (capital delta) is the symbol used to indicate the difference in a measured quantity, usually at two different times. 1.2.1.3 Summation - Sigma notation In physics there are often contexts in which it’s necessary to add several quantities. A useful abbreviation for representing such a sum is the Greek letter \\(\\Sigma\\) (capital sigma). Suppose we wish to add a set of five numbers represented by \\(x1, x2, x3, x4, x5\\). In the abbreviated notation, we would write the sum as \\(x1 + x2 + x3 + x4 + x5 = \\sum_{i=1}^{5} x_i\\) where the subscript i on x represents any one of the numbers in the set. For example, if there are five masses in a system, \\(m1, m2, m3, m4, m5\\), the total mass of the system \\(M = m1 + m2 + m3 + m4 + m5\\) could be expressed as \\(M = \\sum_{i=1}^{5} m_i\\) 1.2.1.4 Absolute value The magnitude of a quantity x, written x, is simply the absolute value of that quantity. The sign of x is always positive, regardless of the sign of x. For example, if x = -5, then |x| = 5; if x = 8, then |x| = 8. 1.2.1.5 Basic algebraic operations When algebraic operations are performed, the laws of arithmetic apply. Symbols such as x, y, and z are usually used to represent unspecified quantities, called the unknowns (or variables). First, consider the equation \\(8x = 32\\) If we wish to solve for x, we can divide (or multiply) each side of the equation by the same factor without destroying the equality. In this case, if we divide both sides by 8, we have \\(\\frac{8x}{8} = \\frac{32}{8}\\) \\(x = 4\\) Also, consider the equation \\(x + 2 = 8\\) In this type of expression, we can add or subtract the same quantity from each side. If we subtract 2 from each side, we have \\(x + 2 - 2 = 8 - 2\\) \\(x = 6\\) Now, consider the equation \\(\\frac{x}{5} = 9\\) If we multiply each side by 5, \\((\\frac{x}{5}) \\times 5 = 9 \\times 5\\) \\(x = 45\\) In all cases, whatever operation is performed on the left side of the equality must also be performed on the right side. 1.2.1.6 Some useful arithmetic rules Należy przypomnieć następujące zasady mnożenia, dzielenia, dodawania i odejmowania ułamków, gdzie a, b, c i d to cztery liczby: Rule Example Multiplying \\((\\frac{a}{b})(\\frac{c}{d}) = \\frac{ac}{bd}\\) Dividing \\((\\frac{a/b}{c/d}) = \\frac{ad}{bc}\\) Adding \\((\\frac{a}{b}) \\pm (\\frac{c}{d}) = \\frac{ad \\pm bc}{bd}\\) 1.2.1.7 Powers The following rules apply: \\(x^nx^m = x^{n+m}\\) \\(\\frac{x^n}{x^m} = x^{n-m}\\) \\(x^{\\frac{1}{n}} = \\sqrt[n]{x}\\) \\((x^n)^m = x^{nm}\\) 1.2.1.8 Logarithms Suppose a quantity x is expressed as a power of some quantity a: \\(x = a^y\\) The number a is called the base number. The logarithm of x with respect to the base a is equal to the exponent to which the base must be raised to satisfy the expression \\(x = a^y\\): \\(y = \\log_a x\\) In practice, the two bases most often used are base 10, called the common logarithm base, and base \\(e = 2.718 282\\), called Euler’s constant or the natural logarithm base. For any base: \\(\\log{(ab)} = \\log a + \\log b\\) \\(\\log{a/b} = \\log a + \\log b\\) \\(\\log{a^n} = n \\log a\\) Also, \\(\\ln e\\) \\(\\ln e^a = a\\) \\(\\ln(1/a) = -\\ln a\\) 1.2.1.9 Factoring Some useful formulas for factoring an equation are the following: \\(ax + ay + az = a(x + y + z)\\) \\(a^2 + 2ab + b^2 = (a + b)^2\\) - so called “perfect square” \\(a^2 + b^2 = (a + b)(a - b)\\) 1.2.1.10 Linear equations A linear equation has the general form \\(y = mx + b\\) where m and b are constants. This equation is referred to as linear because the graph of y versus x is a straight line. The constant b, called the y-intercept, represents the value of y at which the straight line intersects the y axis. The constant m is equal to the slope of the straight line. If any two points on the straight line are specified by the coordinates (x1, y1) and (x2, y2), the slope of the straight line can be expressed as \\(Slope = \\frac{y_2 - y_1}{x_2 - x_1} = \\frac{\\Delta{y}}{\\Delta{x}}\\) Note that m and b can have either positive or negative values. If \\(m &gt; 0\\), the straight line has a positive slope. If \\(m &lt; 0\\), the straight line has a negative slope. Solving Simultaneous Linear Equations Consider the equation \\(3x + 5y = 15\\), which has two unknowns, x and y. Such an equation does not have a unique solution. For example, \\((x = 0, y = 3)\\), \\((x = 5, y = 0)\\), and (\\(x = 2, y = \\frac{9}{5}\\)) are all solutions to this equation. If a problem has two unknowns (variables), a unique solution is possible only if we have two equations. In general, if a problem has n unknowns, its solution requires n equations. To solve two simultaneous equations involving two unknowns, x and y, we solve one of the equations for x in terms of y and substitute this expression into the other equation. 1.2.2 Functions A function from a set A to another set B is an assignment of some element of B to each element in A. A function is a rule that assigns each input exactly one output. We call the output the image of the input. The set of all inputs for a function is called the domain. The set of all allowable outputs is called the codomain. In mathematics, a function is a binary relation between two sets that associates every element of the first set to exactly one element of the second set. Figure 1.1. Function2 Figure 1.2. Function3 A mathematical model is an abstract concept through which we use mathematical language and notation to describe a phenomenon in the world around us. Models describe our beliefs about how the world functions. In mathematical modelling, we translate those beliefs into the language of mathematics. A function can serve as a simple kind of mathematical model. Remember that a function is just a rule, f, that expresses the dependency of one variable quantity, y, on another variable quantity, x. We can think of the rule (given as a graph, a formula, or a table of values) as a representation of some natural cause and effect relationship – if x, then y – between the two variable quantities. For a mathematical model, we often seek an algebraic formula that captures observed behavior accurately and can be used to predict behavior not yet observed. 1.2.3 Three basic concepts of calculus Limit of function; Derivative; Integral. 1.2.4 Limits In mathematics, a limit is the value that a function (or sequence) “approaches” as the input (or index) “approaches” some value. Limits are essential to calculus and mathematical analysis, and are used to define e.g. derivatives, and integrals. For \\(f(x)\\), we have \\[\\lim_{x \\rightarrow c}f(x)=L\\] For example, \\[\\lim_{x \\rightarrow 0}\\frac{1}{x}=\\infty\\] or, \\[\\lim_{x \\rightarrow \\infty}\\frac{1}{x}=0\\] In formulas, a limit of a function is usually written as \\[\\lim_{x \\to c}f(x)=L\\] and is read as “the limit of f of x as x approaches c equals L”. The fact that a function f approaches the limit L as x approaches c is usually denoted by a right arrow \\(\\to\\), as in: \\[f(x)\\to L{\\text{ as }}x\\to c\\] which reads \\(f(x)\\) tends to \\(L\\) as \\(x\\) tends to \\(c\\). Figure 1.3. Limits4 1.2.5 Derivative First, a function must be specified that relates one variable to another (e.g., a coordinate as a function of time). Suppose one of the variables is called y (the dependent variable), and the other x (the independent variable). We might have a function relationship such as \\(y(x) = ax^2 + bx + c\\) If a, b, and c are specified constants, y can be calculated for any value of x. We usually deal with continuous functions, that is, those for which y varies “smoothly” with x. The derivative of y with respect to x is defined as the limit as \\(\\Delta x\\) approaches zero of the slopes of chords drawn between two points on the y versus x curve. Mathematically, we write this definition as \\[\\frac{dy}{dx} = \\lim_{\\Delta x \\to\\ 0} \\frac{\\Delta y}{\\Delta x} = \\lim_{\\Delta x \\to\\ 0} \\frac{y(x + \\Delta x) - y(x)}{\\Delta x}\\] where \\(\\Delta y = y_2 - y_1\\) and \\(\\Delta x = x_2 - x_1\\). Note that \\(dy/dx\\) does not mean \\(dy\\) divided by \\(dx\\), but rather is simply a notation of the limiting process of the derivative (differentiation operator). A useful expression to remember when \\(y = ax^n\\), where a is a constant and n is any positive or negative number (integer or fraction), is \\(\\frac{dy}{dx} = nax^{n-1}\\) Figure 1.4. Derivative - visual representation5 1.2.6 Integral We think of integration as the inverse of differentiation. As an example, consider the expression 1.1 \\(f(x) = \\frac{dy}{dx} = 3ax^2 + b\\) which was the result of differentiating the function 1.2 \\(y(x) = ax^3 = bx + c\\) We can write equation 1.1 as \\(dy = f(x)dx = (3ax^2 + b)dx\\) and obtain \\(y(x)\\) by “summing” over all values of x. Mathematically, we write this inverse operation as \\[y(x) = \\int f(x) dx\\] \\[ y(x) = \\int (3az^2 + b)dx = ax^3 + bx + c\\] where c is a constant of the integration. This type of integral is called an indefinite integral because its value depends on the choice of c. 1.2.7 Integral as an area - intuitive explanation For a general continuous function f(x), the integral can be described as the area under the curve bounded by f(x) and the x axis, between two specified values of x, say, \\(x1\\) and \\(x2\\), as in the Figure 1.5. The area of the blue element in Figure 1.5 is approximately \\(f(x_i) \\Delta x_i\\). If we sum all these area elements between \\(x1\\) and \\(x2\\) and take the limit of this sum as \\(\\Delta x_i \\to 0\\), we obtain the true area under the curve bounded by f(x) and the x axis, between the limits \\(x1\\) and \\(x2\\): \\[Area = \\lim_{\\Delta x_i \\to\\ 0} \\sum_i f(x_i)\\Delta x_i = \\int_{x_1}^{x_2} f(x)dx\\] Integrals of this type are called definite integrals. Figure 1.5. Definite integral as an area under a curve6 Figure 1.6. Definite integral as an area under a curve7 Figure 1.7. Definite integral as an area under a curve8 1.2.7.1 Summary Figure 1.8. Summary of basic calulus concepts9 Retrieved from: Sets and Functions. https://mathigon.org/course/sets-and-functions/function-properties↩︎ Retrieved from: Loup Vaillant. http://loup-vaillant.fr/tutorials/from-imperative-to-functional↩︎ Retrieved from: Math24. https://www.math24.net/definition-limit-function/↩︎ Retrieved from: Wikimedia. https://commons.wikimedia.org/wiki/File:Derivative_-_geometric_meaning.svg↩︎ Retrieved from: Serway, R. A., &amp; Jewett, J. W. (2018). Physics for scientists and engineers with modern physics. Cengage learning.↩︎ Retrieved from: Active Calculus. https://activecalculus.org/single/sec-4-3-definite-integral.html↩︎ Retrieved from: Active Calculus. https://activecalculus.org/single/sec-4-3-definite-integral.html↩︎ Retrieved from: Derivatives on Unequally Spaced Grids. http://cococubed.asu.edu/code_pages/fdcoef.shtml↩︎ "],["statistics-an-introduction-lecture-2.html", "2 Statistics - an introduction [Lecture 2]", " 2 Statistics - an introduction [Lecture 2] Statistics is the science of learning from data. Statistics deals with every aspect of data, including the planning of data collection in terms of the design of surveys or experiments. "],["essential-concepts.html", "2.1 Essential concepts", " 2.1 Essential concepts Data refers to a set of values, which are usually organized by variables (what is being measured) and observational units (members of the sample/population). An example of data is a data matrix in a spreadsheet program, such as Google Sheets. A collection of observations on one or more variables. Variable: A characteristic whose value may change from one observation to another. When we want to talk about the influence of a factor on a characteristic of interest, we identify the factor (a variable) as the independent variable (often called a predictor or explanatory variable) and the affected variable as the dependent variable (often called the response variable). Population: The entire collection of individuals or objects about which information is desired is called the population of interest. Sample: A sample is a subset of the population, selected for study. 2.1.1 A parameter and a statistic A parameter is a value, usually a numerical value, that describes a population. A parameter is usually derived from measurements of the individuals in the population. A statistic is a value, usually a numerical value, that describes a sample. A statistic is usually derived from measurements of the individuals in the sample. "],["constructs-and-operational-definitionslecture-21.html", "2.2 Constructs and operational definitions10", " 2.2 Constructs and operational definitions10 “Some variables, such as height, weight, and eye color are well-defined, concrete entities that can be observed and measured directly. On the other hand, many variables studied by behavioral scientists are internal characteristics that people use to help describe and explain behavior. For example, we say that a student does well in school because he or she is intelligent. Or we say that someone is anxious in social situations, or that someone seems to be hungry. Variables like intelligence, anxiety, and hunger are called constructs, and because they are intangible and cannot be directly observed, they are often called hypothetical constructs.” Constructs are internal attributes or characteristics that cannot be directly observed but are useful for describing and explaining behavior. An operational definition identifies a measurement procedure (a set of operations) for measuring an external behavior and uses the resulting measurements as a definition and a measurement of a hypothetical construct. Note that an operational definition has two components. First, it describes a set of operations for measuring a construct. Second, it defines the construct in terms of the resulting measurements. 2.2.1 Conceptualisation and operationalisation Conceptualization is the mental process by which fuzzy and imprecise constructs (concepts) and their constituent components are defined in concrete and precise terms. For example, the process of understanding what is included and what is excluded in the concept of e.g. “prejudice” is the conceptualization process. The conceptualization process is all the more important because of the imprecision, vagueness, and ambiguity of many social science constructs. While defining constructs such as prejudice or compassion, we must understand that sometimes, these constructs are not real or can exist independently, but are simply imaginary creations in our mind. Once a theoretical construct is defined, exactly how do we measure it? Operationalization refers to the process of developing indicators or items for measuring these constructs. For instance, if an unobservable theoretical construct such as socioeconomic status is defined as the level of family income, it can be operationalized using an indicator that asks respondents the question: what is your annual family income? Given the high level of subjectivity and imprecision inherent in social science constructs, we tend to measure most of those constructs (except a few demographic constructs such as age, gender, education, and income) using multiple indicators. This process allows us to examine the closeness amongst these indicators as an assessment of their accuracy (reliability). Retrieved from: Gravetter, F.J., Wallnau, L.B., Forzano, L.A.B. and Witnauer, J.E., 2020. *Essentials of statistics for the behavioral sciences*. Cengage Learning.↩︎ "],["data-collection.html", "2.3 Data collection", " 2.3 Data collection Generally, you can obtain data in three different ways: 1. From a published source; 2. From a designed experiment; 3. From an observational study (e.g., a survey). Moreover, you can obtain data using a simulation: A simulation is the use of a mathematical or physical model to reproduce the conditions of a situation or process. Collecting data often involves the use of computers. Simulations allow you to study situations that are impractical or even dangerous to create in real life, and often they save time and money. For instance, automobile manufacturers use simulations with dummies to study the effects of crashes on humans. Throughout this course, you will have the opportunity to use applets that simulate statistical processes on a computer. "],["sampling-techniqueslecture-22.html", "2.4 Sampling techniques11", " 2.4 Sampling techniques11 A census is a count or measure of an entire population. Taking a census provides complete information, but it is often costly and difficult to perform. A sampling is a count or measure of part of a population, and is more commonly used in statistical studies. To collect unbiased data, a researcher must ensure that the sample is representative of the population. Appropriate sampling techniques must be used to ensure that inferences about the population are valid. Remember that when a study is done with faulty data, the results are questionable. Even with the best methods of sampling, a sampling error may occur. A sampling error is the difference between the results of a sample and those of the population. When you learn about inferential statistics, you will learn techniques of controlling sampling errors. A random sample is one in which every member of the population has an equal chance of being selected. A simple random sample is a sample in which every possible sample of the same size has the same chance of being selected. One way to collect a simple random sample is to assign a different number to each member of the population and then use a random number table Larson, R. and Farber, B., 2019. Elementary statistics. Pearson Education Canada.↩︎ "],["data-distribution.html", "2.5 Data distribution", " 2.5 Data distribution The first step in analyzing data collected on a variable is to look at the observed values by using graphs and numerical summaries. The goal is to describe key features of the distribution of a variable. The most crucial step to exploratory data analysis is estimating the distribution of a variable. The distribution of a variable describes how the observations fall (are distributed) across the range of possible values. The distribution of a data set is a table, graph, or formula that provides the values of the observations and how often they occur. An important aspect of the distribution of a quantitative data set is its shape. Indeed, the shape of a distribution frequently plays a role in determining the appropriate method of statistical analysis. To identify the shape of a distribution, the best approach usually is to use a smooth curve that approximates the overall shape. A frequency distribution is a collection of observations produced by sorting observations into classes and showing their frequency of occurrence in each class: The (frequency) distribution of data - name the possible observations (numbers, categories) and tell how frequently each occurs. A frequency distribution is a summary table in which the data are arranged into numerically ordered classes or intervals. A relative frequency distribution is obtained by dividing the frequency in each class by the total number of values. From this a percentage distribution can be obtained by multiplying each relative frequency by 100%. Frequency distribution for categorical data: A table that displays the possible categories along with the associated frequencies and/or relative frequencies. Frequency: The frequency for a particular category is the number of times the category appears in the data set. The relative frequency for a particular category is the proportion of the observations that belong to that category. "],["basic-stages-of-social-researchlecture-23.html", "2.6 Basic stages of social research12", " 2.6 Basic stages of social research12 Systematically testing our ideas about the nature of social reality often demands carefully planned and executed research in which the following occur: The problem to be studied is reduced to a testable hypothesis (for example, “One-parent families generate more delinquency than two-parent families”). An appropriate set of instruments is developed (for example, a questionnaire or an interview schedule). The data are collected (that is, the researcher might go into the field and conduct a poll or a survey). The data are analyzed for their bearing on the initial hypotheses. Results of the analysis are interpreted and communicated to an audience (for example, by means of a lecture, journal article, or press release). Retrieved from: Fox, J.A., Levin, J. and Forde, D.R., 2017. Elementary Statistics in Social Research.↩︎ "],["statistical-study-essential-steps.html", "2.7 Statistical study - essential steps", " 2.7 Statistical study - essential steps Identify the variable(s) of interest (the focus) and the population of the study. Develop a detailed plan for collecting data. If you use a sample, make sure the sample is representative of the population. Collect the data. Describe the data, using descriptive statistics techniques. Interpret the data and make decisions about the population using inferential statistics. Identify any possible errors. "],["experimental-and-observational-studieslecture-24.html", "2.8 Experimental and observational studies13", " 2.8 Experimental and observational studies13 A statistical study can usually be categorized as an observational study or an experiment. In an observational study, a researcher does not influence the responses. In an experiment, a researcher deliberately applies a treatment before observing the responses. Here is a brief summary of these types of studies. In an observational study, a researcher observes and measures characteristics of interest of part of a population but does not change existing conditions. For instance, an observational study was performed in which researchers observed and recorded the mouthing behavior on nonfood objects of children up to three years old. (Source: Pediatrics Magazine) In performing an experiment, a treatment is applied to part of a population, called a treatment group, and responses are observed. Another part of the population may be used as a control group, in which no treatment is applied. (The subjects in the treatment and control groups are called experimental units.) In many cases, subjects in the control group are given a placebo, which is a harmless, fake treatment, that is made to look like the real treatment. The responses of the treatment group and control group can then be compared and studied. In most cases, it is a good idea to use the same number of subjects for each group. For instance, an experiment was performed in which diabetics took cinnamon extract daily while a control group took none. After 40 days, the diabetics who took the cinnamon reduced their risk of heart disease while the control group experienced no change. (Source: Diabetes Care) Retrieved from: Larson, R., Farber, E. and Farber, E., 2009. Elementary statistics: Picturing the world. Pearson Prentice Hall.↩︎ "],["statistical-research-design-an-example-of-a-simple-experimentlecture-25.html", "2.9 Statistical research design - an example of a simple experiment14", " 2.9 Statistical research design - an example of a simple experiment14 Experimental research design - overview Gravetter, F.J., Wallnau, L.B., Forzano, L.A.B. and Witnauer, J.E., 2020. Essentials of statistics for the behavioral sciences. Cengage Learning.↩︎ "],["descriptive-and-inferential-statistics.html", "2.10 Descriptive and inferential statistics", " 2.10 Descriptive and inferential statistics Descriptive statistics: The branch of statistics that includes methods for organizing and summarizing data. Statistical tools and ideas help us examine data to describe their main features. This examination is called exploratory data analysis. Here are two basic strategies that help us organize our exploration of a set of data: Begin by examining each variable by itself. Then move on to study the relationships among the variables. Begin with a graph or graphs. Then add numerical summaries of specific aspects of the data. Inferential statistics: The branch of statistics that involves generalizing from a sample to the population from which the sample was selected and assessing the reliability of such generalizations. "],["random-samplinglecture-26.html", "2.11 Random sampling15", " 2.11 Random sampling15 A random sample is one that is selected without bias. In selecting a sample, the importance of randomness cannot be overemphasized. In statistical thinking we expect a random sample to share approximately the same properties as the population. Also, the larger the sample size, the more closely the sample properties approximate those of the population. For example, to estimate the average height of adult males, it would be highly biased to select a sample from among NBA players. In general, non-random samples are generated when there is bias in the selection process. Such samples are useless for statistical purposes, because the sample is not representative of the population. A simple random sample is one in which every individual in the population has the same probability of being selected. To satisfy this requirement, the sampling method that is used must be free of bias with respect to the property being measured. The “lottery method” of selection appears to produce a simple random sample (see the margin). Computer-generated random numbers (also called pseudo-random numbers) can be used in selecting random samples: We first assign a number to each individual in the population and then use a computer random number generator to select from the assigned numbers. The following are common types of sampling bias. 2.11.1 Sampling errors and systematic bias In statistics, sampling errors are incurred when the statistical characteristics of a population are estimated from a subset, or sample, of that population. Since the sample does not include all members of the population, statistics on the sample, such as means and quartiles, generally differ from the characteristics of the entire population, which are known as parameters. For example, if one measures the height of a thousand individuals from a country of one million, the average height of the thousand is typically not the same as the average height of all one million people in the country. Since sampling is typically done to determine the characteristics of a whole population, the difference between the sample and population values is considered an error. Systematic error is predictable and typically constant or proportional to the true value. If the cause of the systematic error can be identified, then it usually can be eliminated. Systematic errors are caused by imperfect calibration of measurement instruments or imperfect methods of observation, or interference of the environment with the measurement process, and always affect the results of an experiment in a predictable direction. 2.11.2 Various types of bias in statistical analysis Undercoverage bias (or exclusion bias), in which part of the population is excluded from the sampling process. Response bias, in which the wording of a questionnaire is not neutral but rather suggests or provokes a particular response. Nonresponse bias, in which individuals with a common characteristic are unwilling (or neglect) to respond to a questionnaire. (Notice that this is not the opposite of response bias.) Self-selection bias (or voluntary response bias), in which individuals select themselves (or volunteer) for the sample. Many of these biases are a result of convenience sampling, in which individuals are sampled only because they are nearby or easily accessible. Selection bias is the bias introduced by the selection of individuals, groups or data for analysis in such a way that proper randomization is not achieved, thereby ensuring that the sample obtained is not representative of the population intended to be analyzed. It is sometimes referred to as the selection effect. The phrase “selection bias” most often refers to the distortion of a statistical analysis, resulting from the method of collecting samples. If the selection bias is not taken into account, then some conclusions of the study may be false. In practice, it is difficult to ensure the selection of a random sample. Several methods have been developed for sampling in particular situations. Some of the most common are as follows. Systematic Sampling: In systematic sampling, a sample is chosen systematically from a list. For example, we may pick every 100th name in a telephone book. Stratified Sampling: In stratified sampling, the population is first divided into nonoverlapping groups (or strata), and then the sample is chosen proportionally from each group. For example, to pick a sample of registered voters, we may want to stratify the population into groups—white, African American, Hispanic, and other—and then randomly pick registered voters, choosing from each group a number proportional to the size of the group in the population. Cluster Sampling: In cluster sampling, the population is divided into groups (or clusters) and then a random sample of clusters is selected. For example, to survey apartment dwellers in Los Angeles, we would first randomly select a collection of apartment buildings (the clusters) and then interview every resident in the selected buildings. This type of sampling reduces the enormous time and cost for the pollster in traveling from apartment to apartment. Retrieved from: Stewart, J., Redlin, L. and Watson, S., 2013. Precalculus: Mathematics for calculus. Cengage Learning.↩︎ "],["experimental-designlecture-27.html", "2.12 Experimental design16", " 2.12 Experimental design16 In observational studies, the researcher has no control over the factors affecting the property being studied—the researcher is merely an observer. Extraneous or unintended variables that systematically affect the property being studied are called confounding variables (or confounding factors or lurking variables). Such variables are said to confound (or mix up) the results of the study. The following examples show how this can happen. To eliminate or vastly reduce the effects of confounding variables, researchers often conduct experiments so that such variables can be controlled. In an experimental study, two groups are selected: a treatment group (in which individuals are given a treatment) and a control group (in which individuals are not given the treatment). The individuals in the experiment are called subjects (or experimental units). The goal is to measure the response of the subjects to the treatment—that is, whether or not the treatment has an effect. The next step is to make sure that the two groups are as similar as possible except for the treatment. If the two groups are alike except for the treatment, then any statistical difference in response between the groups can be confidently attributed to the treatment. Here are some typical experimental designs. 1. Completely Randomized Design: The effects of unknown variables that may confound the experiment can be reduced or eliminated by randomization, that is, by assigning individuals randomly to the treatment or control groups. Randomization ensures that the effects of any confounding variables are equally likely to occur in either group. So any difference between the two groups in the response to the treatment can be attributed to the treatment. 2. Randomized Block Design: Variables that are known (prior to the experiment) to affect the response can be controlled by blocking. The participants are arranged into blocks (or groups) consisting of subjects with similar characteristics, and then treatment and control groups are randomly selected within each block. For example, if sex is a known source of variability in response, then a male block and a female block are formed. Treatment and control subjects are then randomly selected from the male block and from the female block. This design specifically “controls” for a known confounding factor by ensuring equal participation of individuals from each block in the treatment and control groups. 3. Matched Pair Design: In this design, the subjects are matched in pairs based on variables that may affect the response to the treatment. For example, the subjects of the study may be matched in pairs based on age and sex (a young male with a young male, a senior female with a senior female, and so on). Then an individual from each pair is randomly assigned to the treatment group, and the other is assigned to the control group. In this example, the treatment and control groups have equal participation with respect to two possible confounding variables (age and sex). A common confounding factor is the placebo effect, in which patients who think they are receiving a medication report an improvement (perceived or actual), even though the “treatment” they received was a placebo—a simulated or false treatment (sometimes called a “sugar pill”). To control the placebo effect, a researcher may use single-blinding, a method in which subjects don’t know whether they are in the treatment or control group, or double-blinding, in which the researchers are also not privy to this information during the course of the experiment. Replication, the repetition of the experiment, can also reinforce the reliability of the results. Retrieved from: Stewart, J., Redlin, L. and Watson, S., 2013. Precalculus: Mathematics for calculus. Cengage Learning.↩︎ "],["relevant-modern-application-of-statistical-theory-machine-learning-the-conceptual-introduction.html", "2.13 Relevant modern application of statistical theory: Machine learning - the conceptual introduction", " 2.13 Relevant modern application of statistical theory: Machine learning - the conceptual introduction Definitions Machine learning (ML) is a sub-field of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning algorithms build a mathematical model based on sample data, known as “training data”, in order to make predictions or decisions without being explicitly programmed to do so. Basic concepts used in Machine Learning: Algorithm: A Machine Learning algorithm is a set of rules and statistical techniques used to learn patterns from data and draw significant information from it. It is the logic behind a Machine Learning model. An example of a Machine Learning algorithm is the Linear Regression algorithm. Model: A model is the main component of Machine Learning. A model is trained by using a Machine Learning Algorithm. An algorithm maps all the decisions that a model is supposed to take based on the given input, in order to get the correct output. Predictor Variable: It is a feature(s) of the data that can be used to predict the output. Response Variable: It is the feature or the output variable that needs to be predicted by using the predictor variable(s). Training Data: The Machine Learning model is built using the training data. The training data helps the model to identify key trends and patterns essential to predict the output. Testing Data: After the model is trained, it must be tested to evaluate how accurately it can predict an outcome. This is done by the testing data set. 2.13.1 Machine learning approaches DiagrammeR::grViz(&quot;digraph { graph [layout = dot, rankdir = TB] node [shape = rectangle] rec1 [label = &#39;Step 1. Machine learning&#39;] rec2 [label = &#39;Step 2. Supervised learning&#39;] rec3 [label = &#39;Step 3. Unsupervised learning&#39;] rec4 [label = &#39;Step 4. Reinforced learning&#39;] # edge definitions with the node IDs rec1 -&gt; {rec2, rec3, rec4} }&quot;, height = 200) [From Wikipedia.org:] Supervised learning: The computer is presented with example inputs and their desired outputs, given by a “teacher”, and the goal is to learn a general rule that maps inputs to outputs. Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning). Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that’s analogous to rewards, which it tries to maximize. “For the process of learning (model fitting) we need to have available some observations or data (also known as samples or examples) in order to explore potential underlying patterns, hidden in our data. These learned patterns are nothing more that some functions or decision boundaries.” 2.13.2 Make predictions or decisions using ML In science and technology, predictions or decisions are made using formal models. A very simple mathematical deterministic model can be: \\[F = \\frac{9}{5}(C) + 32\\] which you could use to convert degrees Celsius to degrees Fahrenheit. For example: \\[F = \\frac{9}{5}(39) + 32 = 70.2 + 32 = 102.2\\] You might be familiar with the formula for a line using the slope and y-intercept (recall the equation of linear function - \\(y = ax + b\\)): \\(y\\) = predicted value (dependent variable); \\(a\\) = slope, i.e. \\(\\frac{\\text{change in }y}{\\text{change in }x}\\); \\(b\\) = intercept with \\(x-\\)axis. However, in statistics, we rarely deal with deterministic models which will produce perfect prediction. We have stochastic models which will have unexplained (“random”) error. If you have an equation that tries to predict what the adult height of a newborn baby boy based on the height of his father. You will certainly not get a perfect prediction for many reasons. A mathematical version of a simple linear regression model, which is stochastic, would be: \\[y = \\beta_0 + x_1\\beta_1 + ... + x_k\\beta_k + \\epsilon\\] This denotes that we believe that there is a linear relationship between predictor variables \\(x_k\\) and response variable \\(y\\) with some unexplained error \\(\\epsilon\\). 2.13.3 Machine learning approaches - visual guide The following figures give general idea on how machine learning works17: Supervised learning Unsupervised learning Reinforcement learning 2.13.3.1 Supervised learning - example18 We seek to teach a computer to predict housing prices. We begin with giving our computer the prices of other houses in the area, as well as information about each house (e.g. the size, number of bedrooms, number of floors). This data are called the training set. Also, the data provided for any one of the given houses is called a training example - this is denoted by \\(x^{(i)}\\), meaning data pertaining to house (i), while \\(x^{(2)}\\) = training example (2). Each distinct bit of information contained within a training example is called a feature. In data representing housing attributes, the size of the house is a feature, as would the number of stories and the number of bedrooms. Every training example contains the same features in the same order. Features are denoted with \\(j\\). That is: \\(x^{(i)}_j\\) is a feature \\(j\\) for an example \\(i\\). Linear regression is one of the most basic machine learning models. Symbolically, this is a common representation of the linear regression model: \\[h_{\\theta}(x) = \\theta_0 + \\theta_1 x\\] \\(h_{\\theta}(x)\\) represents the hypothesis function (hypothesis). It says that the outputted value varies based on the input \\(x\\) That is to say, based on the value \\(x\\) between parentheses, the prediction is made, meaning that \\(h_{\\theta}(x^{(i)})\\) symbolizes the prediction made by the hypothesis on example \\(x^{(i)}\\). The \\(\\theta\\) symbols are known as parameters - can be positive or negative numbers. Also, theta zero is called a bias unit. “Let’s go back to our housing prices example. Let’s pretend we’re using training example 1. Our example will use only one feature for this explanation: the size of the house in square feet. This will be represented by \\(x^{(1)}_1\\), meaning feature 1 of training example 1, and will be equal to 2,500 (square feet).” \"Let’s say our hypothesis believes that each square foot adds $50 of value to the home and that housing prices start at $200,000 in the area. \\(\\theta_0\\) would then have a value of 200,000 and \\(\\theta_1\\) would then be 50. Let’s check out why that is. We know that a prediction is formed by summing the bias unit with the product of features and their respective parameters. When we multiply our \\(x^{(1)}_1\\) (2,500 square feet) by our \\(\\theta_1\\) (the associated parameter of $50/square feet), we get a value of $125,000. Through this multiplication, for every square foot (\\(x^{(1)}_1\\)), $50 dollars of value (\\(\\theta_1\\)) is added. We add that product to our bias unit of $200,000 (\\(\\theta_0\\) representing the average local starting housing price) to get a final output value of $325,000!\" Retrieved from: Loukas, S. What is Machine Learning: Supervised, Unsupervised, Semi-Supervised and Reinforcement learning methods. https://towardsdatascience.com/what-is-machine-learning-a-short-note-on-supervised-unsupervised-semi-supervised-and-aed1573ae9bb↩︎ Based on: Nolan, F. A Comprehensive Introductory Guide to Supervised Learning for the Non-Mathematician. https://towardsdatascience.com/an-involved-introduction-to-supervised-learning-for-the-common-human-6338d9559748↩︎ "],["exploratory-data-analysis-lecture-3.html", "3 Exploratory data analysis [Lecture 3] ", " 3 Exploratory data analysis [Lecture 3] "],["types-of-data-and-the-scales-of-measurement.html", "3.1 Types of data and the scales of measurement", " 3.1 Types of data and the scales of measurement 3.1.1 What is measurement? Measurement is a method of assigning numbers to magnitudes. Bertrand Russell stated that measurement is any method by which a unique and reciprocal correspondence is established between all or some of the magnitudes of a kind and all or some of the numbers, integral, rational or real. (1903: 176) “Broadly speaking, measurement theory sets out to (i) identify the assumptions underlying the use of various mathematical structures for describing aspects of the empirical world, and (ii) draw lessons about the adequacy and limits of using these mathematical structures for describing aspects of the empirical world. Following Otto Hölder (1901), measurement theorists often tackle these goals through formal proofs, with the assumptions in (i) serving as axioms and the lessons in (ii) following as theorems. A key insight of measurement theory is that the empirically significant aspects of a given mathematical structure are those that mirror relevant relations among the objects being measured. For example, the relation”bigger than\" among numbers is empirically significant for measuring length insofar as it mirrors the relation “longer than” among objects. This mirroring, or mapping, of relations between objects and mathematical entities constitutes a measurement scale. As will be clarified below, measurement scales are usually thought of as isomorphisms or homomorphisms between objects and mathematical entities\". (…) “Mathematical theories of measurement (often referred to collectively as”measurement theory“) concern the conditions under which relations among numbers (and other mathematical entities) can be used to express relations among objects. In order to appreciate the need for mathematical theories of measurement, consider the fact that relations exhibited by numbers—such as equality, sum, difference and ratio—do not always correspond to relations among the objects measured by those numbers. For example, 60 is twice 30, but one would be mistaken in thinking that an object measured at 60 degrees Celsius is twice as hot as an object at 30 degrees Celsius. This is because the zero point of the Celsius scale is arbitrary and does not correspond to an absence of temperature. Similarly, numerical intervals do not always carry empirical information. When subjects are asked to rank on a scale from 1 to 7 how strongly they agree with a given statement, there is no prima facie reason to think that the intervals between 5 and 6 and between 6 and 7 correspond to equal increments of strength of opinion. To provide a third example, equality among numbers is transitive [if (a=b &amp; b=c) then a=c] but empirical comparisons among physical magnitudes reveal only approximate equality, which is not a transitive relation. These examples suggest that not all of the mathematical relations among numbers used in measurement are empirically significant, and that different kinds of measurement scale convey different kinds of empirically significant information”19. 3.1.2 Levels of measurement (scales of measurement) Adapted from: D. Osherson and D. M. Lane, http://onlinestatbook.com/2/introduction/levels_of_measurement.html Types of Scales Before we can conduct a statistical analysis, we need to measure our dependent variable. Exactly how the measurement is carried out depends on the type of variable involved in the analysis. Different types are measured differently. To measure the time taken to respond to a stimulus, you might use a stop watch. Stop watches are of no use, of course, when it comes to measuring someone’s attitude towards a political candidate. A rating scale is more appropriate in this case (with labels like very favorable, somewhat favorable, etc.). For a dependent variable such as favorite color, you can simply note the color-word (like red) that the subject offers. Although procedures for measurement differ in many ways, they can be classified using a few fundamental categories. In a given category, all of the procedures share some properties that are important for you to know about. The categories are called scale types, or just scales, and are described in this section. Nominal scales When measuring using a nominal scale, one simply names or categorizes responses. Gender, handedness, favorite color, and religion are examples of variables measured on a nominal scale. The essential point about nominal scales is that they do not imply any ordering among the responses. For example, when classifying people according to their favorite color, there is no sense in which green is placed “ahead of” blue. Responses are merely categorized. Nominal scales embody the lowest level of measurement. Ordinal scales A researcher wishing to measure consumers’ satisfaction with their microwave ovens might ask them to specify their feelings as either very dissatisfied, somewhat dissatisfied, somewhat satisfied, or very satisfied. The items in this scale are ordered, ranging from least to most satisfied. This is what distinguishes ordinal from nominal scales. Unlike nominal scales, ordinal scales allow comparisons of the degree to which two subjects possess the dependent variable. For example, our satisfaction ordering makes it meaningful to assert that one person is more satisfied than another with their microwave ovens. Such an assertion reflects the first person’s use of a verbal label that comes later in the list than the label chosen by the second person. On the other hand, ordinal scales fail to capture important information that will be present in the other scales we examine. In particular, the difference between two levels of an ordinal scale cannot be assumed to be the same as the difference between two other levels. In our satisfaction scale, for example, the difference between the responses very dissatisfied and somewhat dissatisfied is probably not equivalent to the difference between somewhat dissatisfied and somewhat satisfied. Nothing in our measurement procedure allows us to determine whether the two differences reflect the same difference in psychological satisfaction. Statisticians express this point by saying that the differences between adjacent scale values do not necessarily represent equal intervals on the underlying scale giving rise to the measurements. (In our case, the underlying scale is the true feeling of satisfaction, which we are trying to measure.) What if the researcher had measured satisfaction by asking consumers to indicate their level of satisfaction by choosing a number from one to four? Would the difference between the responses of one and two necessarily reflect the same difference in satisfaction as the difference between the responses two and three? The answer is No. Changing the response format to numbers does not change the meaning of the scale. We still are in no position to assert that the mental step from 1 to 2 (for example) is the same as the mental step from 3 to 4. Interval scales Interval scales are numerical scales in which intervals have the same interpretation throughout. As an example, consider the Fahrenheit scale of temperature. The difference between 30 degrees and 40 degrees represents the same temperature difference as the difference between 80 degrees and 90 degrees. This is because each 10-degree interval has the same physical meaning (in terms of the kinetic energy of molecules). Interval scales are not perfect, however. In particular, they do not have a true zero point even if one of the scaled values happens to carry the name “zero”. The Fahrenheit scale illustrates the issue. Zero degrees Fahrenheit does not represent the complete absence of temperature (the absence of any molecular kinetic energy). In reality, the label “zero” is applied to its temperature for quite accidental reasons connected to the history of temperature measurement. Since an interval scale has no true zero point, it does not make sense to compute ratios of temperatures. For example, there is no sense in which the ratio of 40 to 20 degrees Fahrenheit is the same as the ratio of 100 to 50 degrees; no interesting physical property is preserved across the two ratios. After all, if the “zero” label were applied at the temperature that Fahrenheit happens to label as 10 degrees, the two ratios would instead be 30 to 10 and 90 to 40, no longer the same! For this reason, it does not make sense to say that 80 degrees is “twice as hot” as 40 degrees. Such a claim would depend on an arbitrary decision about where to “start” the temperature scale, namely, what temperature to call zero (whereas the claim is intended to make a more fundamental assertion about the underlying physical reality). Ratio scales The ratio scale of measurement is the most informative scale. It is an interval scale with the additional property that its zero position indicates the absence of the quantity being measured. You can think of a ratio scale as the three earlier scales rolled up in one. Like a nominal scale, it provides a name or category for each object (the numbers serve as labels). Like an ordinal scale, the objects are ordered (in terms of the ordering of the numbers). Like an interval scale, the same difference at two places on the scale has the same meaning. And in addition, the same ratio at two places on the scale also carries the same meaning. The Fahrenheit scale for temperature has an arbitrary zero point and is therefore not a ratio scale. However, zero on the Kelvin scale is absolute zero. This makes the Kelvin scale a ratio scale. For example, if one temperature is twice as high as another as measured on the Kelvin scale, then it has twice the kinetic energy of the other temperature. Another example of a ratio scale is the amount of money you have in your pocket right now (25 cents, 55 cents, etc.). Money is measured on a ratio scale because, in addition to having the properties of an interval scale, it has a true zero point: if you have zero money, this implies the absence of money. Since money has a true zero point, it makes sense to say that someone with 50 cents has twice as much money as someone with 25 cents (or that Bill Gates has a million times more money than you do). 3.1.3 Discrete or continuous variables All qualitative data are discrete (nominal and ordinal scale). When it comes to the quantitative variables, we may distinguish: discrete variables, and continuous variables. Discrete data set is composed of isolated points (finitely or infinitely many) on the number line, while continuous sets are numerical intervals, e.g. (1, 10]. For the set \\(A = \\{0, 0.1, 2, (3, 10]\\}\\), number \\(0, 0.1, 2\\) are isolated points. The set A also contains an interval (3, 10], there are no isolated points between 3 and 10. If a variable takes values from a discrete set, e.g. -1, 0, 1, 2, 3 …, it is discrete variable, if a variable takes values from a continuous data set, its is continuous variable. Continuous variables can take any value from a numerical interval. A numerical interval (e.g. [1, 2.5]) always contains infinitely many elements. Moreover, the elements of any numerical interval are uncountable. Discrete sets, while sometimes infinite, are always countable. Besides, sometimes, even if, strictly speaking, a variable is discrete, it is easier to treat this variable as a continuous one - e.g. income per capita in Euro. We usually treat income as continuous variable, but it is, strictly speaking, discrete variable. Income is measured in a currency, e.g. Euro, and it cannot take any value. It takes values from the set that is composed of isolated points. We can earn 4000.52 Euro, but we cannot earn 4000.5256 Euro - a precision of measurement is limited to two decimal places. Variables that are measured in very small but discrete units (e.g. income, exam scores measured in points) are usually treated as continuous in practice; these variables usualy behave as continuous variables. Variables that are truly continuous (time, weight, height, etc.) may take any value, however, in practice, a measurement precision is limited, thus we cannot observe any value of a continuous variable. Retrieved from: https://plato.stanford.edu/entries/measurement-science/↩︎ "],["levels-of-measurement-a-summary.html", "3.2 Levels of measurement - a summary", " 3.2 Levels of measurement - a summary Type Qualitative Qualitative Quantitative Quantitative Subtype Nominal Ordinal Interval Ratio Basic features Distinct categories (e.g. gender) Ordered categories (e.g. Likert scales, IQ) Meaningful distances (e.g. dates, temperature measured using Celsius or Fahrenheit scales) Absolute zero (e.g. weight, height, age, voting turnout, sample size) Possible math operations \\(=, \\neq\\) \\(&gt;, &lt;\\) \\(+, -\\) \\(\\times, \\div\\) 3.2.1 Types of data and levels of measurement - intuitions Levels of measurement Continuous and Discrete 3.2.2 Frequency distribution A sequence of observation, made on a set of objects included in the sample drawn from population is known as statistical data. Main methods of data collection include census, sample data (including survey, experimental and quasi-experimental research), and also administrative by-product. A census refers to data collection about everyone or everything in a group or statistical population and has advantages such as accuracy and detail, and disadvantages such as cost and time. A sampling is a data collection method that includes only part of the total population and has advantages such as cost and time, and disadvantages such as accuracy and detail. Administrative by-product data are collected as a by-product of an organization’s day-to-day operations and has advantages such as accuracy, time and simplicity, and disadvantages such as no flexibility and lack of control. Collected, but unordered, data are stored in columns of databases (e.g. in MS Excel files, in SQL databases - eg. MySQL). In databases, each column represent a single variable, each row represents a single observation. Data may be organized into frequency distributions before we start to examine them. We can organize an unordered set of collected data into a frequency distribution. A frequency distribution is a tabular representation of a survey data set used to organize and summarize the data. Specifically, it is a list of either qualitative or quantitative values that a variable takes in a data set and the associated number of times each value occurs (frequencies). The frequency distribution is the basic building block of statistical analytical methods and the first step in analyzing survey data. It helps researchers (a) organize and summarize the survey data in a tabular format, (b) interpret the data, and (c) detect outliers (extreme and rare values) in the survey data set. "],["reliability-and-validity.html", "3.3 Reliability and Validity", " 3.3 Reliability and Validity Reliability and Validity Reliability refers to the consistency of a measure. Psychologists consider three types of consistency: over time (test-retest reliability), across items (internal consistency), and across different researchers (inter-rater reliability). Validity is the extent to which the scores from a measure represent the variable they are intended to. When a measure has good test-retest reliability and internal consistency, researchers should be more confident that the scores represent what they are supposed to. There has to be more to it, however, because a measure can be extremely reliable but have no validity whatsoever. “The usefulness of a measurement tool is reliant on the extent to which it can be considered reliable and accurate as an indicator of behavior. Reliability is an indication of the consistency of the measurement. The degree to which an instrument reflects what it is proposed to measure is reflected in validity. Internal consistency is a form of reliability. This property is most relevant to performance measures that consist of multiple items that are to be summarized clinically into a composite score. Clinical inferences made from a composite score of multiple items are strengthened by evidence that all items—in the case of the FGA, dynamic balance—are measuring the same construct.28 As an index of a test’s ability to differentiate among patients, a high degree of internal consistency also supports the use of the instrument as a screening tool”.20 Three essential types of validity Face validity is the extent to which a measurement method appears “on its face” to measure the construct of interest. Content validity is the extent to which a measure “covers” the construct of interest. Criterion validity is the extent to which people’s scores on a measure are correlated with other variables (known as criteria) that one would expect them to be correlated with. Retrieved from: https://opentextbc.ca/researchmethods/chapter/reliability-and-validity-of-measurement/↩︎ "],["tabular-presentation-of-data-distributions.html", "3.4 Tabular presentation of data distributions", " 3.4 Tabular presentation of data distributions 3.4.1 Unordered data \\(X = \\{4,4,4,4,8,8,8,2\\}\\) \\(i\\) \\(x_i\\) 1 4 2 4 3 4 4 4 5 8 6 8 7 8 8 2 - - \\(n = 8\\) "],["frequency-distribution-1.html", "3.5 Frequency distribution", " 3.5 Frequency distribution The frequency distribution of the variable tells us what values it takes and how often it takes these values. \\(X = \\{4,4,4,4,8,8,8,2\\}\\) Id \\(x_i\\) Frequency \\(f_i\\) Relative frequency (fractions) \\(p_i = f_i/n\\) 1 2 1 1/8 2 4 4 1/2 3 8 3 3/8 \\(\\Sigma\\) - \\(n\\) = 8 1 Remark: The relative frequencies may be used to estimate probabilities of data points (the empirical or statistical probabilities), denoted with the letter p. "],["frequency-distribution-with-intervals-for-grouped-data.html", "3.6 Frequency distribution with intervals (for grouped data)", " 3.6 Frequency distribution with intervals (for grouped data) Id Class interval (bin) \\(h_k\\) for \\(x_i\\) Frequency \\(f_i\\) Relative frequency \\(p_i = f_i/n\\) Density \\(d_i = p_i/\\Delta x_i\\) 1 [1, 6) 12 12/120 = 0.1 0.1/(6 - 1) = 0.02 2 [6, 11) 6 0.05 0.01 … … … … … 20 [96, 101) 3 0.025 0.005 \\(\\Sigma\\) - \\(n\\) = 120 1 - The concept of density (for an interval) is very similar to mass density in physics: its unit is probability per unit length. This is very Density scale is very useful in statistics; it gives the relative frequency per unit for the data in this class, where the unit is the unit of measurement of the data. This allows for a meaningful comparison of different classes where the class widths may not be equal. Histograms (the essential type of statistical graphs discussed below) have been a popular visualization option since at least the 18th century, in part because they are easily generated by hand. More recently, as extensive computing power has become available in everyday devices such as laptops and cell phones, we see them increasingly being replaced by the so-called density plots (smooth curves that model the shape of a histogram). Retrieved from: https://ajsmit.github.io/Basic_stats/graphical-data-displays.html "],["basic-descriptive-statistics.html", "3.7 Basic descriptive statistics", " 3.7 Basic descriptive statistics Any time a data set is summarized by its statistical information, there is a loss of information. That is, given the summary statistics, there is no way to recover the original data. Basic summary statistics may be grouped as: measures of central tendency (giving in some sense the central value of a data set) and measures of dispersion (giving a measure of how spread out that data set is). 3.7.1 Basic measures of central tendency mean (also known as expected value or average value), median - a median is a number separating the higher half of a data sample, a population, or a probability distribution, from the lower half. mode - the mode is the value that appears most often in a set of data. 3.7.2 Which measures of central tendency are appropriate for numerical and categorical data If the data are numerical or quantitative in nature, then the mean or median should be used to describe the center of the distribution. If the data do not contain any unusually large or unusually small values, then the mean should be used to describe the center of the distribution. If the data do contain unusually large or unusually small values, then the median should be used to describe the center of the distribution. If the data are purely categorical or qualitative, the mode should be used; arithmetic is not possible. However, if the data are ordinal, the median can be used as well. 3.7.3 Basic measures of spread/dispersion variance, standard deviation, interquartile range. "],["mean-and-standard-deviation.html", "3.8 Mean and standard deviation", " 3.8 Mean and standard deviation 3.8.1 Mean 3.8.2 Variance and standard deviation The figure above shows the three data sets (1, 2, 3); each of them has the same mean and median. However, the average dispersion of observations (data) relative to the mean, i.e. the standard deviation, is greatest for the lower set (3) and smallest for the uppermost set (1). Also, Figure 2.10 shows the income distributions for music teachers in the US and Denmark - Denmark’s standard deviation of income is much smaller, with the same mean value. "],["useful-formulas-descriptive-statistics.html", "3.9 Useful formulas (descriptive statistics)", " 3.9 Useful formulas (descriptive statistics) Id Unordered data distribution Type of available data - relative or absolute frequency Frequency distribution (ordered data distribution) 1 \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\] \\(n\\) = number of observations; \\[S^2(X) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\] \\[S(X) = \\sqrt{S^2(X)}\\] Absolute frequencies - \\(f_i\\) \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{k}x_if_i\\] \\(n\\) = number of observations (sample or population size); \\(k\\) = number of distinct values (# of rows in a frequency distribution). \\[S^2(X) = \\frac{1}{n}\\sum_{i=1}^{k}(x_i - \\bar{x})^2f_i\\] \\[S(X) = \\sqrt{S^2(X)}\\] or you can use formulas for the relative frequency of observations \\[\\bar{x} = \\sum_{i=1}^{k}x_ip_i\\] \\[S^2(X) = \\sum_{i=1}^{k}(x_i - \\bar{x})^2p_i\\] \\[S(X) = \\sqrt{S^2(X)}\\] 2 - Relative frequencies (fraction, proportion) - \\(p_i = f_i/n\\) \\[\\bar{x} = \\sum_{i=1}^{k}x_ip_i\\] \\(n\\) = number of observations; \\(k\\) = number of distinct values (groups). \\[S^2(X) = \\sum_{i=1}^{k}(x_i - \\bar{x})^2p_i\\] \\[S(X) = \\sqrt{S^2(X)}\\] "],["parameter-and-statistic-summary-of-symbols.html", "3.10 Parameter and statistic - summary of symbols", " 3.10 Parameter and statistic - summary of symbols Population (P) Sample (S) expected value (mean): \\(E(X), \\mu\\) sample mean: \\(\\bar{x}\\) proportion: sample proportion: \\(\\hat{p}\\) standard deviation: \\(\\sigma\\) sample standard deviation: \\(S, S(X), s\\) variance: \\(\\sigma^2\\), \\(Var(X)\\) sample variance: \\(S^2, S^2(X), s^2\\) median: \\(Md_X\\) sample median \\(\\hat{Md}_X\\) mode: \\(Mo_X\\) sample mode \\(\\hat{Mo}_X\\) "],["finding-mean-and-standard-deviation.html", "3.11 Finding mean and standard deviation", " 3.11 Finding mean and standard deviation The mean or expected value is the most important measure of central tendency, while the standard deviation (SD, denoted \\(sigma\\) in a population, \\(S(X)\\) in a sample) is a measure of an average dispersion (spread) of [random] variable values about the mean - SD is the most important measure of dispersion. The standard deviation and variance are very important measures of dispersion (of data). The standard deviation is a square root of the variance. The variance of a data set is the arithmetic average of the squared differences between the values and the mean. A low standard deviation indicates that the data points tend to be very close to the mean (also called the expected value); a high standard deviation indicates that the data points are spread out over a large range of values. The standard deviation measures an average dispersion of data (observations) around the mean. The standard deviation is expressed in the same units as the mean (dollars, meters, etc.) is, whereas the variance is expressed in squared units. The variance and standard deviation are very similar measures, but it is easier to interpret standard deviation (is expressed in the same units as the mean). 3.11.1 Example 3.1 3.11.1.1 Example 3.1 (step 1) - raw, unordered data The table below presents an unordered sequence of data about the wages of people (in thousands of dollars) in the two small random samples (variables X and Y). Calculate the mean value (expected value or average) (denoted \\(E(X)\\) or \\(\\mu\\) in a population and \\(\\bar{x}\\) in a sample) of the earnings for each sample and also find the variance and the standard deviation in both samples. Using data from the example, organize data for the variable X into frequency distribution. \\(i\\) \\(x_i\\) \\(y_i\\) 1 1 4 2 3 3 3 4 3 4 5 4 5 3 5 6 4 3 7 6 3 8 5 4 9 4 5 10 2 3 11 1 2 12 3 3 \\(\\Sigma\\) 42 42 Then, we have: \\(i\\) \\(x_i\\) \\(x_i - \\bar{x}\\) \\((x_i - \\bar{x})^2\\) 1 1 -2.5 6.25 2 3 -0.5 0.25 3 4 0.5 0.25 4 5 1.5 2.25 5 3 -0.5 0.25 6 4 0.5 0.25 7 6 2.5 6.25 8 5 1.5 2.25 9 4 0.5 0.25 10 2 -1.5 2.25 11 1 -2.5 6.25 12 3 -0.5 0.25 \\(\\Sigma\\) 42 0 The mean \\(\\bar{x} = 42/12 = 3.5\\), and \\(S(X) = \\sqrt{27/12} = 1.5\\) (thousands of dollars) 3.11.1.2 Example 3.1 (step 2) - data in a frequency distribution Try to repeat the computation of the mean and the standard deviation, but apply the formulas appropriate for the data organized into a frequency distribution. The table presents the frequency distribution for the values of variable X from the table; \\(f_i\\) denotes the absolute frequencies. \\(i\\) \\(x_i\\) \\(f_i\\) 1 1 1 2 2 2 3 3 3 4 4 3 5 5 2 6 6 1 \\(\\Sigma\\) - 12 It depends on the form of data presentation (unordered or ordered distribution), what formula you need to apply to compute the mean and the standard deviation - see the table with formulas from a section above. \\(i\\) \\(x_i\\) \\(f_i\\) \\(x_if_i\\) \\(p_i\\) \\((x_i-\\bar{x})^2\\) \\((x_i-\\bar{x})^2 * p_i\\) \\((x_i-\\bar{x})^2 * f_i\\) 1 1 2 2 2/12 6.25 1.04 12.5 2 2 1 2 1/12 2.25 0.19 2.25 3 3 3 9 3/12 0.25 0.06 0.75 4 4 3 12 3/12 0.25 0.06 0.75 5 5 2 10 2/12 2.25 0.38 4.5 6 6 1 6 1/12 6.25 0.52 6.25 \\(\\Sigma\\) - 12 42 1 - 2.25 27 Thus, the average value is \\(\\bar{x} = 42/12 = 3.5\\), and the average spread of the observations about the mean \\(S(X)\\) is \\(\\sqrt{27/12} = 1.5\\) thousand ($1500). "],["mode.html", "3.12 Mode", " 3.12 Mode A mode is the most commonly occurring value in a data set. Calculate the mode of the numbers: 2, 2, 2, 6, 6, 6. In this case, the modal value (Md) does not exist. "],["quartiles-and-median.html", "3.13 Quartiles and median", " 3.13 Quartiles and median After a data set has been sorted in ascending order (smallest to largest), the rth percentile, is a value such that r percent of the observations in the data set fall at or below that value. For instance: The median, Q2, is the 50th percentile of a data set. For an odd number of data, the median is one of the original data values. For an even number of data, the median is the average of the two middle values, and hence may not be in the original data set. The 25th percentile is also known as the first quartile (Q1), the 50th percentile as the median or second quartile (Q2), and the 75th percentile as the third quartile (Q3). In general, percentiles and quartiles are specific types of quantiles - q-quantiles are values that partition a finite set of values into q subsets of (nearly) equal sizes. After a data set has been sorted in ascending order (smallest to largest), - the median of a data set is its middle value (the 50th percentile, the 2nd quartile). - the lower quartile is the cutoff point for the bottom 25% of the data (the 25th perc.). - the upper quartile is the cutoff point for the top 25% of the data (the 75th per.). 3.13.1 Example A = {2, 4, 4, 5, 6, 7, 8} \\(Q_1 = 4\\) \\(Q_2 (median) = 5\\) \\(Q_3 = 7\\) A = {1, 3, 3, 4, 5 | 6, 6, 7, 8, 8} \\(Q_1 = 3\\) \\(Q_2 (median) = (5+6)/2 = 5.5\\) \\(Q_3 = 7\\) 3.13.1.1 Interquartile-range (IQR) \\(IQR = Q_3 - Q_1\\) Also, we employ IQR to determine outliers; atypical values (outliers) are usualy defined as values of a variable that not fall into the range: \\[[Q_1 - 1.5 \\times IQR, Q_3 + 1.5 \\times IQR]\\] "],["measures-of-relative-standing.html", "3.14 Measures of relative standing", " 3.14 Measures of relative standing 3.14.1 Percentile and percentile rank The percentile system is widely used to show how an individual has performed relative to a known group. It is based on the cumulative percentage distribution. A percentile point is a point on the measurement scale below which a specified percentage of the cases in the distribution falls. It is more commonly called a percentile (from the Latin centrum, meaning “hundred”). If, for example, 50% of students in the history course have midterm scores lower than 81, the 50th percentile is 81. A percentile rank is the percentage of cases falling below a given point on the measurement scale. In our example, the percentile rank of a score of 81 is 50. Do not confuse percentiles and percentile ranks: Percentile ranks may take values only between 0 and 100, whereas a percentile (point) may have any value that scores may have. For example, it is possible that the value of a percentile is 143. Suppose that Mary earned a score of 143 on a college entrance test and that 75% of applicants score lower. The 75th percentile is 143; Mary’s percentile rank is 75. Standardized tests, such as the SAT (Scholastic Aptitude Test) and GRE (Graduate Record Exam), publish their results in terms of either percentiles or percentile ranks. 3.14.2 Standard score (Z-score) In statistics, the standard score is the number of standard deviations by which the value of a raw score (i.e., an observed value or data point) is above or below the mean value of what is being observed or measured. Raw scores above the mean have positive standard scores, while those below the mean have negative standard scores. It is calculated by subtracting the population mean from an individual raw score and then dividing the difference by the population standard deviation. This process of converting a raw score into a standard score is called standardizing or normalizing. However, “normalizing” can refer to many types of transformations; e.g. feature scaling is used to bring all values into the range [0,1]. This is also called unity-based normalization. This can be generalized to restrict the range of values in the dataset between any arbitrary points a and b. 3.14.2.1 Z-score as a measure of relative standing The z-score for an observation is the number of standard deviations that it falls from the mean. A positive z-score indicates the observation is above the mean. A negative z-score indicates the observation is below the mean. For sample data, the z-score is calculated as: \\[\\text{z-score}_X = \\frac{x_i - \\mu_X}{\\sigma_X} = \\frac{\\text{value} - \\text{mean}}{\\text{standard deviation}}\\] The empirical rule tells us that for a bell-shaped distribution, it is unusual for an observation to fall more than 3 standard deviations from the mean. An observation in a bell-shaped distribution is regarded as a potential outlier (an atypical value) if it falls more than 3 standard deviations from the mean. The z-score allows us to tell quickly how surprising or extreme an observation is. The z-score converts an observation (regardless of the observation’s unit of measurement) to a common scale of measurement, which allows comparisons. Also, The z-score is often used in the z-test in standardized testing – the analog of the so-called Student’s t-test (in statistical inference) for a population whose parameters are known, rather than estimated. As it is very unusual to know the entire population, the t-test is much more widely used. "],["basic-methods-of-data-visualization.html", "3.15 Basic methods of data visualization", " 3.15 Basic methods of data visualization bar chart (bar plot) - visualizes the distribution of observations for nominal or ordinal data, histogram (for absolute and relative frequencies and for the so-called densities - only for quantitative data, box plot - for quantitative data, but sometimes can be employed to describe distributions of ordinal data. "],["bar-plot.html", "3.16 Bar plot", " 3.16 Bar plot # Plot a bar plot using R programming language knitr::opts_chunk$set(fig.width=4, fig.height=4) # Knitr settings library(ggplot2) # Load ggplot package data = data.frame( x = c(1,1,5,5,5,5,5,3,3,3,3,4,4,5) ) # Create data barplot &lt;- ggplot(data = data) + geom_bar( aes(x = x), stat = &quot;count&quot; ) # Create a bar plot # Print a bar plot print(barplot) "],["frequency-distribution-table-and-histogram.html", "3.17 Frequency distribution table and histogram", " 3.17 Frequency distribution table and histogram To visualize frequency distribution you can use frequency or density histogram Id Class interval (bin) \\(h_k\\) for \\(x_i\\) Frequency \\(f_i\\) Relative frequency (fraction) \\(p_i = f_i/n\\) Density \\(d_i = p_i/\\Delta x_i\\) 1 [1, 6) 12 12/120 = 0.1 0.1/(6 - 1) = 0.02 2 [6, 11) 6 0.05 0.01 … … … … … 20 [96, 101) 3 0.025 0.005 \\(\\Sigma\\) - \\(n\\) = 120 1 - "],["three-types-of-histograms-are-used.html", "3.18 Three types of histograms are used:", " 3.18 Three types of histograms are used: histogram of absolute rates (to be used only in justified cases); histogram of relative frequencies - the sum of the heights of all bars is equal to 1 (or 100%); density histogram (the so-called true histogram) - the sum of the area of all bars is equal to 1 (or 100%). "],["density-histogram-and-frequency-histogram.html", "3.19 Density histogram and frequency histogram", " 3.19 Density histogram and frequency histogram 3.19.1 Construction of the density histogram (1) # Plot histogram using R knitr::opts_chunk$set(fig.width=4, fig.height=4) # Knitr settings library(lattice) # Load lattice package data = c(140,145,200,325,320,285,283,280,248,246,242,240,240,204,201) # Create data set histogram &lt;- histogram(data, nint = 5, type = &quot;density&quot;, endpoints = c(140, 340), right = F) # Create histogram print(histogram) # Plot histogran histogram$panel.args.common$breaks # Print interval breaks used to plot the histogram ## [1] 140 180 220 260 300 340 3.19.2 Absolute histogram histogram &lt;- histogram(data, nint = 5, type = &quot;count&quot;) # Create histogram print(histogram) # Print histogram 3.19.3 Relative frequency histogram histogram &lt;- histogram(data, nint = 5, type = &quot;percent&quot;) # Create histogram print(histogram) # Print histogram "],["histogram-for-the-binomial-distribution-1.html", "3.20 Histogram for the binomial distribution (1)", " 3.20 Histogram for the binomial distribution (1) library(ggplot2) # Generate a random sample Z &lt;- seq(0,4,by = 1) # Calculate probabilities P &lt;- dbinom(Z,4,0.25) binom_data &lt;- data.frame(Z, P) # Merge data sets head(binom_data) ## Z P ## 1 0 0.31640625 ## 2 1 0.42187500 ## 3 2 0.21093750 ## 4 3 0.04687500 ## 5 4 0.00390625 # Plot data ggplot(data = binom_data) + geom_bar( aes(x = Z, y = P), stat = &quot;identity&quot; ) "],["box-plot.html", "3.21 Box plot", " 3.21 Box plot Like bar plots and histograms, the box plot is used to show the distribution of the data. This type of plot illustrates the basic characteristics of a data distribution, and is often used when researchers want to see how the distribution of a quantitative variable is affected by some qualitative variable (or discrete quantitative) (e.g .: life expectancy vs. continent). "],["box-plot-example-1.html", "3.22 Box plot - example (1)", " 3.22 Box plot - example (1) # Plot box plots using R data &lt;- data.frame( men = c(143, 160, 165, 168, 172, 173, 175, 176, 177, 178, 179, 180, 180, 181, 181, 182, 182, 183, 183, 184, 186, 188, 190, 191, 200), women = c(140, 150, 155, 158, 160, 163, 163, 165, 166, 166, 168, 170, 170, 171, 172, 173, 173, 173, 175, 176, 177, 181, 182, 183, 196) ) # Data set head(data) # Displays the first lines of a dataset ## men women ## 1 143 140 ## 2 160 150 ## 3 165 155 ## 4 168 158 ## 5 172 160 ## 6 173 163 library(dplyr) library(tidyr) # Load packages data &lt;- gather(data = data, key = &quot;plec&quot;, value = &quot;wzrost&quot;, men:women ) # Transform dataset from wide to long format head(data) ## plec wzrost ## 1 men 143 ## 2 men 160 ## 3 men 165 ## 4 men 168 ## 5 men 172 ## 6 men 173 3.22.1 Box plot - example (2) box &lt;- ggplot(data = data) + geom_boxplot( aes( x = plec, y = wzrost ) ) + coord_flip() # Rysuje wykres pudełkowy print(box) # Wyświetla wykres 3.22.2 Box plot - example (compare the box plots) True or False: Women in the studied sample are, on average, taller than men (F); Male height is more dispersed relative to the median (…); The lowest person is a woman (…); Both data sets negatively skewed (…); Half of the women measure at least 170 cm (…). 3.22.3 Plot the data from the above example using histograms and smooth density curves hist &lt;- ggplot(data = data) + geom_histogram( aes( x = wzrost, y = ..density.., fill = plec ), bins = 6, alpha = 0.7 ) + geom_density( aes( x = wzrost, y = ..density.., colour = plec ) ) + theme_classic() # Create histograms print(hist) # Print the result "],["box-plots-additional-example.html", "3.23 Box plots - additional example", " 3.23 Box plots - additional example X = c(215, 140, 290, 300, 300, 320, 330, 340, 415, 480) # Define the data set boxplot(X, horizontal = T) # Plot the data "],["histogram-and-box-plot.html", "3.24 Histogram and box-plot", " 3.24 Histogram and box-plot "],["skewness-of-data-distribution.html", "3.25 Skewness of data distribution", " 3.25 Skewness of data distribution Also, "],["introduction-to-statistical-inference-lecture-4-draft-copy-ver-0-4.html", "4 Introduction to statistical inference [Lecture 4 - draft copy, ver. 0.4] ", " 4 Introduction to statistical inference [Lecture 4 - draft copy, ver. 0.4] "],["introduction.html", "4.1 Introduction", " 4.1 Introduction 4.1.1 Logic Logic operations include any operations that manipulate Boolean values. Boolean values are either true or false. They are named after English mathematician George Boole, who invented Boolean algebra, and is widely considered the founder of computer science theory. They can also be represented as 1 and 0. Normally, 1 represents true, and 0 represents false, but it could be the other way around. The basic Boolean operators are and (\\(\\wedge\\)), or (\\(\\vee\\)), not (\\(\\sim\\)), implication (\\(\\Longrightarrow\\)), and equivalence (\\(\\Longleftrightarrow\\)). Given two Boolean variables A and B, the Boolean expression \\(A \\wedge B\\) is true only if both A and B are true. \\(A \\vee B\\) is true if either A or B is true, including the case when both are true. Not A is true when A is false, and vice-versa. The material conditional (also known as implication, or conditional) is a logical connective (or a binary operator) that is often symbolized by a forward arrow “\\(\\Longrightarrow\\)”. The material conditional is used to form statements of the form p → q (termed a conditional statement) which is read as “if p then q”. Unlike the English construction “if … then …”, the material conditional statement \\(p \\Longrightarrow q\\) does not conventionally specify a causal relationship between p and q; It merely means “if p is true then q is also true”, such that the statement \\(p \\Longrightarrow q\\) is false only when p is true and q is false. 4.1.1.1 Boolean Operators Boolean symbols are useful for brevity and precision, just like arithmetic symbols. If \\(p\\) denotes “I like chocolate” \\(q\\) denotes “I like ice cream” then \\(p \\wedge q\\) means “\\(p\\) and \\(q\\)” (I like chocolate and I like ice cream). True iff \\(p\\) and \\(q\\) are both true. \\(p \\vee q\\) means “\\(p\\) or \\(q\\).” True iff one or both of \\(p\\) and \\(q\\) is true. Not an exclusive or. (How could I formulate exclusive or?) \\(p \\implies q\\) means “\\(p\\) implies \\(q\\)” or “if \\(p\\) then \\(q\\)” (If I like chocolate, then I like ice cream). True iff \\(p\\) being true makes \\(q\\) true. note: \\(p\\implies q\\) is also true when \\(p\\) is false! \\(p \\iff q\\) 4.1.1.2 Predicates Predicates are similar to propositions but they depend on variables. \\(P(x,y,z)\\) denotes a predicate on variables \\(x,y,z\\). For example, define: \\(R(x)\\): \\(x\\) is an odd number \\(Q(x)\\): \\(x &gt; 2\\) \\(P(x)\\): \\(x\\) is a prime number These predicates are not propositions, because they can be true or false depending on \\(x\\). They are like functions from variables to truth values. \\(P(2)\\) is true \\(R(2)\\) is false \\(P(4) \\vee R(3)\\) is true \\(Q(3) \\wedge R(4)\\) is false \\(Q(1) \\implies R(2)\\) is true. 4.1.1.3 Quantifiers Many propositions assert that something is true for all or some elements of a given domain (e.g., all numbers). Let’s agree in advance on a universe of discourse. “\\(\\forall\\)” means “for all.” \\(\\forall x P(x)\\) is a statement that is true if \\(P(x)\\) is true for every \\(x\\) in the universe of discourse. “\\(\\exists\\)” means “there exists.” \\(\\exists x P(x)\\) is true if \\(P(x)\\) is true for at least one \\(x\\) in the universe of discourse. “\\(\\exists !\\)” means “there exists exactly one.” “\\(\\forall x \\in S\\)” means “for every \\(x\\) in the set \\(S\\).” \\((\\forall x \\in S) P(x)\\) is equivalent to \\((\\forall x) (x \\in S \\implies P(x)).\\) Quantifies can turn predicates into propositions, e.g. \\[\\forall x, P(x) \\wedge Q(x) \\implies R(x)\\] This expression is a (true) proposition, because the variable in the predicates is bound. \\(\\forall x \\exists y\\) is different from \\(\\exists y \\forall x\\): \\(S(x,y):\\) student \\(x\\) falls asleep in class \\(y\\). \\(\\forall y \\exists x P(x,y):\\) “In every class, some student will fall asleep” \\(\\exists x \\forall y P(x,y):\\) “There exists a student who will fall asleep in every class.” 4.1.1.4 Axioms Axioms are propositions that are assumed to be true.There doesn’t exist a proof that the axiom is true – you just start with a reasonable assumption. (“axiom” comes from Greek “to think worthy,” not “to be true”). It is not wrong to make assumptions (in fact, it is unavoidable), but to be rigorous you have to state your assumptions explicitly. Some typical examples of axioms from various parts of mathematics: If \\(a=b\\) and \\(b=c\\) then \\(a=c\\). Euclidean geometry has an axiom: Given a line \\(l\\) and a point \\(p\\) not on \\(l\\), there is exactly one line through \\(p\\) parallel to \\(l\\). (Sometimes an axiom from one domain contradicts an axiom from another.) Spherical geometry has an axiom contradicting Euclid’s: Given a line \\(l\\) and a point \\(p\\) not on \\(l\\), there is no line through \\(p\\) parallel to \\(l\\). 4.1.2 Sets A set is a well-defined collection of objects. Each object in a set is called an element of the set. Two sets are equal if they have exactly the same elements in them. A set that contains no elements is called a null set or an empty set. If every element in Set A is also in Set B, then Set A is a subset of Set B. Membership: If \\(a\\) is a member of a set A, we write \\(a \\in A\\) Sets of numbers: set of natural numbers \\(N = \\{0, 1, 2, 3, ... \\}\\), set of positive natural numbers \\(N^+ = \\{1, 2, 3, ... \\}\\), a set of integers \\(Z = \\{..., -2, -1, 0, 1, 2, 3, ... \\}\\), a set of rational numbers \\(Q\\), i.e. all numbers that can be represented as \\(\\frac{p}{q}\\) for \\(q \\neq 0\\), set of irrational numbers \\(NQ\\), i.e. all numbers that have infinite and non-periodic decimal expansion, e.g. number \\(\\pi \\approx 3,141592...\\), or a number indicated by a letter \\(e \\approx 2,718 ...\\), set of real numbers \\(R = Q + NQ\\). \\(R\\) can be expressed as an interval \\((-\\infty, \\infty)\\). An interval is a set of real numbers with the property that any number that lies between two numbers in the set is also included in the set. The interval of numbers between a and b, including a and b, is often denoted \\([a, b]\\). The two numbers are called the endpoints of the interval. A singleton is a set with exactly one element. CAUTION: Be sure you understand the difference between the outcome -8 and the event {−8}, which is the set consisting of the single outcome −8. The cardinality (or size) of a collection or set \\(A\\), denoted \\(|A|\\), is the number of elements of the collection. This number may be finite or infinite. A finite set is a set that has a finite number of elements. In other words, it is either an empty set, a singleton, or a set whose elements can be listed in the form \\({a1, a2, . . . , an}\\) for some \\(n \\in N\\). A set that is not finite is called infinite. These sets have more than \\(n\\) elements for any integer \\(n\\). Whether finite or infinite, the elements of a countable set can always be counted one at a time and, although the counting may never finish, every element of the set is associated with a natural number. Countable sets form the foundation of a branch of mathematics called discrete mathematics. A set that is not countable is called uncountable set (or uncountably infinite set). It contains too many elements to be countable, e.g. an interval with positive length: \\([0, 1]\\). Table 1.1. The terminology of set theory and probability theory Set Theory Probability Theory Set Event Universal set Sample space Element Outcome Table 1.2. Probability event language - Event language \\(A\\) A occurs \\(A^c\\) A does not occur \\(A \\cup B\\) Either A or B occur \\(A \\cap B\\) Both A and B occur 4.1.3 Cardinality (Retrieved from Wikipedia.org) In mathematics, the cardinality of a set is a measure of the “number of elements” of the set. For example, the set \\(A=\\{2,4,6\\}\\) contains 3 elements, and therefore A has a cardinality of 3. Beginning in the late 19th century, this concept was generalized to infinite sets, which allows one to distinguish between the different types of infinity, and to perform arithmetic on them. The cardinality of a set is also called its size, when no confusion with other notions of size is possible. The cardinality of a set A is usually denoted \\(\\|A\\|\\), with a vertical bar on each side; this is the same notation as absolute value, and the meaning depends on context. The cardinality of a set A may alternatively be denoted by e.g. \\(n(A)\\), \\(\\#A\\). If the so-called axiom of choice holds, the law of trichotomy holds for cardinality: Any set X with cardinality less than that of the natural numbers is said to be a finite set. Any set X that has the same cardinality as the set of the natural numbers is said to be a countably infinite set. Any set X with cardinality greater than that of the natural numbers is said to be uncountable. The difference between countable and uncountable sets is important for statistics and probability. Because of the mathematics required to determine probabilities, probabilistic methods are divided into two distinct types, discrete and continuous. A discrete approach is used when the number of experimental outcomes is finite (or infinite but countable). A continuous approach is used when the outcomes are continuous (and therefore infinite). It will be important to keep in mind which case is under consideration since otherwise, certain paradoxes may result. 4.1.3.1 Remark Do not confuse symbol \\(\\subseteq\\) (to be a subset; can be also denoted as \\(\\subset\\)) with the symbol \\(\\in\\) (to be an element): \\(\\subseteq\\) \\(\\neq\\) \\(\\in\\) \\(\\emptyset \\subseteq \\emptyset\\), but \\(\\emptyset \\notin \\emptyset\\) \\(\\emptyset \\subseteq \\{1,2,3,4,5\\}\\), \\(\\emptyset \\notin \\{1,2,3,4,5\\}\\) \\(\\{3\\} \\subseteq \\{1,2,3,4,5\\}\\), \\(3 \\nsubseteq \\{1,2,3,4,5\\}\\), but \\(3 \\in \\{1,2,3,4,5\\}\\) 4.1.4 Sets - summary A set is a collection of objects: \\(x \\in S\\) means “\\(x\\) is in the set \\(S\\)” \\(\\emptyset\\) is the empty set (contains no elements). \\(A \\cap B\\) means “the intersection of \\(A\\) and \\(B\\)” (the set of elements in both sets). \\(A \\cup B\\) means “the union of \\(A\\) and \\(B\\)” (elements in either set). Set difference. \\(A-B=\\{x| x \\in A, but x \\not \\in B\\}\\) \\(\\subseteq\\) or \\(\\subset\\), subset. \\(=\\), set equivalence. 4.1.5 Venn diagrams Venn diagrams offer an easy way to visualize set operations. The big rectangle can represents the probability space \\(\\Omega\\) or \\(S\\). The disks inside the rectangle can represent probability events \\(A\\), \\(B\\), etc. Also, the following De Morgan’s laws may be useful: \\[(A\\cup B)^c=A^c \\cap B^c \\ \\ \\ \\ \\ {\\rm and}\\ \\ \\ \\ \\ (A\\cap B)^c=A^c\\cup B^c\\] In all the figures S is the region inside the large rectangle, L is the region inside the left circle and R is the region inside the right circle. The shaded region shows the set indicated underneath each figure. The product of sets S and T is the set of ordered pairs: \\(S×T = \\{(s,t) | s∈S, t∈T\\}\\). In words the right-hand side reads \"the set of ordered pairs (s, t) such that s is in S and t is in T. The following diagrams show two examples of the set product. The right-hand figure also illustrates that if \\(A \\subseteq S\\) and \\(B \\subseteq T\\) then \\(A×B \\subseteq S×T\\). If S is finite, we use |S| or #S to denote the number of elements of S. 4.1.5.1 Two useful counting principles are the inclusion-exclusion principle and the rule of product (discussed below in detail). The inclusion-exclusion principle says \\(|A \\cup B| = |A| + |B| − |A \\cap B|\\). We can illustrate this with a Venn diagram. S is all the dots, A is the dots in the blue circle, and B is the dots in the red circle. \\(|A|\\) is the number of dots in A and likewise for the other sets. The figure shows that \\(|A|+|B|\\) double-counts \\(|A \\cap B|\\), which is why \\(|A \\cap B|\\) is subtracted off in the inclusion-exclusion formula. The Rule of Product says: If there are n ways to perform action 1 and then by m ways to perform action 2, then there are n · m ways to perform action 1 followed by action 2. We will also call this the multiplication rule. Example. If you have 3 shirts and 4 pants then you can make 3 · 4 = 12 outfits. An extremely important point is that the rule of product holds even if the ways to perform action 2 depend on action 1, as long as the number of ways to perform action 2 is independent of action 1. To illustrate this: Example 6. There are 5 competitors in the 100m final at the Olympics. In how many ways can the gold, silver, and bronze medals be awarded? Answer: There are 5 ways to award the gold. Once that is awarded there are 4 ways to award the silver and then 3 ways to award the bronze: answer 5 · 4 · 3 = 60 ways. Note that the choice of gold medallist affects who can win the silver, but the number of possible silver medallists is always four. 4.1.6 Basic counting principles 4.1.6.1 Injections, surjections and bijections In mathematics, injections, surjections and bijections are classes of functions distinguished by the manner in which arguments (input expressions from the domain) and images (output expressions from the codomain) are related or mapped to each other. The function is injective, or one-to-one, if each element of the codomain is mapped to by at most one element of the domain, or equivalently, if distinct elements of the domain map to distinct elements in the codomain. The function is surjective, or onto, if each element of the codomain is mapped to by at least one element of the domain. That is, the image and the codomain of the function are equal. The function is bijective (one-to-one and onto, one-to-one correspondence, or invertible) if each element of the codomain is mapped to by exactly one element of the domain. That is, the function is both injective and surjective. A bijective function is also called a bijection. 4.1.6.2 Sum If \\(A\\) and \\(B\\) are disjoint, then \\(|A \\cup B| = |A| + |B|\\). Example. There are 99 math majors, 179 cs majors. How many majors are in math or cs (assume no double majors)? 99 + 179 = 278 Extend sum rule to any number of sets: If \\(A_1, \\ldots, A_n\\) are pairwise disjoint, then \\(|A_1 \\cup \\ldots \\cup A_n| = |A_1| + |A_2| + \\ldots + |A_n|\\). Example. There are 99 math, 179 cs, 24 philosophy. Total in math or cs or philosophy = 302 4.1.6.3 Inclusion-Exclusion What if the sets aren’t disjoint? E.g., math and cs majors, where some people are majoring in both? Consider two sets first. If \\(A\\) and \\(B\\) are any sets (not necessarily disjoint), then \\(|A \\cup B| = |A| + |B|- |A \\cap B|\\). Example. There are 99 math majors, 179 cs majors, 7 majoring in both. How many majors are in math or cs? Solution. 99 + 179 - 7 = 271 How many numbers in \\(\\{1,\\ldots,100\\}\\) are divisible by \\(2\\) or \\(5\\)? \\(50\\) divisible by \\(2\\) \\(20\\) divisible by \\(5\\) \\(10\\) divisible by both \\(2\\) and \\(5\\) total: \\(50+20-10=60\\). The inclusion-exclusion formula expresses the fact that the sum of the sizes of the two sets may be too large since some elements may be counted twice. The double-counted elements are those in the intersection of the two sets and the count is corrected by subtracting the size of the intersection. Example. Suppose a survey of 100 people asks if they have a cat or dog as a pet. The results are as follows: 55 answered yes for cat, 58 answered yes for dog and 20 people checked yes for both cat and dog. How many people have a cat or a dog? Solution: Since 55 have a cat, and 58 have a dog, you may think at first that 55 + 58 = 113 have one or the other. That thinking overlooks that some people – 20 of them – have both, and we counted these people twice by adding 55 and 58. To correct our answer, we must subtract from that sum the number 20: 55 + 58 − 20 = 93 have a cat or a dog. This is an example of the inclusion-exclusion principle. The I-E principle is more clearly seen in the case of three sets, which for the sets A, B and C is given by: \\(|A\\cup B\\cup C|=|A|+|B|+|C|-|A\\cap B|-|A\\cap C|-|B\\cap C|+|A\\cap B\\cap C|\\) 4.1.6.4 Product If \\(A\\) and \\(B\\) are any sets, then \\(| A \\times B| = |A| \\cdot |B|\\). Example. License plates – 3 letters followed by 3 digits: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10\\). Example. The power set. Number of subsets of \\(n\\)-element set (the power set of \\(n\\)-element set)? This is \\(2^n\\). Each subset corresponds to a bit string of length \\(n\\), with a \\(1\\) in position \\(k\\) meaning that the \\(k\\)th element is in the subset. That is, set of subsets has bijection to set of bit strings of length \\(n\\), which has \\(2^n\\) elements. Example. Number of passwords – length \\(8\\), letters and digits, at least one letter. First calculate number of length \\(8\\) strings of letters and digits, counting those with no letters: \\(36^8\\). Then subtract those with no letters: \\(26^8\\). The difference is what’s needed: \\(36^8 - 26^8\\). Example. How many possible 4-digit PINs are there? This can be solved as 10 · 10 · 10 · 10 = 104 = 10, 000. So, there is a one in ten thousand chance that a robber can guess your pin code (randomly). Let’s consider a stronger case where you must use each digit exactly once, so the PIN is exactly 10 digits long. How many such PINs exist? Well, we have 10 choices for the first digit, 9 choices for the second digit, and so forth, until we only have 2 choices for the ninth digit, and 1 choice for the tenth digit. This means there are 362880 possible PINs in this scenario as follows: \\[10 \\times 9 \\times \\ldots \\times 2 \\times 1 = \\prod_{i = 1}^{n = 10} i = 362880\\] There is more general formula: \\[N! = N \\times (N − 1) \\times (N − 2) \\times \\ldots \\times 3 \\times 2 \\times 1 = \\prod_{j=1}^n j\\] \\(N!\\) is read as “N factorial”. It is important to note that \\(0! = 1\\) since there is one way to arrange 0 objects. We know with absolute certainty that \\(1!=1, (n = 1)\\). Thus, we obtain the following: We know that \\(n! = n \\times (n-1)!\\), it follows that \\(1! = 1 \\times (1-1)!\\), it follows that \\(1! = 1 \\times 0!\\), thus, it must be \\(0! = 1\\). For the equation to be true, we must force the value of zero factorial to equal 1. Otherwise, \\(1! \\neq 1\\) which is a contradiction. 4.1.6.5 Complementary counting Example. Suppose we are making a 10-digit PIN, but now at least one digit has to be repeated at least once. How many such PINs exist? Some examples of this PIN would be 1111111111, 01234556788, or 9876598765, but the list goes on! Let’s try our “normal” approach. If we try this, we’ll end up getting stuck. Consider placing the first digit - we have 10 choices. How many choices do we have for the second digit? Is this a repeated digit or not? We can try to find a product of counts of choices for each digit in different scenarios but this can become complicated as we move around which digits are repeated… Another approach might be to count how many PINs don’t satisfy this property, and subtract it from the total number of PINs. This strategy is called complementary counting, as we are counting the size of the complement of the set of interest. The number of possible 10-digit PINs, with no stipulations, is 10^10 (from the product rule, multiplying 10 choices with itself for each of 10 positions). Then, we found above that the 10-digit PINs with no repeats has 10! possibilities (each digit used exactly once). Well, consider that the 10-digit PINs with at least one repeat will be all other possibilities (they could have one, two, or more repeats but certainly won’t have none). This means that we can count this by taking the difference of all the possible 10-digit PINs and those with no repeats. That is: 10^10 − 10! 4.1.6.6 Division Rule One last basic rule: division rule: If there is a \\(k\\) to \\(1\\) mapping from \\(A\\) to \\(B\\), and \\(|A| = n\\), then \\(|B| = n/k\\). How many subsets of size \\(2\\) are there, of a \\(5\\)-element set \\(A\\)? Let \\(S\\) be this set of subsets. First, consider set \\(P\\) of ordered pairs without repeats. Have \\(|P| = 5 \\times 4\\) (since can’t repeat). There’s a \\(2\\) to \\(1\\) mapping from \\(P\\) to \\(S\\) – just ignore the order. So \\(S\\) has \\(20 / 2 = 10\\) elements. Example. How many different ways are there to seat four people around a circular table, where two seatings are considered the same when each person has the same left neighbor and the same right neighbor? To solve this exercise we must first pick a random seat, and assign it to person 1, the rest of seats will be labeled in numerical order, in clockwise rotation around the table. There are 4 seats to choose from when we pick the first seat, 3 for the second, 2 for the third and just 1 option left for the last one. Thus there are 4! = 24 possible ways to seat them. However, since we only consider a different arrangement when they don’t have the same neighbours left and right, only 1 out of every 4 seat choices matter. Because there are 4 ways to choose for seat 1, by the division rule (\\(n/k\\)) there are 24/4 = 6 different seating arrangements for 4 people around the table. 4.1.7 Permutations and Combinations Some problems deal with the number of ways of choosing some particular number of elements from a set. There are two different ways to select them: in a particular order (as a sequence), or just in an (unordered) set. Selections are called permutations when we care about the order, and combinations when we don’t. 4.1.7.1 Choices: With or without replacement? When you are choosing several things, can you choose the same thing more than once? If so, you are choosing with replacement. Example: You buy bagels at a bakery. You can buy more than one blueberry bagel if you want. This is choosing with replacement. Example: You select five players for a basketball team from a pool of 20 candidates. You can not pick the same person more than once. This is choosing without replacement. 4.1.7.2 Choices: Ordered or unordered? When you are choosing several things, does the order in which you select them matter? If so, you are making an ordered choice. Example: You select five players for a basketball team for a pickup game in the park. All five will run on the court together, without organizing positions. This is an unordered choice. Example: You select five players for a basketball team for a formal game with fixed positions: center, power forward, small, forward, shooting guard, and point guard. This is an ordered choice. 4.1.8 Permutations without repetitions An \\(r\\)-permutation (without repetition) of a set of \\(n\\) elements is an ordered arrangement of \\(r\\) of the \\(n\\) elements (all distinct). \\(S=\\{A,B,C\\}\\). The \\(2\\)-permutations are \\((A,B),(B,A),(A,C),(C,A),(B,C),(C,B)\\). \\(6\\) \\(2\\)-permutations How many \\(r\\)-permutations of a set of \\(n\\) elements? \\(n\\) ways to choose first element given first choice, \\(n-1\\) ways to choose second element \\(n-2\\) to choose third overall: \\[n(n-1)\\cdots(n-r+1) = \\frac{n!}{(n-r)!}.\\] Denote this by \\(P(n,r)\\). A permutation of \\(n\\) elements is an \\(n\\)-permutation of them. \\(P(n,n)=n!\\) How many ways can \\(n\\) people stand in a circle? Map each permutation to a ring. \\(n\\) permutations mapped to each ring. By division rule, number of rings is \\(n!/n = (n-1)!\\). 4.1.9 Combinations without repetitions An \\(r\\)-combination (without repetition) of a set of \\(n\\) elements is an (unordered) subset of the \\(n\\) elements. \\(S=\\{A,B,C\\}\\). The \\(2\\)-combinations are \\(\\{A,B\\},\\{A,C\\},\\{B,C\\}\\). \\(3\\) of them. How many \\(r\\)-combinations of a set of \\(n\\) elements? Map each \\(r\\)-permutation to an \\(r\\)-combination by ignoring the order. How many \\(r\\)-permutations mapped to each \\(r\\)-combination? \\(r!\\) - because there are \\(P(r,r) = r!\\) permutations of a given \\(r\\)-combination. By division rule, \\(P(n,r)/r!\\) Denote this by \\(C(n,r)\\), or more commonly as \\({n \\choose r}\\). The number of \\(r\\)-combinations of an \\(n\\)-set is: \\[{n \\choose r} = \\frac{n!}{r!(n-r)!}\\] \\({n \\choose r}\\) is called a binomial coefficient for reasons that will become clear later. How many ways can \\(3\\) distinct numbers be chosen from \\(1,\\ldots,10\\)? This is \\({10 \\choose 3} = \\frac{10!}{3!7!} = 120\\). 4.1.9.1 Useful properties of binomial coefficient Above, we introduced the binomial coefficients \\[{n \\choose r} = \\frac{n!}{r!(n-r)!}\\] These represent the number of ways to choose \\(r\\) elements from a set of \\(n\\) elements, where the order does not matter. Combinations, as opposed to permutations, where the order does matter. (There are \\[\\frac{n!}{(n-r)!}\\] of those.) Let \\(n\\) and \\(r\\) be naturals, \\(0 \\leq r \\leq n\\). Then \\[{n \\choose r} = \\frac{n!}{r!(n-r)!}.\\] Special cases: \\[{n \\choose 1} = n\\] \\[{n \\choose 0} = 1\\] (uses the convention that \\(0! = 1\\)), \\[{n \\choose n} = 1\\] (note symmetry with previous), \\[{n \\choose n-1} = n\\] (symmetry). There are infinitely many interesting identities involving binomial coefficients, e.g.: Suppose \\(0 \\leq r \\leq n\\). Then \\[{n \\choose r} = {n \\choose n-r}.\\] 4.1.10 Permutations with repetitions Recall that an \\(r\\)-permutation of a set of \\(n\\) elements is a sequence of length \\(r\\) of distinct elements. An \\(r\\)-permutation of a set of \\(n\\) elements allowing repetitions is a sequence of \\(r\\) elements, each chosen from the set. (Repeats allowed.) Recall that the number of \\(r\\)-permutations without repetitions is \\(\\frac{n!}{(n-r)!}\\). The number of \\(r\\)-permutations with repetitions is \\(n^r\\). By Product Rule. How many strings of length \\(10\\), of letters A-M? Same as number of \\(10\\)-permutations with repetitions allowed, of the set of letters A-M. \\(13^{10}\\). Given a bag containing \\(5\\) red balls and \\(5\\) blue balls. Experiment involves picking a sequence of \\(4\\) balls (without replacement). How many different color sequences are possible? This is easy – just the number of \\(4\\)-permutations of the set of \\(2\\) elements (red, blue), which is \\(2^4\\). It doesn’t matter here how many red and blue balls there are – just matters that there are more than \\(4\\). Really the unlimited case. 4.1.11 Combinations with repetitions Now we move from permutations with repetition to combinations with repetition. Let \\(S\\) be the set \\(\\{ A, B, C \\}\\). This set has three 2-combinations. That is, there are three ways to choose two distinct elements of \\(S\\) where order does not matter. The three 2-combinations of \\(S\\) are shown below. \\[\\{\\{ A, B \\}, \\{ A, C \\}, \\{ B, C \\}\\}\\] Suppose that we are not required to choose distinct elements of \\(S\\), but rather can choose the same element repeatedly. The resulting sets are called the \\(r\\)-combinations with repetition of the set \\(S\\). Listed below are the six \\(2\\)-combinations with repetition of \\(S\\). \\[\\{\\{ A, B \\}, \\{ A, C \\}, \\{ B, C \\}, \\{ A, A \\}, \\{ B, B \\}, \\{ C, C \\}\\}\\] Strictly speaking, these are multisets (bags), not sets, since an element may appear multiple times. 4.1.11.1 Counting \\(r\\)-Combinations with Repetition The following theorem gives a nice formula for the number of \\(r\\)-combinations with repetition of an \\(n\\)-element set. The number of \\(r\\)-combinations with repetition of an \\(n\\)-element set is \\[\\binom{n + r - 1}{r}.\\] In the example above, we found six ways to choose two elements from the set \\(S = \\{ A, B, C \\}\\) with repetition allowed. Sure enough, the theorem says that the number of 2-combinations of a 3-element set is \\(\\binom{3 + 2 - 1}{2} = 6\\). For comparison, recall that the number of ordinary \\(r\\)-combinations of an \\(n\\)-element set is \\(\\binom{n}{r}\\). Every ordinary \\(r\\)-combination is also a valid \\(r\\)-combination with repetition. So, as one would expect, the number of \\(r\\)-combinations with repetition is greater if \\(r &gt; 1\\). 4.1.11.2 Why is this calculation accurate? Understand it by a thought experiment: Represent each combination concisely by a string of stars and bars. E.g., \\(3R-2B\\) is: ***|**| \\(1R-3B-1G\\) is: *|***|* The two bars are like dividers between compartments, the stars represent how many of each color. In order, red, blue, green. Every combination has a unique representation as a string of \\(5\\) stars and \\(2\\) bars, and every string of \\(5\\) stars and \\(2\\) bars represents a combination. So enough to count the number of different strings of \\(5\\) stars and \\(2\\) bars. This is \\({7 \\choose 2} = {7 \\choose 5} = 21\\). Think of choosing the positions representing the stars (or bars). How many ways to choose 12 doughnuts from 21 varieties? This is a combination problem – order doesn’t matter. Allows repetitions. So it’s asking for the number of \\(12\\)-combinations of a \\(21\\)-set, with repetitions allowed. Formula says \\({21 + 12 - 1 \\choose 12} = ???\\). Intuitively, see in terms of \\(20\\) bars and \\(12\\) stars. Now an equivalent problem – counting the number of ways of putting \\(r\\) indistinguishable balls into \\(n\\) (distinguishable) baskets. To see the equivalence, think of the doughnut problem as putting \\(12\\) indistinguishable “doughnut requests” into the \\(21\\) doughnut bins. Given \\(n\\) baskets in an amusement park arcade game, \\(r\\) balls (all same), how many different results can you get by throwing the balls into the baskets? Again, the number of \\(r\\)-combinations of \\(n\\) elements. Can see this by corresponding each result with a pattern of \\(r\\) stars and \\(n-1\\) bars. \\({n + r - 1 \\choose r}\\) Another equivalent problem: Counting the number of ways to build up a number by addition: In how many ways can a positive integer \\(r\\) be written as the sum of exactly \\(n\\) nonnegative integers, where the order matters? E.g., write \\(7\\) as sum of at most \\(3\\) positive integers: \\(7 + 0 + 0\\), \\(0 + 7 + 0\\), \\(0 + 0 + 7\\), \\(6 + 1 + 0\\), etc. \\(5 + 2 + 0\\), etc. Again, the number of \\(r\\)-combinations of \\(n\\) elements. Can see this by corresponding each sum with a pattern of \\(r\\) stars and \\(n-1\\) bars. The bars are the \\(+\\) signs, the stars are the units being counted. Here, \\({7 + 3 - 1 \\choose 7} = {9 \\choose 7} = 36\\). 4.1.12 Permutations and Combinations with Bounded Repetition 4.1.12.1 Combinations (*) So far, these \\(r\\)-combination problems all allowed arbitrary numbers of occurrences of each element of the set. (Arbitrary number of balls in each basket, arbitrary number for each summation term.) Can also consider variations in which there are constraints on the number of occurrences of each element. Start with some lower bounds: In how many ways can \\(7\\) be written as the sum of exactly \\(3\\) positive integers (that is, no zeros)? In terms of stars and bars, there are \\(7\\) stars and \\(2\\) bars, as before, only now there must be at least one star in each compartment. We can just eliminate consideration of \\(3\\) stars – their position is determined. What’s left is distributing the remaining \\(4\\) stars into the \\(3\\) compartments, which is \\({4 + 3 - 1 \\choose 4} = {6 \\choose 4} = 15\\). In general, to write \\(r\\) as sum of \\(n\\) positive integers (where order matters), where \\(r \\geq n\\), have \\[{(r-n) + (n-1) \\choose r-n} = {r-1 \\choose r-n} = {r-1 \\choose n-1}.\\] Express this as another theorem: The number of \\(r\\)-combinations of \\(n\\) elements, allowing repetitions, and where each element occurs at least once, is \\[{r-1 \\choose n-1}.\\] Same thing here: Given \\(n\\) baskets in arcade, \\(r\\) balls, how many different results in which each basket has at least one ball? This is number of \\(r\\)-combinations of \\(n\\) elements in which each element is represented at least once, which is \\[{r-1 \\choose n-1}.\\] Generalize this to other constraints: Arcade, \\(n\\) baskets, \\(r\\) balls, but now basket \\(i\\) has to have at least \\(b_i\\) balls. Just subtract off the number that are already assigned to baskets, that is, \\(b = \\Sigma_i b_i\\), and allocate the rest to the \\(n\\) baskets. So, the number of \\((r-b)\\)-combinations of \\(n\\) elements, which is \\({r - b + n - 1 \\choose r-b} = {r-b+n-1 \\choose n-1}\\). The number of \\(r\\)-combinations of \\(n\\) elements, with repetitions, and where each element \\(i\\) occurs at least \\(b_i\\) times, is \\[{r-b+n-1 \\choose r-b} = {r-b+n-1 \\choose n-1},\\] where \\(b = \\Sigma_i b_i\\). The following examples use these ideas: In how many ways can the \\(2n+1\\) seats in a congress be divided among three parties so that any two parties can form a majority? (Not distinguishing the individuals here – just the combinations of numbers.) To compute this number, we first compute the number of all assignments of the seats to the parties, without any restrictions. This is the number of \\(2n+1\\)-combinations of \\(3\\) objects (parties) allowing repetitions: \\[{3 + (2n+1) - 1 \\choose 2n+1} = {2n+3 \\choose 2n+1} = {2n+3 \\choose 2}.\\] Second, we compute the number of wrong distributions, i.e., when there is a party with at least \\(n+1\\) seats. We have three choices for this unique party, then we can give it \\(n+1\\) seats and distribute the remaining n seats in \\[{3 + n - 1 \\choose 2} = {n+2 \\choose 2}\\] ways. Thus the number of wrong distributions is \\(3{n+2 \\choose 2}\\), so the number of good distributions is \\[{2n+3 \\choose 2} - 3{n+2 \\choose 2} = \\frac{n(n+1)}{2} = {n+1 \\choose 2}.\\] 4.1.12.2 Permutations (*) One last topic – permutations of elements allowing repeats, with bounds. The general problem is: Given \\(n\\) elements, with upper and/or lower bounds on number of times to use each, how many different \\(r\\)-permutations are there? Simplest case: Where each of the \\(n\\) elements has exact bounds – we’re told exactly how many to use of each. This only makes sense when \\(r\\) is equal to the sum of the bounds. This is the only case we will work out in this course. \\(n=3\\); the elements are the letters P, E, R. The bounds are: \\(P-3\\), \\(E-2\\), \\(R-1\\). \\(r=6\\). How many permutations? Same as asking how many permutations of the word PEPPER. To analyze, subscript each letter to make them distinct, yielding \\(P_1,P_2,P_3,E_1,E_2,R_1\\). This set has \\(6!\\) permutations. However, by mapping all the \\(P_i\\) to \\(P\\) and all the \\(E_i\\) to \\(E\\), we get a \\(3! 2!:1\\) mapping. So by rule of division, we see that the correct number of distinct permutations of PEPPER is \\(\\frac{6!}{3! 2!}\\). The question is the same as asking for the number of permutations of a particular multiset. Let \\(S\\) be a multiset with finite repetition counts \\(b_1,b_2,\\ldots b_n\\), where \\(b_1+b_2+\\ldots +b_n = r = |S|\\). Then the number of permutations of \\(S\\) is \\[\\frac{r!}{b_1!b_2!\\cdots b_n!}.\\] "],["elementary-probability.html", "4.2 Elementary probability", " 4.2 Elementary probability 4.2.1 Introduction Probability origins were concerned primarily with games of chance, and many lectures on elementary probability theory still contain references to dice, playing cards, and coin flips. These lottery-style scenarios give an extremely narrow and restrictive view of what probability is about: lotteries are based on elementary outcomes that are equally likely, but in many situations where quantification of uncertainty is helpful there is no compelling way to decompose outcomes into equally-likely components. In fact, the focus on equally-likely events is characteristic of pre-statistical thinking. In modern texts equally-likely outcomes are used to illustrate elementary ideas, but they are relegated to special cases. It is sometimes possible to compute the probability of an event by counting the outcomes within that event, and dividing by the total number of outcomes. For example, the probability of rolling an even number with a fair six-sided die, i.e., of rolling any of the three numbers 2, 4, or 6, out of the 6 possibilities, is \\(\\frac{3}{6}=\\frac{1}{2}\\). In many situations, however, such reasoning is at best a loose analogy. To quantify uncertainty via statistical models a more general and abstract notion of probability must be introduced. Quantities that are measured but uncertain are formalized in probability theory as {}. More specifically, we set up a theoretical framework for understanding variation based on probability distributions of random variables, and the variation of random variables is supposed to be similar to real-world variation observed in data. 4.2.2 Essential definitions and concepts 4.2.2.1 Probabilities are defined on sets of uncertain events. The calculus of probability is defined for sets, which in this context are called events. That is, we speak of “the probability of the event \\(A\\)” and we will write this as \\(P(A)\\). Events are considered to be composed of outcomes from some experiment or observational process. The collection of all possible outcomes (and, therefore, the union of all possible events) is called the sample space and will be denoted by \\({\\Omega}\\). Because \\({\\Omega}\\) is a set, we might also say that \\({\\Omega}\\) is made up of elements (each of which is an outcome) and to indicate that \\(\\omega\\) is an element of \\({\\Omega}\\) we would write \\(\\omega \\in {\\Omega}\\). Recall the definitions of union and intersection: for events \\(A\\) and \\(B\\) the union \\(A \\cup B\\) consists of all outcomes that are either in \\(A\\) or in \\(B\\) or in both \\(A\\) and \\(B\\); the intersection \\(A \\cap B\\) consists of all outcomes that are in both \\(A\\) and \\(B\\). The complement \\(A^c\\) of \\(A\\) consists of all outcomes that are not in \\(A\\). We say two events are mutually exclusive or disjoint if they have empty intersection. 4.2.2.2 Basic terminology Random experiment - an activity with an observable result, or set of results, for example: tossing a coin, the result being a Head or a Tail. Outcome - an outcome is simply an observable result of an experiment, for example: testing a component, the outcome being a defective or non-defective component. Event - this is just an outcome (a simple event) or set of outcomes to an experiment of interest to the experimenter. Sample Space (\\(S\\) or \\(\\Omega\\)) - a sample space is the set of all possible outcomes of an experiment. An event space F, which is a set of events (for a discrete space, this is its power set \\(2^{|S|}\\)); an event is a set of outcomes in the sample space. A probability function, which assigns each event in the event space a probability, which is a number between 0 and 1. If the sample space can be written in the form of a list (possibly inﬁnite) then it is called a discrete sample space (e.g. number of tosses of a fair coin before Heads occurs). If this is not possible then it is called a continuous sample space (e.g. positions where shells land in a tank battle). 4.2.2.2.1 Sample space The set of all possible outcomes of a random experiment is called a sample space, we denote it by \\(\\Omega\\). Its elements, or points, are called outcomes, they are denoted by \\(\\omega\\). The result of the random experiment is always one point \\(\\omega\\) of \\(\\Omega\\). An event is a part of \\(\\Omega\\) (called a subset of \\(\\Omega\\)). It is often characterized by a certain condition (such as “two Heads are observed in three tosses” or “the bull’s-eye is hit”). Events are denoted by \\(A,B,C,\\) etc. We say that an event \\(A\\) occurs if the random experiment results in an outcome \\(\\omega\\) that belongs in \\(A\\). If \\(\\omega\\) happens to be outside of \\(A\\), the event \\(A\\) does not occur. Each event has a probability, which is a number between 0 and 1. The probability of an event \\(A\\) is denoted by \\(P(A)\\). The entire \\(\\Omega\\) is called a certain event. It always occurs because it contains every possible outcome \\(\\omega\\). So, its probability is one: \\(P(\\Omega)=1\\). There is a special notation \\(\\emptyset\\) for the event that never occurs. It contains no outcomes. Its probability is zero, \\(P(\\emptyset)=0\\). The event \\(\\emptyset\\) is said to be impossible. It is also called an empty set. If \\(A\\) is an event, then the rest of \\(\\Omega\\) is called the complement of \\(A\\) and denoted by \\(A^c\\). If \\(A\\) occurs, \\(A^c\\) doesn’t, and vice versa. The probability of \\(A^c\\) is given by \\(P(A^c)=1-P(A)\\). If \\(A\\) is a part of \\(B\\), we write \\(A\\subseteq B\\) (inclusion). This means that \\(A\\) implies \\(B\\) (i.e., if \\(A\\) occurs, then \\(B\\) also occurs). Then we have \\(P(A)\\leq P(B)\\). The common part of two events, \\(A\\) and \\(B\\), is called their intersection, denoted by \\(A\\cap B\\), or just \\(AB\\). It occurs whenever both \\(A\\) and \\(B\\) occur. The event consisting of all the outcomes that are either in \\(A\\) or in \\(B\\) is called the union of \\(A\\) and \\(B\\), denoted by \\(A\\cup B\\). It occurs whenever \\(A\\) or \\(B\\) occurs. If two events \\(A\\) and \\(B\\) have no common part (no common outcomes; note that in this case \\(A\\cap B=\\emptyset\\)), then \\(A\\) and \\(B\\) are said to be disjoint, or mutually exclusive. They cannot occur simultaneously. In this case we have \\(P(A\\cup B)=P(A)+P(B)\\). 4.2.2.2.2 Probability model An experiment is modeled by a probability space, which is a triplet \\((\\Omega,F,P)\\). We will read this triplet as “Omega, Script F, P.” The first component, Ω, is a nonempty set. Each element ω of Ω (s of S) is called an outcome and Ω is called the sample space. The second component, F, is a set of subsets of Ω called events (i.e. an event space of S). The final component, P, of the triplet \\((\\Omega,F,P)\\), is a probability measure on F, which assigns a probability, P(A), to each event A. The axioms of probability are of two types: event axioms, which are about the set of events F, and probability axioms, which are about the probability measure P. Two important tools that help assign probability measures to events in F are: 1. a random variable, 2. a probability distribution function. We discuss these important concepts in the next lecture. 4.2.2.3 Three definitions of probability Experimental probability In experiments involving chance we use the following terms to talk about what we are doing and the results we obtain: The number of trials is the total number of times the experiment is repeated. The outcomes are the different results possible for one trial of the experiment. The frequency of a particular outcome is the number of times that this outcome is observed. The relative frequency of an outcome is the frequency of that outcome expressed as a fraction or percentage of the total number of trials. For example, when a small plastic cone was tossed into the air 279 times it fell on its side 183 times and on its base 96 times. We say: the number of trials is 279 the outcomes are side and base the frequencies of side and base are 183 and 96 respectively the relative frequencies of side and base are … In the absence of any further data, the relative frequency of each event is our best estimate of the probability of that event occurring. In this case, we write Experimental P(side) = the experimental probability the cone will land on its side when tossed is 0.656 Experimental P(base) = the experimental probability the cone will land on its base when tossed is 0.344 The larger the number of trials, the more confident we are that the estimated probability will be accurate. Naive (classical definition of probability) Historically, the earliest definition of the probability of an event was to count the number of ways the event could happen and divide by the total number of possible outcomes for the experiment. We call this the naive definition since it is restrictive and relies on strong assumptions; nevertheless, it is important to understand, and useful when not misused. When we are working with probabilities, our notation will be P(A). In english, this means ‘the Probability that event A occurred’. So, if A is the event of flipping heads in one flip of a fair coin, then P(A)=.5. The probability of an event occurring, if the likelihood of each outcome is equal, is: \\[P(Event) = \\frac{\\text{number of favorable outcomes}}{\\text{number of outcomes}}\\] This ‘Naive Definition’ is a reasonable place to start, because it’s likely how you have calculated probabilities up to this point. Of course, this is not always the correct approach for real world probabilities (hence the name ‘naive’). For example, imagine a random person running for President of the United States. Using the naive definition of probability, their probability of winning the election is .5; one favorable outcome (winning) divided by the total number of outcomes (winning or losing). Clearly this is a simplified approach; different outcomes often have different probabilities associated with them, so it’s important to realize when the naive definition does and does not apply. In the President case, the ‘losing’ outcome is much more likely, so the naive ‘weighting’ scheme does not apply. Anyways, we often apply the naive definition (correctly, hopefully) automatically: if someone asks you the probability that a fair die rolls a 6, you would say 1/6 because you quickly reason that there are six outcomes (rolls 1 to 6) and one that is favorable (rolling a 6), so the overall probability is just 1/6. In this example, it’s very easy to count the number of favorable outcomes and number of total outcomes; however, counting the number of outcomes can quickly become much more complex. Subjective probability The third type of probability is subjective probability. Subjective probabilities result from intuition, educated guesses, and estimates. For instance, given a patient’s health and extent of injuries, a doctor may feel that the patient has a 90% chance of a full recovery. Or a business analyst may predict that the chance of the employees of a certain company going on strike is 0.25. 4.2.3 Axioms of probability We now state the axioms of probability. Axioms of probability: For all events \\(A\\), \\(P(A) \\geq 0\\). \\(P({S}) = 1\\). If \\(A_1, A_2, \\ldots, A_n\\) are mutually exclusive events, then \\(P(A_1 \\cup A_2 \\cup \\cdots \\cup A_n) = P(A_1) + P(A_2) + \\cdots + P(A_n)\\). A technical point is that in advanced texts, Axiom 3 would instead involve infinitely many events, and an infinite sum: If \\(A_1, A_2, \\ldots,\\) are mutually exclusive events (possibly infinitely many events), then \\(P(\\cup_{i}A_i) = \\sum_{i}P(A_i)\\) where the notations mean that the union and summation extend across all events. Regardless of whether one worries about the possibility of infinitely many events, it is easy to deduce from the axioms the elementary properties we need. Theorem: Three Properties of Probability For any events \\(A\\) and \\(B\\) we have \\(P(A^c)= 1-P(A)\\), where \\(A^c\\) is the complement of \\(A\\). If \\(A\\) and \\(B\\) are mutually exclusive, \\(P(A \\cap B)=0\\). \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\). These facts are often illustrated by analyzing games of chance, which is the context in which many of the basic methods of probability were first worked out. For instance, in picking at random a playing card from a standard 52-card deck, we may compute the probability of drawing a spade or a face card, meaning either a spade that is not a face card, or a face card that is not a spade, or a face card that is also a spade. We take \\(A\\) to be the event that we draw a spade and \\(B\\) to be the event that we draw a face card. Then, because there are 3 face cards that are spades we have \\(P(A \\cap B)=\\frac{3}{52}\\), and, appying the last formula above, we get \\(P(A \\cup B) = \\frac{1}{4} + \\frac{3}{13} - \\frac{3}{52} = \\frac{11}{26}\\). This matches a simple enumeration argument: there are 13 spades and 9 non-spade face cards, for a total of 22 cards that are either a spade or a face card, i.e., \\(P(A \\cup B) = \\frac{22}{52} = \\frac{11}{26}.\\) The main virtue of such formulas is that they also apply to contexts where probabilities are determined without reference to a decomposition into equally-likely sub-components. Coin tossing example. Toss a coin three times. What are possible outcomes? What is the chance to observe exactly two Heads? Solution: We know (by the product rule) that the result of three tosses can be recorded by a string of H’s and T’s of length three. There are 8 such strings: \\[\\begin{array}{cccc} &amp; HHT &amp; HTT &amp; \\\\ HHH &amp; HTH &amp; THT &amp; TTT \\\\ &amp; THH &amp; TTH &amp; \\end{array}\\] Three strings (in the second column) contain exactly two Heads, so the chance to observe two Heads is 3/8. Example [infinite sample space] Suppose, a stubborn person tosses a coin until it lands on Head. What are possible outcomes? What is the chance that three or more tosses will be necessary? Solution: The coin may land on Head at once, or else it may land on Tail once or several times before it lands on Head. The experiment ends when Head appears. The possible outcomes are: \\[H,\\ \\ TH,\\ \\ TTH,\\ \\ TTTH,\\ \\ldots,\\ \\underbrace{T\\ldots T}_{n-1}H,\\ \\ldots\\] The probability of any string of T’s and H’s of length \\(n\\) is \\(1/2^{n}\\). So, the above outcomes have the corresponding probabilities \\[1/2,\\ \\ 1/4,\\ \\ 1/8,\\ \\ 1/16,\\ \\ldots,\\ 1/2^n,\\ \\ldots\\] One knows from calculus that the sum of these numbers equals one, i.e. \\[\\frac 12 +\\frac 14 +\\frac 18+\\cdots +\\frac{1}{2^n}+\\cdots = 1\\] The probability that three or more tosses are necessary is found by the summation \\[\\frac 18 +\\frac{1}{16}+\\cdots+\\frac{1}{2^n}+\\cdots=\\frac 14\\] Example [uncountable sample space (continuous data)] One shoots at a target that is a round disk of radius 30 inches. Assuming that the arrow lands anywhere in the target arbitrarily, what is the chance that the bull’s-eye, the inner disk of radius 10 inches, will be hit? Solution. The outcome of this experiment is the point where the arrow lands. All the points on the surface of the target are possible outcomes. It is important to note: one cannot assign positive probabilities to individual points (outcomes). Instead, one associates the probability to hit any region on the target surface with the area of that region. So, the probability to hit the bull’s-eye is proportional to its area, or more precisely it is the relative area of the bull’s-eye on the target: \\[\\frac{\\pi\\, 10^2}{\\pi\\, 30^2}=\\frac 19\\] (Remember: the area of a disk of radius \\(r\\) equals \\(\\pi r^2\\).) We summarize the above three examples. A random experiment always has more than one possible outcome. The collection (set) of all possible outcomes can be described and represented by a list, chart or a geometric figure. In probability theory, one is interested in probabilities of certain parts of that collection of outcomes, or subcollections (subsets) of outcomes. The probability is a number between 0 and 1. 4.2.4 Further examples 4.2.4.1 Example 1 You arrive randomly between 1:30 and 1:45. What is the probability that you will arrive before 1:35? Obviously, the favourable length is 5 minutes, while the total length is 15 minutes. Hence, Pr(you arrive before 1:35)=favourably length/total length=5/15=1/3. 4.2.4.2 Example 2 You arrive randomly between 2:00 and 2:30. What is the probability that you arrive between 2:15 and 2:20? The favorable length is 5 minutes and the total length is 30 minutes. Hence, Pr(you arrive between 2:15 and 2:20) = 1/6. What is the probability you arrive at 2:15? It is zero, because 2:15 has length zero. In this model only intervals of time (lengths) have probability greater than zero. 4.2.4.3 Example 3 A movie starts at 5:00, 5:15, and 5:30, and that you get to the movie theater at random between 5:00 and 5:30. What is the probability that you’ll have to wait 5 minutes or less before the movie starts? We can model the situation with a length of 30 and note that if you get there between 5:10 and 5:15 you will wait 5 minutes or less, and similarly if you get there between 5:25 and 5:30. So, the favourable length is 10 minutes, while the total length is 30 minutes. Hence, Pr(you wait less then 5 minutes)=10/30, that is, 1/3. Remark. Note that if what is picked is one-dimensional (a number, the time of arrival of one person, for example) then the model is one-dimensional, that is, a line. So, if the probability is uniformly distributed within an interval [a,b], then one models what is picked by a variable x such that a≤x≤b and determines the probability by dividing the favorable length by the total length. However, if what is picked is two-dimensional (two numbers, the time of meeting of two persons, for example), then the model is two-dimensional, that is a rectangle, for example. So, if the probability is uniformly distributed within two (possibly identical) intervals [a,b] and [c,d], then one models the event by two numbers x and y such that a≤x≤b and c≤y≤d, and the probability space by the rectangle abcd. The relevant probability is obtained by dividing the favorable area (typically obtained by determining the graph of an inequality) by the total area. More generally, an n-dimensional problem is modeled in an n-dimensional probability space. 4.2.5 Conditional Probability and Independence A friend tosses a coin three times. You accidentally notice that the first time the coin shows Head. What is the chance that the friend observes 2 Heads? Solution. In a previous example, we found all eight possible outcomes. Now, with the additional information at our disposal, we can exclude the outcomes starting with a T. Only four possible outcomes remain: HHH, HHT, HTH, HTT. Two of them contain exactly two Heads. So, the chance is 2/4=1/2. Note that here we have two events: \\(A=\\{\\text{2 Heads are observed}\\}\\) and \\(B=\\{\\text{First toss is Heads}\\}\\). We know that \\(P(A)=3/8\\). Now, the event \\(A\\) is considered under the condition that the event \\(B\\) has occurred. Then the conditional probability of \\(A\\), given \\(B\\), is found by calculating the fraction of \\(A\\) within \\(B\\), i.e. the fraction of \\(A\\cap B\\) within \\(B\\). Conditional probability. The conditional probability of an event \\(A\\), given an event \\(B\\), is \\[P(A|B)=\\frac{P(A\\cap B)}{P(B)}\\] 4.2.6 Multiplication rule The formula for conditional probability can be rewritten as \\[P(A\\cap B)=P(B)\\cdot P(A|B)\\] Due to the symmetry, one can rewrite this as \\[P(A\\cap B)=P(A)\\cdot P(B|A)\\] Example. A deck of 52 cards has 13 spades. If two cards are drawn from the deck at random, what is the chance that both are spades? Solution. Let \\(A=\\{\\)First card is a spade\\(\\}\\) and \\(B=\\{\\)Second card is a spade\\(\\}\\). Clearly, \\(P(A)=13/52=1/4\\). If the first card is a spade, then the chance to draw another spade is 12/51 (the remaining deck of 51 cards has 12 spades left). This means that \\(P(B|A)=12/51\\). Hence, \\[P(A\\cap B)=P(A)\\cdot P(B|A)=\\frac 14\\cdot\\frac{12}{51}=\\frac{12}{204}\\] Extended multiplication rule. If \\(A_1,A_2,\\ldots,A_n\\) are events, then \\[P(A_1\\cap A_2\\cap\\cdots\\cap A_n)=P(A_1)\\cdot P(A_2|A_1)\\cdot P(A_3|A_1\\cap A_2)\\cdots P(A_n|A_1\\cap\\cdots\\cap A_{n-1})\\] Partition. Let \\(B_1,\\ldots,B_n\\) be disjoint (i.e., mutually exclusive) events; i.e. \\(B_i\\cap B_j=\\emptyset\\). Let \\(\\cup B_i=\\Omega\\), i.e. these events cover (exhaust) the entire probability space. We call \\(\\{B_1,\\ldots, B_n\\}\\) a partition of \\(\\Omega\\). 4.2.6.1 Two-stage experiments Amanda rolls a die and then flips a coin the number of times shown on the die. What is the chance she observes two Heads? Solution: In the first stage, the die shows one of the six numbers \\(1,\\ldots,6\\). These are six events, which we denote by \\(B_1,\\ldots,B_6\\). They are disjoint and exhaust all the possibilities, so they make a partition. In the second stage, the event \\(A=\\{\\)Two Heads are observed\\(\\}\\) may (or may not) occur. Applying the law of total probability gives \\[\\begin{aligned} P(A)&amp;=&amp;P(B_1)\\cdot P(A|B_1)+\\cdots +P(B_6)\\cdot P(A|B_6)\\\\ &amp;=&amp;\\frac 16 \\cdot 0 +\\frac 16 \\cdot \\frac 14 +\\frac 16 \\cdot \\frac 38 +\\frac 16 \\cdot \\frac {C_{4,2}}{2^4} +\\frac 16 \\cdot \\frac{C_{5,2}}{2^5}+\\frac 16 \\cdot\\frac{C_{6,2}}{2^6} =\\frac{33}{128}\\end{aligned}\\] Roll a die twice. If the first roll is a six, what is the chance the second roll will be a six? Solution. Let \\(A=\\{\\)The second roll is a six\\(\\}\\) and \\(B=\\{\\)The first roll is a six\\(\\}\\). Then \\[P(A|B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{1/36}{1/6}=\\frac 16\\] Note that \\(P(A)=1/6\\), so that \\[P(A|B)=P(A)\\] In other words, the probability of \\(A\\) does not change when the event \\(B\\) occurs, the event \\(B\\) does not affect the chance of \\(A\\) to occur. 4.2.7 Independent events Two events, \\(A\\) and \\(B\\), are said to be independent if \\[P(A|B)=P(A)\\] By using 3.2, we can rewrite this equation as \\[P(A\\cap B)=P(A)\\, P(B)\\] and also as \\[P(B|A)=P(B)\\] All these three equations mean the same: the independence of \\(A\\) and \\(B\\). Note: The equation \\(P(A\\cap B)=P(A)P(B)\\) is better the other two: it is symmetric. It also works when \\(P(A)=0\\) or \\(P(B)=0\\). So, it is preferred for practical purposes. Example. Flip two coins. Let \\(A=\\{\\)First coin shows Head\\(\\}\\) and \\(B=\\{\\)Both coins show the same face\\(\\}\\). Are \\(A\\) and \\(B\\) independent? Solution. One easily finds that \\(P(A)=1/2\\), \\(P(B)=1/2\\) and \\(P(A\\cap B)=1/4\\). Then we check that \\(1/2\\times 1/2=1/4\\). Yes, they are independent. Note: Sometimes the independence is obvious, like in 3.11 (because there is no way the result of the first roll can affect the second). Sometimes the independence is harder to recognize, as it is in 3.13 above. One can explain the independence in 3.13 noting that the second coin may or may not show the same face as the first with probability 1/2, no matter what face the first coin shows. Independence of three events. Three events \\(A,B,C\\) are said to be mutually (or jointly) independent if any two of them are independent in the sense of 3.12, and the following holds: \\[P(A\\cap B\\cap C)=P(A)\\, P(B)\\, P(C)\\] Neither one of the conditions (a) and (b) alone is enough for joint independence. One needs to check both (a) and (b) to verify the joint independence of \\(A,B,C\\). 4.2.8 Law of total probability Let \\(\\{B_1,\\ldots, B_n\\}\\) be a partition of \\(\\Omega\\), and \\(A\\) an event. Then \\[P(A)=P(B_1)\\cdot P(A|B_1)+\\cdots +P(B_n)\\cdot P(A|B_n)\\] One can think of \\(B_1,\\ldots,B_n\\) as conditions under which the event \\(A\\) may occur. The events \\(B_1,\\ldots,B_n\\) are also called hypotheses. Example. Alex goes to school by bus or train, whichever comes first. He notice that the bus comes first with probability 30% and the train with probability 70%. When Alex takes train, he arrives late to school with probability 5%. When he takes bus, he is late to school with probability 20%. What is the probability that he is late to school? Solution. The event in question here is \\(A=\\{\\)Alex is late to school\\(\\}\\). This may happen under two conditions (hypotheses): \\(B_1=\\{\\)Alex takes bus\\(\\}\\) and \\(B_2=\\{\\)Alex takes train\\(\\}\\). Hence, \\[P(A)=P(B_1)\\cdot P(A|B_1)+P(B_2)\\cdot P(A|B_2)=0.3\\times 0.2+0.7\\times 0.05=0.095\\] 4.2.9 Bayes’ theorem Example. A rocket has a built-in redundant system. It has three components, \\(K_1,K_2,K_3\\). If component \\(K_1\\) fails, it is bypassed and component \\(K_2\\) is used, etc. So, as long as one component works the system is functioning. Suppose that the probabilities of failure of the components are 10%, 20% and 5%, respectively. Find the probability that the entire system works. Solution. First, note: \\(P(\\)system works\\()=1-P(\\)system fails\\()\\). The system fails if all the three components fail. The failures are mutually independent events, so \\[P({\\rm system}\\ {\\rm fails})=0.1\\cdot 0.2\\cdot 0.05=0.001\\] So, the entire system will function with probability 99.9%. Note a very high reliability! An additional note: it is more difficult to find the probability that two components fail. Because they can fail in various combinations: \\(\\{1,2\\}\\), \\(\\{1,3\\}\\), and \\(\\{2,3\\}\\). In each case the remaining component is assumed to work. Therefore, the probability that two components fail is \\[\\begin{aligned} P({\\rm two}\\ {\\rm fail})&amp;=&amp;P(1,2\\ {\\rm fail})+P(1,3\\ {\\rm fail})+P(2,3\\ {\\rm fail})\\\\ &amp;=&amp;0.1\\cdot 0.2\\cdot 0.95+0.1\\cdot 0.8\\cdot 0.05+0.9\\cdot 0.2\\cdot 0.05=0.032\\end{aligned}\\] Remark. If \\(A_1,\\ldots,A_n\\) are independent, one can replace any number of these events by their complements (e.g., \\(A_1\\) by \\(A_1^c\\), etc.) and the new collection of events will be also independent. Bayes formula. Recall the law of total probability in 3.8 and suppose we need to compute \\(P(B_i|A)\\) for some \\(i=1,\\ldots,n\\). By using the formulas in 3.2-3.3 we get \\[P(B_i|A)=\\frac{P(B_i\\cap A)}{P(A)}=\\frac{P(B_i)\\cdot P(A|B_i)}{P(A)}\\] Now we replace the denominator \\(P(A)\\) by its expansion given by the law of total probability and obtain \\[P(B_i|A)=\\frac{P(B_i)\\cdot P(A|B_i)}{P(B_1)\\cdot P(A|B_1)+\\cdots +P(B_n)\\cdot P(A|B_n)}\\] This is called Bayes formula. Note that the numerator here is one of the terms that appear in the denominator. 4.2.10 Various examples (*) 4.2.10.1 Example You roll a six-sided die. What is the probability of getting an even number? Solution. Since \\(E = \\{2, 4, 6\\}\\), \\(S = \\{1, 2, 3, 4, 5, 6\\}\\), then \\[P(E) = \\frac{3}{6} = \\frac{1}{2}\\] 4.2.10.2 Example You roll two fair dice numbered from 1 to 6. Find the probability of rolling 1 on the first die and 2 on the second one. Solution. Since \\(E = \\{(1, 2)\\}\\) and \\(S = \\{(1, 1), (1, 2), (2, 1), ..., (6, 5), (6, 6)\\}\\), then \\(P(X = (1, 2)) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}\\) To find the total number of possible outcomes, you need to apply multiplication principle (the rule of product). \\(n(S) = |S| = k_1 \\times k_2 = 6 \\times 6 = 36\\) 4.2.10.3 Example You roll a fair die. What is the probability of getting an even number? Solution. \\(E = E_1 \\cup E_2 \\cup E_3\\). You can see that events \\(E_1, E_2, E_3\\) are disjoint, then \\(P(E = E_1 \\cup E_2 \\cup E_3) = P(E_1) + P(E_2) + P(E_3) = \\frac{3}{6}\\) You roll a fair die. What is the probability of getting an even number (A) and the number greater or equal to 4 (B)? Are events A and B independent? Solution. Let’s find the intersection of events A and B, \\(A \\cap B\\). \\(A = \\{2, 4, 6\\}, B = \\{4, 5, 6\\}\\), then \\(A \\cap B = \\{4, 6\\}\\). \\[P(A \\cap B) = \\frac{|A \\cap B|}{|S|} = \\frac{2}{6} = \\frac{1}{3}\\] Also, \\[P(A) = \\frac{|A|}{|S|} = \\frac{3}{6} = \\frac{1}{2}, P(B) = \\frac{|B|}{|S|} = \\frac{3}{6} = \\frac{1}{2}\\] then, \\[P(A)P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\] We conclude that events A and B are dependent, on the basis of the test for independence: \\[P(A)P(B) \\neq P(A \\cap B)\\] 4.2.10.4 Example Roll two fair dice. What is the probability of getting the sum of the two dice equal 7 and an even number on the second die? Let \\(A = \\{ (1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1) \\}\\) \\[P(A) = \\frac{|A|}{|S|} = \\frac{6}{36} = \\frac{1}{6}\\] Let \\(B = \\{ (1, 6), (1, 4), (1, 2), (2, 6), (2, 4), ... \\}\\) We can notice that, by product rule, we have \\(|B| = 6 \\times 3\\), Thus, \\[P(B) = \\frac{|B|}{|S|} = \\frac{6 \\times 3 = 18}{36} = \\frac{1}{2}\\] Finally, \\[P(A \\cap B) = \\frac{|A \\cap B|}{|S|} = \\frac{3}{36} = \\frac{1}{12}\\] Also, \\[P(A)P(B) = \\frac{1}{6} \\times \\frac{1}{2} = \\frac{1}{12}\\] Employing the test for independence of events: \\[P(A)P(B) = P(A \\cap B)\\] - Events A and B are independent. 4.2.10.5 Example You roll three fair dice. What is the probability of rolling a combination of the numbers 1, 3, 5? Solution. We need to answer two questions. “What are the odds of getting any particular combination, in order, on three dice?”. The second is “How many orderings are there of the numbers 1, 3, and 5?”. The answer to the first question is that there is a 1 in 216 chance of getting a specific, particular ordering of results from three dice. For \\((1,3,5)\\), you have to get 1 on the first die (1 in 6 chance), 3 on the second (1 in 6 chance), and 5 on the third (1 in 6 chance). For \\((3,1,5)\\), the odds are the same. And so on. The answer to the second question is that there are 6 possible orderings of three distinct digits: \\((1,3,5), (1,5,3), (3,1,5), (3,5,1), (5,1,3), \\text{and } (5,3,1)\\). That’s because there are 3 possible choices for the first digit, 2 possible choices for the second digit, and 1 possible choice for the last digit. Combining these two answers, we find that for each of the 6 possible orderings, there is a 1 in 216 chance of getting that specific result. Since each possibility is distinct, we can just add them together to get a 6 in 216 chance of getting the numbers \\({1, 3, 5}\\) in some order on three dice. Finally, the probability is \\((1/6 \\times 1/6 \\times 1/6) \\times (3 \\times 2 \\times 1)\\) 4.2.10.6 Example Three dice are thrown. What is the probability that the same number appears on exactly two of the three dice? Solution. Since you need exactly two to be the same, there are three possibilities: (1) First and second, not third, (2) First and third, not second, (3) Second and third, not first. For the first possibility (1): The first die, you have probability of 6/6. The second die needs to be equal to the first, so you have probability of 1/6. Then the third die can’t be equal to the first and second die, so it’s 5/6. Finally you get \\(1\\times \\frac{1}{6} \\times \\frac{5}{6}\\). And since the next two possibilities (2) and (3) yield the same result, then the probability that the same number appears on exactly two of the three dice is \\[3 \\times (1 \\times \\frac{1}{6} \\times \\frac{5}{6}) = \\binom{3}{2}(1 \\times \\frac{1}{6} \\times \\frac{5}{6}) = \\frac{5}{12}\\] "],["random-variables-and-probability-distributions-lecture-5-draft-copy-ver-0-44.html", "5 Random variables and probability distributions [Lecture 5 - draft copy, ver. 0.44] ", " 5 Random variables and probability distributions [Lecture 5 - draft copy, ver. 0.44] "],["random-variable-and-probability-distribution-definitions.html", "5.1 Random variable and probability distribution - definitions", " 5.1 Random variable and probability distribution - definitions Let S be the sample space of an experiment. The outcomes can take any form such as colors, letters, or brands of cat food. A random variable is any function \\(X\\) that converts outcomes into real numbers: \\(X: S \\rightarrow R\\) For a given outcome \\(s \\in S\\) we use the functional notation \\(X(s) \\in R\\) to denote the associated real number. A random variable is a numerical description of the outcome of a statistical experiment. A random variable that may assume only a finite number or an infinite sequence of values is said to be discrete; one that may assume any value in some interval on the real number line is said to be continuous. The probability distribution for a random variable describes how the probabilities are distributed over the values of the random variable. In probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes (or of values of a random variable) for an experiment. 5.1.1 Random variables Figure 5.0. RV and PDF - summary 5.1.1.1 Random variable and probability distribution function for a single toss of a fair coin The possible outcomes for one coin toss can be described by the sample space \\(S =\\{\\text{heads},\\text{tails}\\}\\). We can introduce a real-valued random variable \\(X(S)\\) that models a $1 payoff for a successful bet on heads as follows: \\[ \\begin{equation} X(S)= \\begin{cases} 0, &amp; \\text{if } s_1 = \\text{ heads} \\\\ 1, &amp; \\text{if } s_2 = \\text{ tails} \\end{cases} \\end{equation} \\] If the coin is a fair coin, rv. \\(X\\) has a probability distribution function \\(P(X_{(S)})\\) given by: \\[ \\begin{equation} P(X)= \\begin{cases} 1/2, &amp; \\text{if } X(S) = 1 \\\\ 1/2, &amp; \\text{if } X(S) = 0 \\end{cases} \\end{equation} \\] 5.1.1.2 Two dice flip A random variable can also be used to describe the process of rolling dice and the possible outcomes. The most obvious representation for the two-dice case is to take the set of pairs of numbers n1 and n2 from \\(S = \\{1, 2, 3, 4, 5, 6\\}\\) (representing the numbers on the two dice) as the sample space S. The total number rolled (the sum of the numbers in each pair) is then a random variable X given by the function that maps the pair to the sum, as follows: \\[X((n_1, n_2)) = n_1 + n_2\\] 5.1.1.3 Three flips of a coin For example, suppose that a coin is flipped 3 times. Let us encode the outcomes as strings of the symbols H and T, so the sample space is \\(S \\in \\{TTT,TTH,THT,HTT,THH,HTH,HHT,HHH\\}\\). Let X be the number of heads that we get. We can think of this as a function \\(X: S \\in R\\) that takes in a string of symbols \\(s \\in S\\) and returns the number \\(X(s)\\) of Hs that this string contains. Here is a part of the “graph” of this function: \\((H, H, H) \\rightarrow 3\\); \\((H, H, T) \\rightarrow 2\\); \\((T, H, H) \\rightarrow 2\\); \\((...) \\rightarrow ...\\); (…) \\((T, T, T) \\rightarrow 0\\). We will use the notation \\(X(S) \\subseteq R\\) to denote the set of all possible values of the random variable X, which we call the “support” of the random variable. In this example we have \\(X(S) \\in \\{0,1,2,3\\}\\). Let \\(S=\\) outcomes of 3 coin tosses = \\(\\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\}\\). \\(R_H =\\) number of H in outcome. So \\(R_H(HHH)=3, R_H(HHT)=2\\). \\(R_M(p) =\\) 1 if all coins match, 0 otherwise. So \\(R_M(HHH)=1, R_M(HHT)=0\\). \\(R_M\\) is an indicator or characteristic random variable: \\(1\\) if event happens, \\(0\\) otherwise. Note functions: \\(R_H:S\\rightarrow \\{0,1,2,3\\},\\; R_M:S\\rightarrow \\{0,1\\}\\) 5.1.1.4 Bernoulli random variable An indicator (or Bernoulli or characteristic) random variable is a random variable with range 0,1. A random trial having only 2 possible outcomes (Success, Failure) is called a Bernoulli trial, e.g., - Tossing a coin, the outcomes are head or tail. - Whether a drug works on a patient or not. - Whether a randomly selected eligible voter will vote in the upcoming general election or not. A random variable partitions \\(S\\) into events (subsets of sample points). Note that indicators partition the sample space into two events. 5.1.2 Probability distribution (function) For both discrete and continuous variables, the collection of all the possible values and the probabilities associated with them is called the probability model (the probability distribution function) for the random variable; a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. Figure 5.1. Probability distribution for the random variable X defined as the number of heads in two tosses of a coin Suppose n independent Bernoulli trials are to be performed, each of which results in - a success with probability p or - a failure with probability 1 − p. If we define X = the number of successes that occur in the n trials, then X is said to have a binomial distribution with parameters (n, p). "],["how-to-define-random-variable-and-probability-distribution-an-example.html", "5.2 How to define random variable and probability distribution - an example", " 5.2 How to define random variable and probability distribution - an example In an experiment, we throw three coins (\\(n = 3\\)) and we are interested in the probability of throwing \\(k\\) Heads \\((H)\\) - we assume that getting \\(H\\) is a success and throwing \\(T\\) is a failure. Define a random variable on the sample space and construct a probability distribution for the experiment. The experiment from the example is called a binomial experiment. We begin with the sample space \\(S\\). The sample space contains possible outcomes of the experiment. \\(S = \\{ (H, H, H), (H, H, T), (H, T, T), (T, T, T), (T, T, H), (T, H, H), (T, H, T), (H, T, H) \\}\\). We can compute the number of elements in S (\\(|S|\\)) using the fundamental principle of counting (the product rule). In our example we have \\(2^3 = 8\\) (eight 3-permutations from the set \\(X = \\{H, T\\}\\), and \\(|X| = 2\\)). To construct a random variable we need to assign real numbers to the outcomes of the experiment. For example, we can define a rv Y and assign: \\((H, H, H) \\rightarrow 3\\); \\((H, H, T) \\rightarrow 2\\); \\((T, H, H) \\rightarrow 2\\); \\((...) \\rightarrow ...\\); \\((T, T, T) \\rightarrow 0\\). Then, if we assign the probability to each value of the random variable Y = {0, 1, 2, 3}, \\(P(Y = ...) = ...\\), we will finally construct the probability distribution function for this rv (See the table 1.1). Probability distribution of Y y f(y) = p computations 1 0 1/8 \\(f(x; n=3, p=0.5) = \\binom{3}{0}0.5^0(1-0.5)^3\\) 2 1 3/8 \\(f(x; n=3, p=0.5) = \\binom{3}{1}0.5^1(1-0.5)^2\\) 3 2 3/8 \\(f(x; n=3, p=0.5) = \\binom{3}{2}0.5^2(1-0.5)^1\\) 4 3 1/8 \\(f(x; n=3, p=0.5) = \\binom{3}{3}0.5^3(1-0.5)^0\\) - - 1 - In general, the probability of getting heads in trials is: \\[P(X = x) = f(x; n = \\text{the number of trials}, p = \\text{the probability of success}) = \\\\ = \\binom{n}{x} p^x(1-p)^{n-x} = \\frac{n!}{(n-x)!x!} p^x(1-p)^{n-x}, \\text{ for } x = 0, 1, 2, ..., n\\] Why is the probability of, for example, tossing one head (1 success) equal to \\(3/8\\)? In the example, the probability of getting heads is \\(1/2\\), therefore, the probability of getting tails is also \\(1/2\\), because \\(1-1/2 = 1/2\\). The random experiment from the example is composed of 3 levels (trials) (it is a compound experiment): first toss (first trial), second toss (second trial), third toss (third trial). In compound experiments, we employ the multiplication rule (in the example we use the multiplication rule for independent events) to compute probabilities. We begin with computing the probability of getting one head in 3 trials in a particular order: \\[P((H,T,T)) = P((1,0,0)) = p^1 \\times (1-p)^2 = (1/2)^1 \\times (1/2)^2 = 1/8\\] \\[P((T,H,T)) = P((0,1,0)) = (1-p) \\times p \\times (1-p) = (1/2) \\times (1/2) \\times (1/2) = 1/8\\] \\[P((T,T,H)) = P((0,0,1)) = (1-p)^2 \\times p^1 = (1/2)^2 \\times (1/2)^1 = 1/8\\] Then, the probability of getting one head in 3 trials in any order is: \\[P(\\{(H,T,T), (T,H,T), (T,T,H)\\}) = P((H,T,T)) + P((T,H,T)) + P((T,T,H)) =\\] \\[= 1/8 + 1/8 + 1/8 = 3/8 =\\] \\[= \\binom{3}{1} \\times (1/2)^1 \\times (1/2)^2 = 3 \\times (1/2)^1 \\times (1/2)^2 = 3/8\\] In general, the probability of getting x heads in n trials in any order is: \\[P(X = x) = f(x; n = \\text{number of trials}, p = \\text{probability of success}) = \\\\ = \\binom{n}{x} p^x(1-p)^{n-x} = \\frac{n!}{(n-x)!x!} p^x(1-p)^{n-x}, \\text{ for } x = 0, 1, 2, ..., n\\] Notice that \\(\\binom{3}{1} = |\\{\\{1\\}, \\{2\\}, \\{3\\}\\}| = 3\\) - it is a number of 1-element combinations from the set of 3 elements. As for the binomial experiment, we can think of every single combination as a set of coordinates that indicates the place of success/successes in a sequence of outcomes. In our example, the elements of sets \\(\\{1\\}, \\{2\\}, \\{3\\}\\) indicate that success (heads) can appear only in the first trial, only in the second, or only in the third trial. If we have for example \\(\\binom{3}{2} = 3 = |\\{\\{1,2\\}, \\{1,3\\}, \\{2,3\\}\\}|\\), the elements of sets \\(\\{1,2\\}, \\{1,3\\}, \\{2,3\\}\\) indicate that heads can appear in the first and second trial, in the first and third, or in the second and third trial. Do not confuse \\((H, T, H)\\) - the sequence (the order of elements is important) - with the set \\(\\{H, T, H\\} = \\{H, T\\} = \\{T, H\\}\\) "],["discrete-probability-distributions-bernoulli-and-binomial-distributions.html", "5.3 Discrete probability distributions - Bernoulli and binomial distributions", " 5.3 Discrete probability distributions - Bernoulli and binomial distributions Wikipedia.org gives a good and concise definition of Binomial distribution: \"In probability theory and statistics, the binomial distribution with parameters \\(n\\) and \\(p\\) is the discrete probability distribution of the number of successes in a sequence of \\(n\\) independent yes/no experiments [usually called a binomial experiment - M.P], each of which yields success with probability \\(p\\). A success/failure experiment is also called a Bernoulli experiment or Bernoulli trial; when \\(n\\) = 1, the binomial distribution is a Bernoulli distribution. (…) The binomial distribution is frequently used to model the number of successes in a sample of size \\(n\\) drawn with replacement from a population of size \\(N\\). If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a hypergeometric distribution, not a binomial one. However, for \\(N\\) much larger than \\(n\\), the binomial distribution is a good approximation, and widely used\". 5.3.1 Binary random variables and Binomial distribution A binary variable (the Bernoulli variable) is a variable that has two possible outcomes. For example, sex (male/female) is an example of a binary categorical variable. A random variable can be transformed into a binary variable by defining a “success” and a “failure”. For example, consider rolling a fair six-sided die and recording the value of the face. The random variable, value of the face, is not binary. If we are interested, however, in the event A={an even number is rolled}, then the “success” is rolling 2, 4, or 6. The failure would be any value not equal to 2, 4, 6. Therefore, we can create a new variable with two outcomes, namely A = {2, 4, 6} and B = {not an even number} or {1, 3, 5}. This new variable is now a binary variable. For the Bernoulli random variable, we can define the Bernoulli distribution. The Bernoulli distribution, named after Swiss mathematician Jacob Bernoulli, is the discrete probability distribution of a Bernoulli random variable which takes the value 1 with probability p and the value 0 with probability q = 1. It can be thought of as a model for the set of possible outcomes of any single experiment that asks a yes–no (binary) question. This gives outcomes that are boolean-valued: success/yes/true/one with probability p and failure/no/false/zero with probability q. 5.3.1.1 Binomial experiment We have a binomial experiment if ALL of the following four conditions are satisfied: The experiment consists of n finite identical trials. Each trial results in one of the two outcomes, called success and failure. The probability of success, denoted p, remains the same from trial to trial. The n trials are independent. That is, the outcome of any trial does not affect the outcome of the others. If the four conditions are satisfied, then the random variable X = number of successes in n trials, is a binomial random variable with: \\(\\mu = np\\) and \\(\\sigma^2 = np(1-p)\\) For the binomial experiment, if we define a random variable X as the sum of “successes” in the n trials of the binomial experiment, the probability distribution function for rv. X is known as a binomial distribution. 5.3.1.2 The Binomial formula For a binomial random variable with probability of success, p, and n trials… \\[P(Y = k) = f(y; n = \\text{the number of trials}, p = \\text{a probability of success}) = \\\\ = \\binom{n}{k} p^x(1-p)^{n-k} = \\frac{n!}{(n-k)!k!} p^k(1-p)^{n-k}, \\text{ for } k = 0, 1, 2, ..., n\\] Basically, binomial random variable is a sum of n identical Bernoulli random variables. If the range of the binary rv. \\(X\\) is 0 or 1 \\(X \\in {1 = success, 0 = failure}\\), then, \\(Y = X1 + X2 + ... + X_n\\) (\\(X_i\\) are independent and identically distributed, i.i.d.) is binomially distributed (\\(Y \\sim Bin(\\mu, \\sigma^2)\\)), with \\(\\mu = np\\), \\(\\sigma^2 = np(1-p)\\). Remark: The exclamation mark (!) is used in math to represent factorial operations. The factorial of a number means to take that number and multiply it by every number that comes before it - down to one (excluding 0). 5.3.1.3 Binomial distribution - summary Criteria for a Binomial Probability Experiment A binomial experiment is an experiment which satisfies these four conditions: A fixed number of trials Each trial is independent of the others There are only two outcomes The probability of each outcome remains constant from trial to trial. In short: An experiment with a fixed number of independent trials, each of which can only have two possible outcomes. (Since the trials are independent, the probability remains constant.) 5.3.1.4 Binomial formula - intuitive explanation Once we determine that a random variable is a binomial random variable, the next question we might have would be how to calculate probabilities. Suppose that the turnout rate for the 2016 presidential election in the Chicago area is 80%. Among a miniature random sample of 3 eligible voters, find the probability that exactly 0, or 1, or 2, or 3 will vote? If we let \\(X\\) = the number of people who voted, then \\(X\\) is a binomial random variable because: there is a fixed number of voters (3), the decisions of eligible voters are independent, each voter has two outcomes - to vote (denoted 1) or to abstain from voting (denoted 0), the probability of voting is constant: 4/5 = 0.8 = the probability of “success” in a single Bernoulli trial \\(X_i\\), (i = 1, 2, 3). So how can we find probabilities? Let’s look at a tree diagram of the situation (see Figure A and B). Finding the probability distribution of X involves a couple key concepts. First, notice that there are multiple ways to get 0, 1, 2, or 3 people voted. In fact, we can use the combinations without repetitions (\\(C(n, x)\\)) to figure out how many ways there are. For example, P(X = 2) is the same regardless of the order in which we get 2 correct; we can just multiply the probability of one line by 3, since there are 3 ways to have 3 “successes”. Not only that, since the decisions of eligible voters are independent, we can just multiply the probability of getting “success” or “failure”. The general equation of the Binomial distribution is, \\[P(\\text{x &quot;successes&quot; in n trials}) = C_x^n(p^x \\times (1-p)^{n-x})\\] where: \\(p\\) = probability of a “success” (denoted with \\(1\\)); \\((1-p) = q\\) = probability of a “failure”, coded as \\(0\\); \\(C_x^n = nCx =\\) the number of \\(x\\)-combinations from the set of \\(n\\) elements. Inspect Figures A and B to understand the above general equation of the Binomial distribution. Figure A: Binomial distribution function - informal derivation (part I) Figure B: Binomial distribution function - informal derivation (part II) 5.3.1.5 Remark about random sampling Sampling with replacement: Consider a population of potato sacks, each of which has either 12, 13, 14, 15, 16, 17, or 18 potatoes, and all the values are equally likely. Suppose that, in this population, there is exactly one sack with each number. So the whole population has seven sacks. If I sample two with replacement, then I first pick one (say 14). I had a 1/7 probability of choosing that one. Then I replace it. Then I pick another. Every one of them still has 1/7 probability of being chosen. And there are exactly 49 different possibilities here (assuming we distinguish between the first and second.) They are: (12,12), (12,13), (12, 14), (12,15), (12,16), (12,17), (12,18), (13,12), (13,13), (13,14), etc. Sampling without replacement: Consider the same population of potato sacks, each of which has either 12, 13, 14, 15, 16, 17, or 18 potatoes, and all the values are equally likely. Suppose that, in this population, there is exactly one sack with each number. So the whole population has seven sacks. If I sample two without replacement, then I first pick one (say 14). I had a 1/7 probability of choosing that one. Then I pick another. At this point, there are only six possibilities: 12, 13, 15, 16, 17, and 18. So there are only 42 different possibilities here (again assuming that we distinguish between the first and the second.) They are: (12,13), (12,14), (12,15), (12,16), (12,17), (12,18), (13,12), (13,14), (13,15), etc. When we sample with replacement, the two sample values are independent. Practically, this means that what we get on the first one doesn’t affect what we get on the second. Mathematically, this means that the covariance between the two is zero. In sampling without replacement, the two sample values aren’t independent. Practically, this means that what we got on the for the first one affects what we can get for the second one. Mathematically, this means that the covariance between the two isn’t zero. When we sample without replacement, and get a non-zero covariance, the covariance depends on the population size. If the population is very large, this covariance is very close to zero. In that case, sampling with replacement isn’t much different from sampling without replacement. In some discussions, people describe this difference as sampling from an infinite population (sampling with replacement) versus sampling from a finite population (without replacement). Source: https://www.ma.utexas.edu/users/parker/sampling/repl.htm 5.3.2 Some characteristics of the binomial distribution Suppose \\(X\\) has Bernoulli distribution with parameter p - probability of success. Then \\(E(X) = p\\) \\(Var(X) = p(1-p)\\) then, if \\(Y = \\Sigma X_i = X_1 + X_2 + ... + X_n\\), Y has binomial distribution with parameters p = probability of success and n = number of trials (or sample size). If \\(Y \\sim Bin(n, p),\\) \\(E(Y) = np\\) \\(Var(Y) = np(1-p)\\) And also for the variable \\(\\frac{Y}{n} = \\hat{p}\\) - sample proportion, we have: \\(E(\\frac{Y}{n}) = p\\) \\(Var(\\frac{Y}{n}) = \\frac{p(1-p)}{n}\\) According to the Central Limit Theorem (CLT), if n is sufficiently large, sample proportion has approximately normal distribution, \\(\\hat{p} \\text{ } \\dot{\\sim} \\text{ } N(p, \\sqrt{\\frac{p(1-p)}{n}})\\). Notice that if \\(Y = X_1 + X_2 + ... + X_n\\), and \\(Y \\sim Binom(n, p)\\), and \\(X_i = \\{0 = \\text{failure}, 1 = \\text{success}\\}\\), then the mean = \\(E(Y) = Y/n = \\Sigma X/n = E(Y)= p\\) and the variance = \\(Var(Y) = \\frac{p(1-p)}{n}\\), where p is a proportion (fraction, relative frequency) of “successes”. 5.3.3 Examples 5.3.3.1 Example Assuming that the selection of items for a sample can be treated as independent trials, and that the probability that any 1 item is defective is 0.01, find: The probability of 1 defective item in a random sample of 15 items from a production line; The probability of 1 defective item in a random sample of 1 item from a production line. Solution: The experiment in the example is composed of n independent Bernoulli trials (experiments), therefore it is a binomial experiment, wherein selecting a defective item is a “success”. Assigning positive integer numbers to outcomes of the experiment we construct rv that indicates the number of defective items in a batch, so the binomial random variable for this experiment can be X = the number of defective items (“successes”) in a sample (in a batch), n stands for the sample size (the batch size). We assume that selecting each item for the sample is an independent trial, then we can apply the binomial probability formula. The probability of success p (a defective item) is 0.01, while the probability of failure (an acceptable item) is 1-0.01 = 0.99. The binomial probability function is: \\[P(X = x) = f(x; n, p) = \\binom{n}{x} p^x(1-p)^{n-x}, \\text{ for } x = 0, 1, 2, ..., n\\] The probability of 1 defective item in a random sample of 15 items from a production line is: \\[P(1 \\text{ defective item}) = P(1 \\text{ success}) = P(X = 1) =\\] \\[= \\binom{15}{1} \\times 0.01^1 \\times 0.99^{14} = 0.1303\\] The probability of 1 defective item in a random sample of 1 item from a production line is: \\[P(1 \\text{ defective item}) = P(1 \\text{ success}) = P(X = 1) =\\] \\[= \\binom{1}{1} \\times 0.01^1 \\times 0.99^{0} = 0.01\\] Notice that for n = 1, a binomial distribution is just a Bernoulli distribution. The Bernoulli distribution is the binomial distribution for n (number of trials) = 1. 5.3.3.2 Example Random variable X - # of heads in n tosses of a fair coin has binomial distribution with parameters \\(n\\) and \\(p = 0.5\\). Find the probability that in 10 tosses you get heads at least 7 times. Solution: We have \\(X \\sim Bin(10, 0.5)\\). Cumulative binomial probability function is: \\[F(x) = P(X \\leq x) = \\sum_{a=0}^x \\binom{n}{a} p^a(1-p)^{n-a}, \\text{ for } x = 0, 1, 2, ..., n\\] Then \\[P(X \\geq 7 | n = 10, p = 0.5) = P(X = 7) + P(X = 8) + P(X = 9) + P(X = 10) =\\] \\[= \\sum_{a = 7}^{10} \\binom{10}{a} 0.5^a(1-0.5)^{10-a} =\\] \\[\\binom{10}{7}(\\frac{1}{2})^7(\\frac{1}{2})^3 + \\binom{10}{8}(\\frac{1}{2})^8(\\frac{1}{2})^2 + \\binom{10}{9}(\\frac{1}{2})^9(\\frac{1}{2})^1 + \\binom{10}{10}(\\frac{1}{2})^{10}(\\frac{1}{2})^0 = \\frac{176}{1024}\\] 5.3.3.3 Example Suppose that the proportion of Polish people who trust the president of RP is equal to 60% and let rv X to be the number of people who trust Polish president - \\(X \\sim Bin(n, 0.6)\\). Find the probability that in the random sample of 15 people, at most 3 (\\(\\hat{p} = 0.2 = \\frac{3}{15}\\)) trust the president. Solution: RV X has binomial distribution, \\(X \\sim Bin(15, 0.6)\\) To calculate \\(P(X \\leq 3 | n = 15, p = 0.6)\\) we can employ the binomial distribution function or apply a normal approximation to the binomial distribution (only if the condition \\(np \\wedge n(1-p) &gt; 5\\) is satisfied) with a continuity correction like in the previous example. We need to use a cumulative form of the binomial distribution function: \\[F(x) = P(X \\leq x) = \\sum_{a=0}^x \\binom{n}{a} p^a(1-p)^{n-a}, \\text{dla } x = 0, 1, 2, ..., n\\] Then, \\[P(X \\leq 3 | n = 15, p = 0.6) = \\sum_{x=0}^{3}\\binom{15}{x}0.6^x(1-0.6)^{15-x} =\\] \\[= \\sum_{x=0}^{3}\\frac{15!}{(15-x)!x!}0.6^x(1-0.6)^{15-x} =\\] \\[= \\binom{15}{0}0.6^0(1-0.6)^{15-0} + \\binom{15}{1}0.6^1(1-0.6)^{15-1} +\\] \\[+ \\binom{15}{2}0.6^2(1-0.6)^{15-2} + \\binom{15}{3}0.6^3(1-0.6)^{15-3} =\\] \\[= \\frac{15!}{(15)!0!}0.6^0(0.4)^{15-0} + \\binom{15}{1}0.6^1(0.4)^{15-1} +\\] \\[+ \\binom{15}{2}0.6^2(0.4)^{15-2} +\\] \\[\\frac{1\\times2\\times3\\times...\\times15}{(1\\times2\\times3\\times...\\times12)1\\times2\\times3}0.6^3(1-0.6)^{15-3} =\\] \\[= \\frac{15!}{(15)!0!}0.6^0(0.4)^{15-0} + \\binom{15}{1}0.6^1(0.4)^{15-1} +\\] \\[+ \\binom{15}{2}0.6^2(0.4)^{15-2} + \\frac{13\\times14\\times15}{1\\times2\\times3}0.6^3(0.4)^{15-3} = 0.0019.\\] Now, let us compute the probability using the normal approximation. Remember that you should use a continuity correction to get a better approximation, therefore instead X = 3, we do computations for a slightly different value, namely X = 3.5 or equivalently for \\(\\hat{p} = 0.233(3) = \\frac{3.5}{15} = \\frac{7}{30}\\). Finally, \\[P(X \\leq 3.5 | n = 15, p = 0.6) = \\int_{t_0(-\\infty)}^{t_1(x = 3.5)}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-(t-\\mu)^2/(2 \\sigma^2)}dt =\\] \\[= P(Z &lt; \\frac{3.5-np}{\\sqrt{p(1-p)n}}) = P(Z &lt; -2.9) = \\int_{t_0(-\\infty)}^{t_1(z = -2.9)}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-t^2}{2}}dt = 0.0019.\\] Remark: For continuous rv’s we have \\(P(Z &lt; z) = P(Z \\leq z)\\) and also \\(P(Z &gt; z) = P(Z \\geq z)\\). Equivalently, we can do computations employing proportions, i.e. \\(\\frac{X}{n} = \\hat{p}\\), but remember to use modified formulas for \\(\\mu\\) and \\(\\sigma\\). \\[P(\\frac{X}{n} \\leq \\frac{3.5}{15} = \\frac{7}{30} | n = 15, p = 0.6) = \\int_{t_0(-\\infty)}^{t_1(\\frac{7}{30})}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-(t-\\mu)^2/(2 \\sigma^2)}dt =\\] \\[= P(Z &lt; \\frac{\\frac{7}{30}-p}{\\sqrt{\\frac{p(1-p)}{n}}}) = P(Z &lt; -2.9) = P(Z &gt; 2.9) = 1 - P(Z &lt; 2.9) = 0.0019.\\] As you may notice, the approximation is very good. The answer: The probability, that in the random sample of 15 Polish people, 3 trust the president of Poland equals 0.0019 = 0.19%. "],["continuous-probability-distributions-uniform-and-normal-distributions.html", "5.4 Continuous probability distributions - uniform and normal distributions", " 5.4 Continuous probability distributions - uniform and normal distributions 5.4.1 Uniform probability distribution 5.4.1.1 Example RV X - the amount of time to wait, in minutes, that a person must wait for a metro train on the platform - is uniformly distributed with parameters \\(a = 0\\) - the minimum value, and \\(b = 6\\) - the maximum value, \\(X \\sim U(0, 6)\\). What is the probability that you need to wait at least 4 minutes until the train leaves? Solution: We solve this problem using the uniform distribution function: \\[P(X = x) = f(x; a, b) = \\frac{1}{b - a}, \\text{ for } 0 \\leq x \\leq 6\\] Integrating uniform distribution function over the interval \\([0, x]\\), we obtain: \\(P(X &lt; x) = \\frac{x}{b-a}\\), then, \\[P(X \\geq 4) = 1 - P(Z &lt; 4) = 1 - \\frac{4}{6-0} = \\frac{1}{3}\\] Answer: The probability that you need to wait at least 4 minutes until the train leaves equals \\(\\frac{1}{3}\\). 5.4.2 Normal probability distribution 5.4.2.1 Example For normally distributed rv X with parameters \\(E(X) = 72\\) and \\(Var(X) = 144\\), compute: \\(P(X &lt; 84)\\) \\(P(60 &lt; X &lt; 69)\\) \\(P(X \\geq 102)\\) Solution: In order to use tables of the values of cumulative standardised normal distribution function, we need to standardise rv X. As a result we obtain the values of a standardised rv Z. We standardise values of X employing the following formula: \\(Z = \\frac{Y - \\mu_Y}{\\sigma_Y}\\). In the example Y = X. a) Compute \\(P(X &lt; 84)\\), \\[P(X &lt; x) = P(Z &lt; \\frac{X – \\mu_X}{\\sigma_X}) \\rightarrow P(Z &lt; z)\\] \\(P(X &lt; 84) = P(Z &lt; [(84 – 72) / 12] = 1)\\). In the tables we find that for Z = 1 the required probability is equal to 0.8413. b) Compute \\(P(60 &lt; X &lt; 69)\\), \\[P(x_1 &lt; X &lt; x_2) \\rightarrow P(z_1 &lt; Z &lt; z_2)\\] Then, Z is contained in \\((z_1, z_2)\\) We do computation as follows: \\(P(Z &lt; z_2) – P(Z &lt; z_1)\\). Then, \\(P(60 &lt; X &lt; 69) = P(-1 &lt; Z &lt; -0.25) = P(Z &lt; -0.25) – P(Z &lt; -1)\\), and from the tables we obtain 0.4013 – 0.1587 = 0.2426. c) Compute \\(P(X \\geq 102)\\), \\[P(X &gt; x) \\rightarrow P(Z &gt; z) = 1 – P(Z &lt; z)\\] Then, \\(P(X &lt; 102) = P(Z &lt; 2.5)\\), and from the tables for \\(Z = 2.5\\) we have 0.9938, and finally \\(1 – 0.9938 = 0.0062\\). 5.4.2.2 Example Assume that a random variable Z is normally distributed, with parameters \\(\\mu = 0\\) and \\(\\sigma = 1\\). What is the probability that \\(-1.96 &lt; Z &lt; 1.96\\). Normal probability density function is as follows: \\[f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/(2\\sigma^2)}\\] To find the probability that \\(-1.96 &lt; Z &lt; 1.96\\), we can apply a computer algebra system (CAS) like Mathematica or other software that is able to integrate functions (e.g. R). We can also try to integrate the normal density function without the aid of a computer, but it is very difficult. Some functions (e.g. polynomials) are easy to integrate but the normal density function is not. To find the probability, that \\(-1.96 &lt; Z &lt; 1.96\\) we have to integrate the normal density function with the parameters \\(\\mu = 0\\) and \\(\\sigma = 1\\) (the standard normal density function), from -1.96 to 1.96. So, we need to instruct a program we use to determine: \\[Integral = \\int_{-1.96}^{1.96}\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/(2\\sigma^2)} dx\\] We know that \\(\\mu = 0\\) and \\(\\sigma = 1\\), so we can simplify the formula above: \\[I = \\int_{-1.96}^{1.96}\\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2} dz\\] For example, using Wolfram Integral Calculator which is available for free at: http://www.wolframalpha.com/calculators/integral-calculator/, insert in the dialog box the following code: integrate 1/\\sqrt(2\\pi)e^(-x^2/2) from -1.96 to 1.96 Wolfram Calculator will integrate the function from -1.96 to 1.96 and the outcome should be 0.95 = 95%. Use the calculator to obtain the probability for the following intervals: \\(-1.645 &lt; Z &lt; 1.645\\) \\(-2.575 &lt; Z &lt; 2.575\\) Use \\(\\mu = 0\\) and \\(\\sigma = 1\\). 5.4.2.3 Example - Normal approximation of the binomial distribution Let \\(X = X_1 + X_2 + ... + X_n\\) be the number of times a respondent is willing to pay a particular price for a product. Assume that rv \\(X_i \\sim Bern(p = 0.6)\\) - each person (trial) is a Bernoulli rv: either the person is willing to pay a particular price (1) or is not (0). If you draw a sample of size n = 100 from a population, what is the \\(P(X \\geq 65) = P(\\frac{X}{n} \\geq 0.65)\\)? We have \\(X \\sim Bin(100, 0.6)\\). \\[P(X \\geq 65 | n = 100, p = 0.6) = \\sum_{k = 65}^{100} \\binom{100}{k} 0.6^k(1-0.6)^{100-k}\\] Instead of computing the probability employing binomial distribution function, we can use the normal approximation to the binomial because the condition \\(np \\wedge n(1-p) &gt; 5\\) is satisfied. It is often handy to replace the binomial distribution with the normal distribution if the criteria above are satisfied - then approximation of the probability is sufficiently good. The Central Limit Theorem asserts that the normal approximations to the probability distributions of the sample sum and sample mean of independent random draws with replacement from a population improve as the number of draws grows (\\(n\\rightarrow \\infty\\)). In practice, we can use normal approximation to binomial if \\(np \\wedge n(1-p) &gt; 5\\). Normal distribution requires two parameters: \\(\\mu\\) and \\(\\sigma\\). For binomial rv X, recall that, \\(E(X) = np\\) \\(Var(X) = np(1-p)\\) \\(E(\\frac{X}{n}) = p\\) \\(Var(\\frac{X}{n}) = \\frac{p(1-p)}{n}\\) Then, we can approximate the distribution of rv X with normal distribution with parameters \\(\\mu = np\\) and \\(\\sigma = \\sqrt{np(1-p)}\\). \\[N(np, \\sqrt{np(1-p)})\\] Instead sample sum \\(\\Sigma X_i = X\\), we can use sample proportion \\(\\frac{X}{n} = \\bar{X} = \\hat{p}\\) equivalently. If X has binomial distribution, we have: \\(\\mu_{\\hat{p}} = p\\) and \\(\\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}}\\). \\[N(p, \\sqrt{\\frac{p(1-p)}{n}})\\] In the example \\(p = 0.6\\) and \\(n = 100\\), then \\(\\frac{X}{n} \\sim N(0.6, 0.0490)\\). Then, \\[P(X \\geq 65 | \\mu = 60, \\sigma = 4.90) = P(\\frac{X}{n} \\geq 0.65 | \\mu = 0.6, \\sigma = 0.0490) =\\] \\[= \\int_{t_0(X = 65)}^{t_1(\\infty)}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-(t-\\mu)^2/(2 \\sigma^2)}dt\\] Because probability tables cannot be printed for every normal distribution, as there is an infinite variety of normal distributions, it is common practice to convert a normal to a standard normal and then to use the standard normal table to find probabilities - without tables or computer algebra systems, we need to compute probabilities employing integration by hand but it is difficult and time-consuming. Tables are printed for standard normal distributions with parameters \\(\\mu = 0, \\sigma = 1\\). To convert a normally distributed variable X with parameters \\(\\mu\\) and \\(\\sigma\\) to a standard normal variable, usually denoted Z, we use the following formula: \\[Z = \\frac{X - \\mu}{\\sigma}\\] Figure 5.1. Z-score transformation Variable \\(X \\sim N(2, 0.5)\\) and \\(Z \\sim N(0, 1)\\). In Fig. 5.1, areas shaded in magenta regions are equal in the distributions centred at 2 (\\(x &gt; 1.5\\)), and at 0 (\\(x &gt; -1\\)). If \\(X \\sim N(\\mu, \\sigma)\\), then \\(Z = \\frac{(X-\\mu)}{\\sigma} \\sim N(0, 1)\\). Thus, \\(Z = \\frac{\\frac{X}{n} – p}{\\sqrt{\\frac{p(1-p)}{n}}}\\) and for \\(\\frac{X}{n} = 0.65\\) we finally obtain \\(Z = 1.02\\), then \\[P(\\frac{X}{n} \\geq 0.65) = P(Z \\geq 1.02) = \\int_{t_0(Z = 1.02)}^{t_1(\\infty)}f(t)dt\\] Now, we can find probability in the tables. We get \\(P(\\frac{X}{n} \\geq 0.65) = P(Z \\geq 1.02) = 1 – P(Z \\leq 1.02) = 1 – 0.8461 = 0.1539 = 15.39\\%\\). Answer: \\(P(\\frac{X}{n} \\geq 0.65) = 15.39\\%\\) To get better approximation we should apply continuity correction. It means that instead \\(P(X \\geq 65) = P(\\frac{X}{n} \\geq 0.65)\\), we compute \\(P(X \\geq 64.5) = P(\\frac{X}{n} \\geq 0.645)\\)21. Check whether or not we get better approximation using continuity correction, if we know that true value of the probability that \\(X \\geq 65\\) is = 0.1795 - this is the true value that we obtained employing binomial formula. In general, we add \\(\\frac{1}{2}\\) to X - if we want to find \\(P(X \\leq x)\\) - or subtract \\(\\frac{1}{2}\\) from X - for \\(P(X \\geq x)\\).↩︎ "],["the-basics-of-statistical-inference-lecture-6-draft-copy-ver-0-2.html", "6 The basics of statistical inference [Lecture 6 - draft copy, ver. 0.2] ", " 6 The basics of statistical inference [Lecture 6 - draft copy, ver. 0.2] "],["statistics-and-sampling-variability.html", "6.1 Statistics and sampling variability", " 6.1 Statistics and sampling variability Statistic: A quantity computed from values in a sample. In inferential statistics, we want to use characteristics of the sample (i.e. a statistic) to estimate the characteristics of the population (i.e. a parameter). If we obtain a random sample and calculate a sample statistic from that sample, the sample statistic is a random variable. Sampling variability: The observed value of a statistic depends on the particular sample selected from the population and it will vary from sample to sample. This variability is called sampling variability. "],["sampling-distribution-for-a-statistic-a-sample-mean-a-sample-proportion-etc-.html", "6.2 Sampling distribution for a statistic (a sample mean, a sample proportion etc.)", " 6.2 Sampling distribution for a statistic (a sample mean, a sample proportion etc.) A statistic, such as the sample mean or the sample standard deviation, is a number computed from a sample. Since a sample is random, every statistic is a random variable: it varies from sample to sample in a way that cannot be predicted with certainty. As a random variable it has a mean, a standard deviation, and a probability distribution. The probability distribution of a statistic is called its sampling distribution. Typically sample statistics are computed in order to estimate the corresponding population parameters. A sampling distribution is the probability distribution of a sample statistic that is formed when samples of size n are repeatedly taken from a population. If the sample statistic is the sample mean, then the distribution is the sampling distribution of sample means. Every sample statistic has a sampling distribution. The sampling distribution of a statistic is the distribution of that statistic, considered as a random variable, when derived from a random sample of size n. It may be considered as the distribution of the statistic for all possible samples from the same population of a given sample size. Sampling distributions are important in statistics because they provide a major simplification to statistical inference. More specifically, they allow analytical considerations to be based on the probability distribution of a statistic. The standard deviation of the sampling distribution of a statistic is referred to as the standard error of that quantity. Consider the Venn diagram below (Figure 6.1). Figure 6.1. The idea of sampling distribution of a statistic (e.g. a sample mean) The rectangle represents a large population, and each circle represents a sample of size n. Because the sample entries can differ, the sample means can also differ. The mean of Sample 1 (S1) is \\(\\bar{x}_1 = 3.5\\); the mean of Sample 2 is \\(\\bar{x_2}\\); and so on. The sampling distribution of the sample means for samples of size n for this population consists of \\(\\bar{x}_1, \\bar{x}_2, \\bar{x}_3\\), and so on. If the samples are drawn with replacement, then an infinite number of samples can be drawn from the population. 6.2.1 Sampling distribution of a sample mean Suppose a population consists of four houses (N = 4), where the value of rv. X, the number of rooms for rent in each unit, is listed below: first house (2 rooms), second house (3 rooms), third house (4 rooms), fourth house (5 rooms). Consider drawing a random sample of size 2 with replacement. There are four possibilities on the first draw from the population and also four possibilities on the second draw from the population. That is, we select a unit at random, put it back, and then select another unit at random. Denote by X1 and X2 the observation of X obtained in the first and second drawing, respectively. The population distribution of X is given in Table 6.1. Table 6.1. The population distribution i X Probability 1 2 1/4 2 3 1/4 3 4 1/4 4 5 1/4 Sum - 1 Find the sampling distribution of the sample mean \\(\\bar{X} = (X1 + X2) / 2\\). In practice, only a single random sample, not 16 possible samples, would be taken from the population; the sample size would be very small relative to a much larger population size, and, of course, not all observations in the population would be known. For each of the 16 possible samples (see Table 6.2) also lists a sample mean (found by adding the two observations and dividing by 2) and its probability of occurrence (expressed as 1⁄16, since each of the 16 possible samples is equally likely). When cast into a relative frequency or probability distribution, the 16 sample means form the sampling distribution of the mean, previously defined as the probability distribution of means for all possible random samples of a given size from some population. Table 6.2. All possible 2-samples i All possible samples (4 * 4 = 16) Mean (\\(\\bar{X}\\)) Probability (\\(P_i\\)) 1 2, 2 2 1/16 2 2, 3 2.5 1/16 3 2, 4 3 1/16 4 2, 5 3.5 1/16 5 3, 2 2.5 1/16 6 3, 3 3 1/16 7 3, 4 3.5 1/16 8 3, 5 4 1/16 9 4, 2 3 1/16 10 4, 3 3.5 1/16 11 4, 4 4 1/16 12 4, 5 4.5 1/16 13 5, 2 3.5 1/16 14 5, 3 4 1/16 15 5, 4 4.5 1/16 16 5, 5 5 1/16 Sum - - 1 Not all values of the sample mean occur with equal probabilities since some values occur more than once among the 16 possible samples. For instance, a sample mean value of 3.5 appears among 4 of 16 possibilities and has a probability of 4⁄16. Table 6.3 presents the sampling distribution of the mean for samples of size n = 2 from a miniature population N = 4. Table 6.3. Sampling distribution of the mean (samples of size two) i Sample mean (\\(\\bar{x}\\)) Probability (\\(p_i\\)) 1 5 1/16 2 4.5 2/16 3 4 3/16 4 3.5 4/16 5 3 3/16 6 2.5 2/16 7 2 1/16 Sum - 1 Figure 6.2 summarizes the process of constructing the sampling distribution of a sample mean. Figure 6.2. The sampling distribution of the sample mean for samples of size two; f stands for an absolute frequency (Source: Robert S. Witte, John S. Witte. (2017) Statistics. p. 172.) 6.2.2 Sampling distribution for a sample sum (\\(S\\)) [Translation soon] Przeprowadźmy eksperyment polegający na rzucie dwiema sześciennymi kostkami do gry. Zdefiniujmy zmienną = suma oczek, które wypadły przy rzucie dwiema kostkami do gry. Rozkład prawdopodobieństwa zmiennej, która może przyjąć 6 wartości z identycznym prawdopodobieństwem jest rozkładem jednostajnym (rzut pojedynczą kostką sześcienną). Jaki będzie rozkład prawdopodobieństwa dla sumy oczek (lub średniej arytmetycznej wyniku) przy rzucie dwiema kostkami? W tabeli 6.4 przedstawiono wszystkie możliwe kombinacje wyników, czyli przestrzeń zdarzeń elementarnych: Table 6.4. Sample space for the sum of outcomes in flipping two fair dice Pierwsza kość (X1) Druga kość (X2) 1 2 3 4 5 6 1 S = 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 4 + 3 = 7 8 9 4 5 6 3 + 4 = 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 6+6 = 12 Rysunek 6.2 przedstawia rozkład prawdopodobieństwa sumy S z próby dwuelementowej (suma wyników dwóch rzutów sześciościenną kością), który kształtem przypomina rozkład normalny. Rozkład prawdopodobieństwa do gry (rozkład zmiennej \\(X_1\\)) był , ale przy rzucie dwiema (\\(X_1+X_2\\)) lub tym bardziej, co można pokazać, większą liczbą kostek, rozkład prawdopodobieństwa sumy wyników (\\(S = X_1+X_2+ ... +X_n\\)), lub wartości przeciętnej wyników (\\(\\overline{X}\\)) wraz z wzrostem liczby kostek, coraz bardziej przypomina rozkład normalny. Figure 6.2. Sampling distribution for the random variable S = sum of outcomes in flipping two fair dice (Source: Wikipedia.org) "],["central-limit-theorem-clt.html", "6.3 Central Limit Theorem (CLT)", " 6.3 Central Limit Theorem (CLT) The central limit theorem (CLT) states that the sampling distribution of the sample mean (also sample sum S and sample proportion p) of any independent, random variable will be normal or nearly normal if the sample size is large enough. Informally, the theorem states that if we take random samples of a certain distribution and then average them, the result (i.e the sample mean) will resemble a normal distribution the more samples we take. “The Central Limit Theorem (CLT) is possibly the most famous theorem in all of statistics, being widely used in any field that wants to infer something or make predictions from gathered data. A first (simple) version of it was introduced in the eighteenth century, first by de Moivre and then later in a more refined way by Laplace, but it wasn’t until around 1935 that the theorem as we know it today was published. The goal of these notes is to explain in broad terms what it says and, more importantly, what it doesn’t”. – Javier Rodríguez Chatruc, Federico Carrone (Read more here: https://lambdaclass.com/data_etudes/central_limit_theorem_misuse/) The central limit theorem (CLT) establishes that, in many situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a bell-shaped curve) even if the original variables themselves are not normally distributed. The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions. Central limit theorem states that when an infinite number of successive random samples are taken from a population, the sampling distribution of the means of those samples will become approximately normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2/n\\) as the sample size (n) becomes larger, irrespective of the shape of the population distribution. Informally, the theorem states that if we take random samples of a certain distribution and then average them, the result (i.e the sample mean) will resemble a normal distribution the more samples we take. More precisely, if \\(X_1, X_2, ..., X_n\\) are independent and identically distributed (i.i.d.) random variables and \\(\\bar{X} = \\frac{X_1 + X_2 + ... + X_n}{n}\\) is the sample mean, its standardization \\(\\bar{Z} = \\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}}\\) converges (in distribution) to a standard normal distribution \\(N(0, 1)\\). The theorem holds just the same if we replace every instance of \\(\\bar{X}_n\\) with the sums \\(S = X_1 + X_2 + ... + X_n\\). The most common example of the CLT in action is when considering a binomial distribution. Say we flip a coin n number of times and we count the number of heads obtained; we can think of this as the sum of n independent random variables \\(X_i\\) with a Bernoulli distribution, \\(X_i \\sim Bern(p)\\), where \\(p = 0.5\\) if a coin is fair. Then the CLT tells us that as n gets big, we can approximate the rv. sum of heads \\(S = X_1 + X_2 + ... + X_n\\), by a normal distribution with a mean \\(np\\) and a variance \\(np(1-p)\\). In general, a random variable \\(X\\) with a binomial distribution \\(X \\sim Binom(n, p)\\), can be approximated by a normal distribution \\(N(np, np(1-p))\\) provided n is large enough. What CLT says is that the sample means (or sums) of a (reasonable) distribution will be close to a normal one. Because the sum of independent Bernoulli random variables (\\(S = X_1 + X_2 + ... + X_n\\)) yields a binomial distribution, this sample sum S is approximately normally distributed, \\(S \\dot\\sim N(np, np(1-p))\\). Also, the distribution of the sample proportion \\(p = S/n\\) can be approximated by the normal distribution. 6.3.0.1 CLT for the sample mean Let \\(X_1, X_2, ..., X_n\\) be a sequence of independent random variables of any distribution, i.i.d, with \\(E(X_i) = \\mu\\) and \\(Var(X_i) = \\sigma^2\\). Then, for \\(n\\) big enough, \\[\\frac{\\sum_{i=1}^{n} X_i}{n} = \\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{\\sqrt{n}}) \\text{ oraz }\\] \\[\\frac{\\sum_{i=1}^{n} X_i - n\\mu}{\\sigma\\sqrt{n}} = \\frac{\\overline{X} - \\mu}{\\sigma/ \\sqrt{n}}\\longrightarrow Z, \\text{gdzie } Z\\sim N(0, 1)\\] CLT states that, for a random sample \\(X_1, X_2, ..., X_n\\) from the population with a mean \\(\\mu\\) and standard deviation \\(\\sigma\\), as n gets bigger, the sampling distribution of the sample mean \\(\\overline{X}\\) can be approximated by the normal distribution \\(N(\\mu, \\frac{\\sigma}{\\sqrt{n}})\\). Also, for \\(\\mu_{\\overline{X}} = E(\\overline{X}) = \\mu\\), and \\(\\sigma_{\\overline{X}} = Var(\\overline{X}) = \\frac{\\sigma}{\\sqrt{n}}\\). As CLT states, for big n (at least 30 elements), \\(\\overline{X} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}})\\) 6.3.0.2 CLT for the sample proportion For a sample proportion p, \\(\\frac{\\Sigma X_i}{n} = \\widehat{p}\\), CLT states that, if \\(X_i \\sim Bern(p)\\), \\(E(X_i) = p, Var(X_i) = p(1-p)\\), \\(\\Sigma X_i \\sim Bin(n, p)\\), \\(E(\\Sigma X_i) = np, Var(\\Sigma X_i) = np(1-p)\\), and also \\(n \\rightarrow \\infty\\), \\[\\Sigma X_i \\sim N(\\mu = np, \\sigma = \\sqrt{np(1-p)}) \\text{ oraz }\\] \\[\\frac{\\Sigma X_i}{n} \\sim N(\\mu = p, \\sigma = \\sqrt{\\frac{p(1-p)}{n}})\\] Furthermore, for the sample proportion: Let \\(X_1, X_2, ..., X_n\\) be a sequence of independent Bernoulli random variables, \\(Bern(p)\\), with \\(E(X_i) = p\\), and \\(Var(X_i) = p(1-p)\\). Then, if \\(n \\longrightarrow \\infty\\), \\[\\frac{\\sum_{i=1}^{n} X_i - np}{\\sqrt{np(1-p)}} = \\frac{\\frac{\\sum_{i=1}^{n} X_i}{n} - p}{\\sqrt{\\frac{p(1-p)}{n}}} = \\frac{\\widehat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}}\\longrightarrow Z, \\text{gdzie } Z\\sim N(0, 1)\\] For sufficiently large n, \\(\\widehat{p} \\sim N(p, \\sqrt{\\frac{p(1-p)}{n}})\\), and \\(E(\\widehat{p}) = p, Var(\\widehat{p}) = \\frac{p(1-p)}{n}\\) "],["point-and-interval-estimation.html", "6.4 Point and interval estimation", " 6.4 Point and interval estimation 6.4.1 Point estimation In statistics, point estimation involves the use of sample data to calculate a single value (known as a point estimate since it identifies a point in some parameter space) which is to serve as a “best guess” or “best estimate” of an unknown population parameter (for example, the population mean). More formally, it is the application of a point estimator to the data to obtain a point estimate. Point estimation can be contrasted with interval estimation: such interval estimates are typically either confidence intervals, in the case of frequentist inference, or credible intervals, in the case of Bayesian inference. 6.4.2 Interval estimation [From Wikipedia.org] In statistics, interval estimation is the use of sample data to calculate an interval of possible values of an unknown population parameter [such as a sample mean]; this is in contrast to point estimation, which gives a single value. Jerzy Neyman (1937) identified interval estimation (“estimation by interval”) as distinct from point estimation (“estimation by unique estimate”). In doing so, he recognized that then-recent work quoting results in the form of an estimate plus-or-minus a standard deviation indicated that interval estimation was actually the problem statisticians really had in mind. The most prevalent forms of interval estimation are: confidence intervals (CI) (a frequentist method); and credible intervals (a Bayesian method). Figure 6.3 summarizes the idea of the confidence interval for sample means (\\(\\bar{X}\\)) in populations with the true mean \\(\\mu\\) and the true standard deviation \\(\\sigma\\). Figure 6.3. The idea of CI for sample means The general formula for a confidence interval for a sample mean \\(p\\): \\[P(\\bar{x} - z_{\\alpha/2} \\sqrt{ \\frac{\\sigma^2}{n} } &lt; \\mu &lt; \\bar{x} + z_{\\alpha/2} \\sqrt{ \\frac{\\sigma^2}{n} } ) = 1 - \\alpha\\] For the most common, \\(95\\%\\) CI, we substitute \\(z_{\\alpha/2}\\) with \\(1.96\\). 6.4.2.1 Worked example A random sample of 985 constituents was polled. Of those surveyed, 592 people intended to vote for the Republican candidate in the upcoming election (sample proportion = \\(\\hat{p} = 0.601\\)). Construct 95% confidence interval for proportion \\(p\\) of voters in the population who intend to vote for the Republican candidate (Notice that the set of selected constituents forms a random sample from the Bernoulli distribution.). Based on this information, can you conclude that the candidate will win the election? Solution: Statistical inference deals with the question: can we infer something from the random sample about the unknown population parameters (e.g. p = proportion, \\(\\mu\\) = mean, \\(\\sigma\\) = standard deviation)? Two essential tools of statistical inference are point estimate and interval estimate (point estimate \\(\\pm\\) margin of error). Interval estimate is usually called a confidence interval. For example, it is possible to infer about the population proportion from a sample proportion (point estimate of the population parameter). The list below presents three essential point estimators that you should be familiar with: sample proportion \\(\\hat{p} = \\frac{\\Sigma X_i}{n}\\), where \\(\\Sigma X_i\\) (sometimes denoted by Y or S or simply by X) is a sample sum, \\(\\Sigma X_i = X_1 + X_2 + ... + X_n\\) and \\(X_i\\) are Bernoulli random variables (binary rv). sample mean \\(\\bar{X} = \\frac{\\Sigma X_i}{n}\\) sample standard deviation \\(S(X) = \\frac{\\Sigma (X_i - \\bar{X})^2}{n-1}\\) Notice that the formula for a sample standard deviation is slightly different from the standard deviation formula for a population, i.e. we divide by n-1, not by n. It was proven that we need to divide by n-1 to get a better estimation. However, if you divide by n, not by n-1, in computing a sample SD, the estimate will be also pretty good. Recall that if \\(X_i\\) are Bernoulli random variables and \\(X = \\{X_1, X_2, ..., X_n\\}\\), then \\(E({X_i}) = p\\) and \\(Var(X_i) = p(1-p)\\). For any estimate \\(\\hat{\\theta}\\) (e.g. \\(\\hat{p}\\)) we would like the sampling distribution of \\(\\hat{\\theta}\\) to have a mean equal to the parameter estimated (\\(E(\\hat{\\theta}) = \\theta\\)). An estimator possessing this property is said to be unbiased - this is the most desirable property of a good estimator. Three estimators listed above are unbiased estimators, \\(E(\\hat{p}) = p\\), for instance. If we compute the value of a point estimate, we can determine confidence interval, that is, numerical interval that is very likely to contain the true value of the population parameter. Most often we want to find a 95% confidence interval and then we are 95% confident that the true value of the population parameter is in our confidence interval - we can say that 95% of the observed confidence intervals will hold the true value of the parameter. Confidence intervals consist of a range of values (interval) that act as good estimates of the unknown population parameter. However, in infrequent cases, none of these values may cover the value of the parameter. The level of confidence (e.g. 0.95) of the confidence interval indicates the probability that the confidence range captures this true population parameter given a distribution of samples. Assuming a 0.95 confidence level, we conclude that 95% of all possible confidence intervals, for all possible random samples, cover the true value of the parameter (e.g. \\(p\\)). This statement is a loose interpretation, but it helps to understand the general idea of the interval estimation. To determine an upper and a lower bound of the confidence interval for proportion p we need to know what the probability distribution of the sample proportion is. From the Central Limit Theorem we know that, if n (n = sample size) is sufficiently large, \\(\\hat{p} \\sim N(\\mu_{\\hat{p}} = p, \\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}})\\). The standard deviation of the sample proportion \\(\\sqrt{\\frac{p(1-p)}{n}}\\) is called a standard error (\\(SE(\\hat{p})\\)) of the sample proportion22. To obtain the formula for the confidence interval (CI) for a proportion, we use the normally distributed standardised variable Z. Recall that for any estimate \\(\\hat{\\theta}\\), \\(Z = \\frac{\\hat{\\theta} - \\mu_{\\hat{\\theta}}}{\\sigma_{\\hat{\\theta}}}\\). For the sample proportion \\(\\hat{p}\\) we have \\(Z = \\frac{\\hat{p} - \\mu_{\\hat{p}}}{\\sigma_{\\hat{p}}} = \\frac{\\hat{p} - p}{\\sqrt{\\frac{p(1-p)}{n} }}\\). To determine a confidence interval that contains the true value of p with the probability of 95%, we need to follow the procedure below. We can read from the table of the standard normal distribution (rv Z) that \\[P(-z_{\\alpha/2} &lt; Z &lt; z_{\\alpha/2}) = 1-\\alpha\\] \\[P(-z_{0.05/2} &lt; Z &lt; z_{0.05/2}) = 0.95\\] \\[P(-1.96 &lt; Z &lt; 1.96) = 0.95\\] The quantity \\(\\alpha\\) is called a significance level. Then, substituting Z with \\(\\frac{\\hat{p} - \\mu_{\\hat{p}}}{\\sigma_{\\hat{p}}}\\) we obtain: \\[P(- z_{\\alpha/2} &lt; Z &lt; z_{\\alpha/2}) = P(- z_{\\alpha/2} &lt; \\frac{\\hat{p} - \\mu_{\\hat{p}}}{\\sigma_{\\hat{p}}} = \\frac{\\hat{p} - p}{\\sqrt{ \\frac{p(1-p)}{n} }} &lt; z_{\\alpha/2}) = 1 - \\alpha\\] Rearranging the expression above, we obtain the general formula that allows us to determine a confidence interval for a proportion \\(p\\): \\[P(\\hat{p} - z_{\\alpha/2} \\sqrt{ \\frac{p(1-p)}{n} } &lt; p &lt; \\hat{p} + z_{\\alpha/2} \\sqrt{ \\frac{p(1-p)}{n} } ) = 1 - \\alpha\\] For the most common, \\(95\\%\\) CI, we substitute \\(z_{\\alpha/2}\\) with \\(1.96\\). Finally, \\[P( 0.601 - 1.96\\sqrt{\\frac{0.601(1-0.601)}{985}} &lt; p &lt; 0.601 + 1.96\\sqrt{\\frac{0.601(1-0.601)}{985}} ) = 0.95\\] \\[P( 0.601 - 0.0306 &lt; p &lt; 0.601 + 0.0306 ) = 0.95\\] Because we do not know the true value of p, in the formula, we replaced p with a sample proportion \\(\\hat{p}\\) to compute the standard error and determine the mean. We can also write: \\[\\hat{p} \\pm 1.96\\sqrt{ \\frac{p(1-p)}{n}}\\] \\[0.601 \\pm 0.0306\\] where 0.0306 is a margin of error. We conclude that numerical interval \\[0.5704, 0.6316\\] (that is based on the data from the sample of 985 voters) contains the true value of the unknown population parameter p with the probability of 95%. Moreover, because the greatest lower bound of the CI (57.04%) is higher than 50%, we have 95% confidence that the candidate will win the election. Similarly, \\(\\sigma_{\\bar{X}} = \\frac{\\sigma_X}{\\sqrt{n}}\\) is called a standard error of the sample mean.↩︎ "],["hypothesis-testing-introduction-lecture-7-draft-copy-ver-0-1.html", "7 Hypothesis testing - introduction [Lecture 7 - draft copy, ver. 0.1]", " 7 Hypothesis testing - introduction [Lecture 7 - draft copy, ver. 0.1] Often in statistics, we have some hypothesis to test. For example, we want to test whether a drug can lower the chance of a heart attack. Often, we will have two hypotheses to compare: the null hypothesis states that the drug is useless, while the alternative hypothesis states that the drug is useful. Quantitatively, suppose that the chance of heart attack without the drug is \\(\\theta_0\\) and the chance with the drug is \\(\\theta\\). Then the null hypothesis is \\(H_0: \\theta = \\theta_0\\), while the alternative hypothesis is \\(H_1: \\theta \\not= \\theta_0\\). It is important to note that the null hypothesis and alternative hypothesis are not on equal footing. By default, we assume the null hypothesis is true. For us to reject the null hypothesis, we need a lot of evidence to prove that. This is since we consider incorrectly rejecting the null hypothesis to be a much more serious problem than accepting it when we should not. For example, it is relatively okay to reject a drug when it is actually useful, but it is terrible to distribute drugs to patients when the drugs are actually useless. Alternatively, it is more serious to deem an innocent person guilty than to say a guilty person is innocent. In general, let \\(X_1, \\cdots, X_n\\) be independent identically distributed (iid), each taking values in \\(\\mathcal{X}\\), each with unknown pdf/pmf \\(f\\). We have two hypotheses, \\(H_0\\) and \\(H_1\\), about \\(f\\). On the basis of data \\(\\mathbf{X} = \\mathbf{x}\\), we make a choice between the two hypotheses. "],["the-basics-of-hypothesis-testing.html", "7.1 The basics of hypothesis testing", " 7.1 The basics of hypothesis testing In most practical data analysis it is possible to carry out inferences (from sample to population) based on graphical techniques (e.g. investigating the empirical distributions). In certain cases it is important to make quantitative statements about the degree of uncertainty in an inference. This requires a formal and quantitative approach to inference. In the standard setup we are considering hypotheses, which are statements about a population. For example, the statement that the mean of a population is positive is a hypothesis. If the data are inconclusive or strongly support the null hypothesis, then we decide in favor of the null hypothesis. Only if the data strongly favor the alternative hypothesis do we decide in favor of the alternative hypothesis over the null. If hypothesis A represents a “conventional wisdom” that somebody is trying to overturn by proposing hypothesis B, then A should be the null hypothesis and B should be the alternative hypothesis. Thus, if somebody is claiming that cigarette smoking is not associated with lung cancer, the null hypothesis would be that cigarette smoking is associated with lung cancer, and the alternative would be that it is not. Then once the data are collected and analyzed, if the results are inconclusive, we would stick with the standard view that smoking and lung cancer are related. If the consequences of mistakenly accepting hypothesis A are more severe than the consequences of mistakenly accepting hypothesis B, then B should be the null hypothesis and A should be the alternative. For example, suppose that somebody is proposing that a certain drug prevents baldness, but it is suspected that the drug may be very toxic. If we adopt the use of the drug and it turns out to be toxic, people may die. On the other hand if we do not adopt the use of the drug and it turns out to be effective and non-toxic, some people will needlessly become bald. The consequence of the first error is far more severe than the consequence of the second error. Therefore we take as the null hypothesis that the drug is toxic, and as the alternative we take the hypothesis that the drug is non-toxic and effective. If hypothesis A is a much simpler explanation for a phenomenon than hypothesis B, we should take hypothesis A as the null hypothesis and hypothesis B as the alternative hypothesis. This is called the principle of parsimony, or Occam’s razor. Stated another way, if we have no reason to favor one hypothesis over another, the simplest explanation is preferred. Note that there is no general theoretical justification for this principal, and it does sometimes happen that the simplest possible explanation turns out to be incorrect. Next we need to consider the level of evidence in the data for each of the two hypotheses. The standard method is to use a test statistic \\(T(X_1, \\ldots, X_n)\\) such that extreme values of \\(T\\) indicate evidence for the alternative hypothesis, and non-extreme values of \\(T\\) indicate evidence for the null hypothesis. “Extreme” may mean “closer to \\(+\\infty\\)” (a right-tailed test), or “closer to \\(-\\infty\\)” (a left-tailed test), or “closer to one of \\(\\pm \\infty\\)”, depending on the context. The first two cases are called one-sided tests, while the final case is called a two-sided test. The particular definition of “extreme” for a given problem is called the rejection region. "],["examples-.html", "7.2 Examples.", " 7.2 Examples. Example 1. Suppose we are investigating a coin, and the null hypothesis is that the coin is fair (equally likely to land heads or tails) while the alternative is that the coin is unfairly biased in favour of heads. If we observe data \\(X_1, \\ldots, X_n\\) where each \\(X_i\\) is \\(H\\) or \\(T\\), then the test statistic \\(T(X_1, \\ldots, X_n)\\) may be the number of heads, and the rejection region would be ‘large values of \\(T\\)’ (since the maximum value of \\(T\\) is \\(n\\), we might also say ‘\\(T\\) close to \\(n\\)’). On the other hand, if the alternative hypothesis was that the coin is unfairly biased in favour of tails, the rejection region would be ‘small values of \\(T\\)’ (since the minimum value of \\(T\\) is zero, we might also say ‘\\(T\\) close to zero’). Finally, if the alternative hypothesis was that the coin is unfairly biased in any way, the rejection region would be ‘large or small values of \\(T\\)’ (\\(T\\) close to \\(0\\) or \\(n\\)). Example 2. Suppose we observe \\(28\\) heads and \\(12\\) tails in \\(40\\) flips of a coin. Our observed test statistic value is \\(T_{\\rm obs} = 28\\). You may recall that under the null hypothesis (\\(P(H) = P(T) = 1/2\\)) the probability of observing exactly \\(k\\) heads out of \\(40\\) flips is \\({40 \\choose k}/2^{40} = {40 \\choose k} \\times (1/2)^{40}\\) (where \\({n \\choose k} = n! / (n-k)!k!\\)). Therefore the probability of observing a test statistic value of \\(28\\) or larger under the null hypothesis (i.e. the p-value) is \\[ P(T = 28) + P(T = 29) + \\cdots + P(T = 40) \\] which equals, \\[ {40 \\choose 28}/2^{40} + {40 \\choose 29}/2^{40} + \\cdots + {40 \\choose 40}/2^{40}. \\] This value can be calculated on a computer. It is approximately \\(.008\\), indicating that it is very unlikely to observe 28 or more heads in 40 flips of a fair coin. Thus the data suggests that the coin is not fair, and in particular it is biased in favor of heads. Put another way, if we decide in favor of the alternative hypothesis, there is \\(&lt;1\\%\\) chance that we are committing a type I error. An alternative approach to calculating this p-value is to use a normal approximation. Under the null distribution, \\(T\\) has mean \\(n/2\\) and standard deviation \\(\\sqrt{n}/2\\) (recall the standard deviation formula for the binomial distribution is \\(\\sigma = \\sqrt{np(1-p)}\\) and substitute \\(p=1/2\\)). Thus the standardized test statistic is \\(T^*_{\\rm obs} = 2(T_{\\rm obs} - n/2)/\\sqrt{n}\\), which is \\(2.53\\) in this case. Since \\(T^*_{\\rm obs}\\) has mean \\(0\\) and standard deviation \\(1\\) we may approximate its distribution with a standard normal distribution. Thus the p-value can be approximated as the probability that a standard normal value exceeds \\(2.53\\). From a table of the standard normal distribution, this is seen to be approximately \\(.006\\), which is close to the true value of (approximately) \\(.008\\) and can be calculated without the use of a computer. "],["important-concepts-in-hypothesis-testing-summary.html", "7.3 Important concepts in hypothesis testing - summary", " 7.3 Important concepts in hypothesis testing - summary \\(H_0\\): null hypothesis - the state of the world that you assume is true. Typically, this is a world of “no effect,” in which probability distributions are easy to calculate or simulate. \\(H_0\\) is a specific mathematical statement about a population parameter. \\(H_A\\): alternative hypothesis - a state of the world different from the null. Typically, this is a world in which the effect you are testing is real. Test statistic: the estimate that you are testing. Typically, this is a something that you have computed from data and are trying to understand in the context of the null distribution. Null distribution: the sampling distribution of the test statistic under the null hypothesis. \\(p\\)-value: probability of observing something as strange or stranger as what you observed, under the assumption that the null hypothesis is true. \\(\\alpha\\)-level: a threshold beyond which you begin to doubt the null hypothesis. This is a line in the sand that you draw to purposefully gauge your dubiousness. Two possible outcomes: Reject \\(H_0\\) at \\(\\alpha\\)-significance level: observations are so unlikely under the null hypothesis, that it is likely false Fail to reject \\(H_0\\) at \\(\\alpha\\)-significance level: observations are reasonably likely under null hypothesis, so can’t rule out possibility that it is true Important: We never confirm the null hypothesis – we only fail to reject! Always report \\(p\\)-values and a confidence interval. One-sided vs. two-sided tests: one-sided test are almost never used in practice. 7.3.1 Testing Outcomes For a defendant on trial: \\(H_0\\): innocent until proven guilty. Type I error: \\(\\Pr(\\text{reject} | H_0)\\) - convicting an innocent person. Type II error: \\(\\Pr(\\text{fail to reject} | H_0^c) = 1- Power\\) - letting a guilty person go free. (‘Alpha’) The probability of committing a Type I error. Also known as the significance level. (‘Beta’) The probability of committing a Type II error. Power is the probability the null hypothesis is rejected given that it is false (ie. \\(1 - \\beta\\)). \\(\\alpha\\) and \\(\\beta\\) are probabilities of committing an error so we want these values to be low. However, we cannot decrease both. As \\(\\alpha\\) decreases, \\(\\beta\\) increases. Note! Type I error is also thought of as the event that we reject the null hypothesis GIVEN the null is true. In other words, Type I error is a conditional event and \\(\\alpha\\) is a conditional probability. The same idea applies to Type II error and \\(\\beta\\). Decision \\Truth \\(H_0\\) is true \\(H_0\\) is false Reject \\(H_0\\) Type I error Correct decision Fail to Reject \\(H_0\\) Correct decision Type II error The “reality”, or truth, about the null hypothesis is unknown and therefore we do not know if we have made the correct decision or if we committed an error. We can, however, define the likelihood of these events. "]]
